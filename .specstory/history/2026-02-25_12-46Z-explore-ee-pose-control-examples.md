<!-- Generated by SpecStory -->

# Explore EE pose control examples (2026-02-25 12:46Z)

_**Assistant**_



---





---



---



---



---



---



---



---





---



---



---



---



---



---



---



---





---



---



---



---



---



---





---



---



---



---



---





---



---



---



---


Here’s a concise report of what’s in your workspace:

---

## 1. Scripts using `control_mode="pd_ee_delta_pose"`

**Examples:**

- `/Users/jianzihang/Downloads/RL_Robot/examples/demo_manual_control_continuous.py` (default control mode)
- `/Users/jianzihang/Downloads/RL_Robot/examples/demo_manual_control.py`
- `/Users/jianzihang/Downloads/RL_Robot/v3-suction/env_clutter_pick.py`, `train_sb3.py`, `config.py`
- `/Users/jianzihang/Downloads/RL_Robot/base_env/env_clutter_pick.py`, `training.py`, `demo_env_visualization.py`, etc.

**Example creation:**

```38:46:examples/demo_manual_control_continuous.py
    env: BaseEnv = gym.make(
        args.env_id,
        obs_mode=args.obs_mode,
        reward_mode=args.reward_mode,
        control_mode=args.control_mode,
        render_mode=args.render_mode,
        **args.env_kwargs
    )
```

---

## 2. Computing actions to move the EE to a target

**`_move_to_position` in `env_clutter_pick.py`:**

```156:283:v3-suction/env_clutter_pick.py
    def _move_to_position(self, target_pos: np.ndarray, steps: int = 200) -> bool:
        """
        逆运动学控制，使用pd_ee_delta_pose控制模式移动到目标位置
        ...
        """
        ...
                # 获取当前末端执行器位置
                current_pos = self.agent.tcp.pose.p
                ...
                # 计算位置误差
                pos_error = target_pos - current_pos
                ...
                # 构建动作向量 [dx, dy, dz, drx, dry, drz, gripper]
                action = torch.zeros(self.num_envs, 7, device=self.device, dtype=torch.float32)
                max_controller_step = 0.1  # 控制器支持的最大增量：10cm
                ...
                # 归一化位置误差到控制器的最大增量范围
                pos_error_norm = torch.linalg.norm(pos_error)
                if pos_error_norm > actual_max_step:
                    pos_command = (pos_error / pos_error_norm) * actual_max_step
                else:
                    pos_command = pos_error
                action[:, :3] = pos_command.unsqueeze(0).repeat(self.num_envs, 1)
                action[:, 3:6] = 0.0  # 不改变姿态
                action[:, 6] = 0.00  # 保持夹爪状态
                super().step(action)
```

**Demo manual control (`pd_ee_delta_pose`):**

```130:194:examples/demo_manual_control_continuous.py
            if (
                "pd_ee_delta_pose" in args.control_mode
                or "pd_ee_target_delta_pose" in args.control_mode
            ):
                ee_action = np.zeros([6])
            ...
            # End-effector
            if num_arms > 0:
                # Position
                if "i" in pressed_keys:  # +x
                    ee_action[0] = EE_ACTION
                if "k" in pressed_keys:  # -x
                    ee_action[0] = -EE_ACTION
                ...
                # Rotation (axis-angle)
                if "1" in pressed_keys:
                    ee_action[3:6] = (1, 0, 0)
```

---

## 3. Reading current TCP/EE pose

**In `jenga_tower.py`:**

```509:511:jenga_tower.py
    def _get_obs_extra(self, info: Dict):
        obs = dict(tcp_pose=self.agent.tcp.pose.raw_pose)
```

**In `v3-suction/env_clutter_pick.py`:**

```python
# Position (world frame)
current_pos = self.agent.tcp.pose.p

# Raw pose (position + orientation)
tcp_pose = self.agent.tcp.pose.raw_pose

# Vector to object
tcp_to_obj = self.target_object.pose.p - self.agent.tcp.pose.p

# Transformation matrix
env.agent.tcp.pose.to_transformation_matrix()[0, :3, 1]  # closing direction
```

**Motion planning (Panda):**

```29:30:examples/motionplanning/panda/solutions/pick_cube.py
    # get transformation matrix of the tcp pose, is default batched and on torch
    target_closing = env.agent.tcp.pose.to_transformation_matrix()[0, :3, 1].cpu().numpy()
```

---

## 4. Default qpos (rest position) for Panda

```34:50:agents/robots/panda/panda.py
    keyframes = dict(
        rest=Keyframe(
            qpos=np.array(
                [
                    0.0,
                    np.pi / 8,
                    0,
                    -np.pi * 5 / 8,
                    0,
                    np.pi * 3 / 4,
                    np.pi / 4,
                    0.04,
                    0.04,
                ]
            ),
            pose=sapien.Pose(),
        )
    )
```

- 7 arm joints: `[0, π/8, 0, -5π/8, 0, 3π/4, π/4]`
- 2 gripper joints: `[0.04, 0.04]` (closed)

---

## 5. How `env.step(action)` works with delta pose control

1. **Action structure (Panda with gripper):**
   - `pd_ee_delta_pose`: `arm = [dx, dy, dz, drx, dry, drz]` + `gripper`
   - Concatenated: `[dx, dy, dz, drx, dry, drz, gripper]` → total 7 dims

2. **Controller behavior** (from `controllers.md`):

   - `arm_pd_ee_delta_pose`:
     - Target position: \(\bar{p}(t) = p(t) + a_p\)
     - Target rotation: \(\bar{R}(t) = R(t) \cdot e^{[a_R]_\times}\)
     - IK: \(\bar{q}(t) = IK(\bar{p}(t), \bar{R}(t))\)
   - Actions are deltas in meters and axis-angle (radians) in EE frame.

3. **Action flow:**

```235:246:examples/demo_manual_control_continuous.py
            action_dict = dict(
                base=base_action,
                arm=ee_action,
                body=body_action,
                gripper=gripper_action,
            )
            action_dict = common.to_tensor(action_dict)
            action = env.agent.controller.from_action_dict(action_dict)

            obs, reward, terminated, truncated, info = env.step(action)
```

---

## 6. Motion planning and EE trajectory

**Panda motion planning** uses `pd_joint_pos`, not `pd_ee_delta_pose`:

```48:56:examples/motionplanning/panda/run.py
    env = gym.make(
        env_id,
        ...
        control_mode="pd_joint_pos",
        ...
    )
```

Trajectory is planned in Cartesian space, then IK yields joint targets; the env uses joint position control to track it.

**Pose-to-EE examples:**

```43:56:examples/motionplanning/panda/solutions/pick_cube.py
    # -------------------------------------------------------------------------- #
    # Reach
    # -------------------------------------------------------------------------- #
    reach_pose = grasp_pose * sapien.Pose([0, 0, -0.05])
    planner.move_to_pose_with_screw(reach_pose)

    # -------------------------------------------------------------------------- #
    # Grasp
    # -------------------------------------------------------------------------- #
    planner.move_to_pose_with_screw(grasp_pose)
    planner.close_gripper()

    # -------------------------------------------------------------------------- #
    # Move to goal pose
```

Trajectory movement is via `planner.move_to_pose_with_screw(pose)` or `planner.move_to_pose_with_RRTConnect(pose)`; the planner outputs joint positions for `pd_joint_pos`.

---

## 7. Action dimension and bounds for `pd_ee_delta_pose`

**Controller config (Panda):**

```113:124:agents/robots/panda/panda.py
        arm_pd_ee_delta_pose = PDEEPoseControllerConfig(
            joint_names=self.arm_joint_names,
            pos_lower=-0.1,
            pos_upper=0.1,
            rot_lower=-0.1,
            rot_upper=0.1,
            ...
        )
```

**Action space:**

| Component | Dims | Bounds |
|-----------|------|--------|
| Arm (pd_ee_delta_pose) | 6 | pos: [-0.1, 0.1] m; rot: [-0.1, 0.1] rad |
| Gripper | 1 | [-1, 1] (open/close) |
| Total | 7 | — |

**Documentation** (`docs/source/user_guide/concepts/controllers.md`):

```149:156:docs/source/user_guide/concepts/controllers.md
- arm_pd_ee_delta_pos (3-dim): only control position ( $p$ ) without rotation ( $R$ ).
  ...
- arm_pd_ee_delta_pose (6-dim): both position ( $p$ ) and rotation ( $R$ ) are controlled. Rotation is represented as axis-angle in the end-effector frame.
```

---

## Summary

| Topic | Answer |
|-------|--------|
| **EE pose** | `agent.tcp.pose.p` (position), `agent.tcp.pose.raw_pose`, `to_transformation_matrix()` |
| **Default qpos** | `[0, π/8, 0, -5π/8, 0, 3π/4, π/4, 0.04, 0.04]` |
| **Action** | `[dx, dy, dz, drx, dry, drz, gripper]` (7 dims) |
| **Position bounds** | [-0.1, 0.1] m per axis |
| **Rotation bounds** | [-0.1, 0.1] rad axis-angle |
| **Target → action** | `pos_error = target_pos - agent.tcp.pose.p`; clip to max step 0.1 m |

---

