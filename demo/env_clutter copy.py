import os
from typing import Any, Dict, List, Union, Tuple, Optional
import numpy as np
import sapien
import torch
import cv2
import random
import sys

# ä¸å†éœ€è¦å¤–éƒ¨é…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨å†…éƒ¨SceneConfig

# è®ºæ–‡å±•ç¤ºåœºæ™¯ä¸éœ€è¦AnyGrasp
ANYGRASP_AVAILABLE = False

import mani_skill.envs.utils.randomization as randomization
from mani_skill import ASSET_DIR
from mani_skill.agents.robots import Fetch, Panda
from mani_skill.envs.sapien_env import BaseEnv
from mani_skill.sensors.camera import CameraConfig
from mani_skill.utils import sapien_utils
from mani_skill.utils.building import actors
from mani_skill.utils.building.actor_builder import ActorBuilder
from mani_skill.utils.io_utils import load_json
from mani_skill.utils.registration import register_env
from mani_skill.utils.scene_builder.table import TableSceneBuilder
from mani_skill.utils.structs import Actor, Pose
from mani_skill.utils.structs.types import GPUMemoryConfig, SimConfig

# æ–°å¢ï¼šIKå’Œæ§åˆ¶å™¨ç›¸å…³å¯¼å…¥
# from mani_skill.agents.controllers.pd_ee_pose import PDEEPoseController

# æ–°å¢ï¼šå¯¼å…¥SAPIENçº¦æŸç›¸å…³æ¨¡å—
import sapien.physx as physx


@register_env(
    "PaperStackingScene-v1",
    asset_download_ids=["ycb"],
    max_episode_steps=50,
)
class PaperStackingSceneEnv(BaseEnv):
    """
    **è®ºæ–‡å±•ç¤ºåœºæ™¯:**
    åŒ…å«12ä¸ªYCBç‰©ä½“çš„å¤æ‚å †å åœºæ™¯ï¼Œä»…ç”¨äºè®ºæ–‡é…å›¾å±•ç¤ºã€‚
    - ç›®æ ‡ç‰©ä½“O_iä½äºä¸­å±‚ï¼Œä¸Šæ–¹æœ‰é£é™©å­ç»“æ„
    
    **åœºæ™¯å¸ƒå±€:**
    - åº•å±‚(L0): 3-4ä¸ªæ”¯æ’‘ç‰©ä½“ï¼Œç¨³å®šçš„å¤§ç‰©ä½“
    - ä¸­å±‚(L1): ç›®æ ‡ç‰©ä½“O_iï¼Œè¢«éƒ¨åˆ†é®æŒ¡ä½†å¯è§
    - ä¸Šå±‚(L2-L3): é£é™©å­ç»“æ„ï¼Œä¸€ä¸ªç‰©ä½“ç›´æ¥å‹åœ¨O_iä¸Šï¼Œå…¶ä»–ç‰©ä½“å‹åœ¨å…¶ä¸Š
    - ä¸­æ€§ç‰©ä½“: 3ä¸ªä¸è§„åˆ™ç‰©ä½“ï¼Œä¸O_iæ— å…³ï¼Œç‹¬ç«‹åˆ†å¸ƒ
    
    **æ³¨æ„:** è¿™æ˜¯é™æ€å±•ç¤ºåœºæ™¯ï¼Œä¸åŒ…å«ä»»åŠ¡é€»è¾‘
    """
    
    SUPPORTED_REWARD_MODES = ["dense", "sparse"]
    SUPPORTED_ROBOTS = ["panda", "fetch"]
    agent: Union[Panda, Fetch]
    
    # åœºæ™¯å‚æ•° - è®ºæ–‡å±•ç¤ºç”¨å›ºå®šé…ç½®
    TOTAL_OBJECTS = 15  # 5ç§ç‰©ä½“æ¯ç§3ä¸ª
    
    # å¼ºåˆ¶ä½¿ç”¨å†…ç½®ç®€åŒ–é…ç½®ï¼Œé¿å…å¤–éƒ¨é…ç½®çš„å¤æ‚æ€§
    if False:  # ç¦ç”¨å¤–éƒ¨é…ç½®å¯¼å…¥
        from scene_config import SceneConfig
        print("ä½¿ç”¨å¤–éƒ¨scene_config.py")
    else:
        # å¦‚æœæ— æ³•å¯¼å…¥ï¼Œä½¿ç”¨ç®€åŒ–çš„å†…ç½®é…ç½®
        class SceneConfig:
            YCB_OBJECTS = {
                "002_master_chef_can": {"size": [0.106, 0.106, 0.142]},  # ä¸»å¨ç½å¤´
                "003_cracker_box": {"size": [0.16, 0.21, 0.07]},         # é¥¼å¹²ç›’
                "004_sugar_box": {"size": [0.09, 0.175, 0.044]},         # ç³–ç›’
                "006_mustard_bottle": {"size": [0.095, 0.095, 0.177]},   # èŠ¥æœ«ç“¶
                "008_pudding_box": {"size": [0.078, 0.109, 0.032]},      # å¸ƒä¸ç›’
                "009_gelatin_box": {"size": [0.028, 0.085, 0.114]},      # æ˜èƒ¶ç›’
                "010_potted_meat_can": {"size": [0.101, 0.051, 0.051]},  # ç½è£…è‚‰ç½å¤´
            }
            
            BALANCED_STACK_CONFIG = {
                # å»æ‰002å’Œ006ï¼Œå…¶ä»–æ¯ç§ç‰©ä½“3ä¸ªï¼Œæ€»å…±15ä¸ªç‰©ä½“çš„åˆ†æ•£å †å é…ç½®
                'objects': [
                    # 003_cracker_box - 3ä¸ª
                    '003_cracker_box',        # 1
                    '003_cracker_box',        # 2
                    '003_cracker_box',        # 3
                    # 004_sugar_box - 3ä¸ª
                    '004_sugar_box',          # 4 (ç›®æ ‡ç‰©ä½“O_i)
                    '004_sugar_box',          # 5
                    '004_sugar_box',          # 6
                    # 008_pudding_box - 3ä¸ª
                    '008_pudding_box',        # 7
                    '008_pudding_box',        # 8
                    '008_pudding_box',        # 9
                    # 009_gelatin_box - 3ä¸ª
                    '009_gelatin_box',        # 10
                    '009_gelatin_box',        # 11
                    '009_gelatin_box',        # 12
                    # 010_potted_meat_can - 3ä¸ª
                    '010_potted_meat_can',    # 13
                    '010_potted_meat_can',    # 14
                    '010_potted_meat_can',    # 15
                ],
                'target_object_index': 3,  # ç¬¬4ä¸ªç‰©ä½“ä½œä¸ºç›®æ ‡O_i
                'description': '15ä¸ªYCBç‰©ä½“çš„åˆ†æ•£å †å åœºæ™¯ï¼ˆ5ç§ç‰©ä½“å„3ä¸ªï¼‰'
            }
            
            CAMERA_CONFIGS = {
                'paper_presentation': {
                    'main_camera': {
                        'eye': [0.5, 0.5, 0.6],
                        'target': [-0.15, 0.0, 0.15],
                        'fov': np.pi / 3,
                        'resolution': (3840, 2160),
                    }
                }
            }
            
            PHYSICS_CONFIG = {
                'stabilization_steps': 100,
            }
            
            @classmethod
            def get_scene_config(cls, config_name='balanced'):
                return cls.BALANCED_STACK_CONFIG
            
            @classmethod
            def get_camera_config(cls, style='paper_presentation'):
                return cls.CAMERA_CONFIGS[style]
            
            @classmethod
            def validate_config(cls, config_name):
                config = cls.get_scene_config(config_name)
                all_objects = config['objects']
                
                total_objects = len(all_objects)
                unique_objects = len(set(all_objects))
                
                # ç»Ÿè®¡æ¯ç§ç‰©ä½“çš„æ•°é‡
                from collections import Counter
                object_counts = Counter(all_objects)
                
                print(f"é…ç½®éªŒè¯:")
                print(f"  æ€»ç‰©ä½“æ•°é‡: {total_objects}")
                print(f"  å”¯ä¸€ç‰©ä½“ç±»å‹: {unique_objects}")
                print(f"  ç‰©ä½“åˆ†å¸ƒ:")
                for obj_type, count in object_counts.items():
                    print(f"    {obj_type}: {count}ä¸ª")
                
                if total_objects != 15:
                    print(f"âŒ é”™è¯¯: ç‰©ä½“æ€»æ•°åº”ä¸º15ä¸ªï¼Œå½“å‰ä¸º{total_objects}ä¸ª")
                    return False
                    
                # æ£€æŸ¥æ¯ç§ç‰©ä½“æ˜¯å¦éƒ½æœ‰3ä¸ª
                for obj_type, count in object_counts.items():
                    if count != 3:
                        print(f"âŒ é”™è¯¯: ç‰©ä½“{obj_type}åº”è¯¥æœ‰3ä¸ªï¼Œå½“å‰ä¸º{count}ä¸ª")
                        return False
                        
                return True
            
            @classmethod
            def print_config_summary(cls, config_name):
                print(f"ä½¿ç”¨å†…ç½®é…ç½®: {config_name}")
                print("åŒ…å«12ä¸ªYCBç‰©ä½“çš„åˆ†å±‚å †å åœºæ™¯")
    
    # æ–°å¢ï¼šå¸ç›˜çº¦æŸç›¸å…³å¸¸é‡
    SUCTION_DISTANCE_THRESHOLD = 0.1  # å¸ç›˜æ¿€æ´»è·ç¦»é˜ˆå€¼ 
    SUCTION_STIFFNESS = 1e6  # å¸ç›˜çº¦æŸåˆšåº¦
    SUCTION_DAMPING = 1e4    # å¸ç›˜çº¦æŸé˜»å°¼
    
    # è®ºæ–‡å±•ç¤ºåœºæ™¯ä¸éœ€è¦AnyGraspé…ç½®
    
    def __init__(
        self,
        *args,
        robot_uids="panda",
        robot_init_qpos_noise=0.02,
        num_envs=1,
        scene_config="balanced",  # åœºæ™¯é…ç½®ç±»å‹
        **kwargs,
    ):
        self.robot_init_qpos_noise = robot_init_qpos_noise
        self.scene_config_name = scene_config
        
        # è·å–åœºæ™¯é…ç½®
        self.scene_config = self.SceneConfig.get_scene_config(scene_config)
        
        # éªŒè¯é…ç½®
        if not self.SceneConfig.validate_config(scene_config):
            raise ValueError(f"åœºæ™¯é…ç½® '{scene_config}' éªŒè¯å¤±è´¥")
        
        print(f"ğŸ“‹ ä½¿ç”¨åœºæ™¯é…ç½®: {scene_config}")
        self.SceneConfig.print_config_summary(scene_config)
        
        # ç¡®ä¿æ‰€æœ‰å‚æ•°æ­£ç¡®ä¼ é€’ç»™çˆ¶ç±»
        super().__init__(
            *args,
            robot_uids=robot_uids,
            num_envs=num_envs,
            **kwargs,
        )

    @property
    def _default_sim_config(self):
        return SimConfig(
            gpu_memory_config=GPUMemoryConfig(
                max_rigid_contact_count=2**21,
                max_rigid_patch_count=2**19
            )
        )

    @property
    def _default_sensor_configs(self):
        # è®ºæ–‡å±•ç¤ºç”¨ç›¸æœºé…ç½® - å±•ç¤ºæ•´ä½“å †å ç»“æ„
        camera_config = self.SceneConfig.get_camera_config('paper_presentation')
        main_cam = camera_config['main_camera']
        
        pose = sapien_utils.look_at(
            eye=main_cam['eye'], 
            target=main_cam['target']
        )
        
        return [
            CameraConfig(
                "base_camera",
                pose=pose,
                width=main_cam['resolution'][0],
                height=main_cam['resolution'][1],
                fov=main_cam['fov'],
                near=0.01,
                far=100,
            )
        ]

    @property
    def _default_human_render_camera_configs(self):
        pose = sapien_utils.look_at([0.6, 0.7, 0.6], [0.0, 0.2, 0.35])
        return CameraConfig(
            "render_camera", 
            pose=pose, 
            width=512, 
            height=512, 
            fov=1, 
            near=0.01, 
            far=100
        )

    def _load_agent(self, options: dict):
        super()._load_agent(options, sapien.Pose(p=[-0.615, 0, 0]))
        
    # å¸ç›˜çº¦æŸç³»ç»Ÿå®ç°
    def _create_suction_constraint(self, target_object: Actor, env_idx: int = 0) -> bool:
        """
        åˆ›å»ºå¸ç›˜çº¦æŸ
        
        Args:
            target_object: ç›®æ ‡ç‰©ä½“
            env_idx: ç¯å¢ƒç´¢å¼•ï¼ˆå¤šç¯å¢ƒæ”¯æŒï¼‰
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸåˆ›å»ºçº¦æŸ
        """
        if self.is_suction_active[env_idx]:
            print(f"ç¯å¢ƒ{env_idx}: å¸ç›˜å·²ç»æ¿€æ´»ï¼Œæ— æ³•åˆ›å»ºæ–°çº¦æŸ")
            return False
            
        # æ£€æŸ¥æ˜¯å¦ä¸ç‰©ä½“æ¥è§¦
        if not self._is_contacting_object(target_object, self.SUCTION_DISTANCE_THRESHOLD, env_idx):
            print(f"ç¯å¢ƒ{env_idx}: ç‰©ä½“è·ç¦»è¿‡è¿œï¼Œæ— æ³•æ¿€æ´»å¸ç›˜")
            return False
        
        try:
            # å¯¼å…¥Driveç±»
            from mani_skill.utils.structs.drive import Drive
            
            print(f"ç¯å¢ƒ{env_idx}: åˆ›å»ºå¸ç›˜çº¦æŸ: TCPé“¾æ¥ -> ç‰©ä½“ {target_object.name}")
            
            # ğŸ”§ ä¿®å¤ï¼šå®‰å…¨çš„å¤šç¯å¢ƒå¯¹è±¡é€‰æ‹©
            # 1. éªŒè¯ç›®æ ‡ç‰©ä½“çš„ç¯å¢ƒå½’å±
            target_scene_idxs = target_object._scene_idxs
            if len(target_scene_idxs) == 0:
                print(f"ç¯å¢ƒ{env_idx}: ç›®æ ‡ç‰©ä½“æ²¡æœ‰åœºæ™¯ç´¢å¼•")
                return False
            
            target_env_idx = target_scene_idxs[0].item()
            print(f"ç¯å¢ƒ{env_idx}: ç›®æ ‡ç‰©ä½“å®é™…å±äºç¯å¢ƒ{target_env_idx}")
            
            # éªŒè¯ç¯å¢ƒç´¢å¼•ä¸€è‡´æ€§
            if target_env_idx != env_idx:
                print(f"ç¯å¢ƒ{env_idx}: ç¯å¢ƒç´¢å¼•ä¸åŒ¹é…ï¼Œç›®æ ‡ç‰©ä½“å±äºç¯å¢ƒ{target_env_idx}")
                return False
            
            # 2. ğŸ”§ ä¿®å¤ï¼šé€šè¿‡scene_idxså®‰å…¨è·å–TCPå®ä½“
            tcp_objs = self.agent.tcp._objs
            tcp_scene_idxs = self.agent.tcp._scene_idxs
            
            # æ‰¾åˆ°å±äºtarget_env_idxç¯å¢ƒçš„TCPå¯¹è±¡
            tcp_mask = (tcp_scene_idxs == target_env_idx)
            if not tcp_mask.any():
                print(f"ç¯å¢ƒ{env_idx}: æ‰¾ä¸åˆ°å¯¹åº”ç¯å¢ƒçš„TCPå¯¹è±¡")
                return False
            
            tcp_indices = torch.where(tcp_mask)[0]
            if len(tcp_indices) == 0:
                print(f"ç¯å¢ƒ{env_idx}: TCPç´¢å¼•åˆ—è¡¨ä¸ºç©º")
                return False
                
            tcp_idx = tcp_indices[0].item()  # è·å–ç¬¬ä¸€ä¸ªåŒ¹é…çš„ç´¢å¼•
            tcp_entity = tcp_objs[tcp_idx].entity
            print(f"ç¯å¢ƒ{env_idx}: æ‰¾åˆ°TCPå¯¹è±¡ï¼Œç´¢å¼•={tcp_idx}ï¼Œç¯å¢ƒ={target_env_idx}")
            
            # 3. ğŸ”§ ä¿®å¤ï¼šå®‰å…¨è·å–ç›®æ ‡ç‰©ä½“å®ä½“
            if len(target_object._objs) == 0:
                print(f"ç¯å¢ƒ{env_idx}: ç›®æ ‡ç‰©ä½“æ²¡æœ‰å®ä½“å¯¹è±¡")
                return False
            
            # åœ¨å½“å‰è®¾è®¡ä¸­ï¼Œæ¯ä¸ªç‰©ä½“é€šå¸¸åªæœ‰ä¸€ä¸ªå®ä½“
            target_entity = target_object._objs[0]
            print(f"ç¯å¢ƒ{env_idx}: ç›®æ ‡ç‰©ä½“å®ä½“æ•°é‡={len(target_object._objs)}")
            
            print(f"ç¯å¢ƒ{env_idx}: ä½¿ç”¨TCPå®ä½“[ç´¢å¼•{tcp_idx}]å’Œç›®æ ‡å®ä½“åˆ›å»ºçº¦æŸ")
            
            # å…³é”®ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨SAPIENçš„create_driveæ–¹æ³•ï¼Œç»•è¿‡DriveåŒ…è£…å™¨çš„æ‰¹é‡å¤„ç†
            # è¿™æ ·å¯ä»¥é¿å…scene_idxså’Œbodiesç´¢å¼•ä¸åŒ¹é…çš„é—®é¢˜
            sub_scene = self.scene.sub_scenes[target_env_idx]
            physx_drive = sub_scene.create_drive(
                tcp_entity,           # TCPå®ä½“
                sapien.Pose(),        # çˆ¶ä½“æœ¬åœ°å§¿æ€ - ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨sapien.Pose()
                target_entity,        # ç›®æ ‡ç‰©ä½“å®ä½“
                sapien.Pose()         # å­ä½“æœ¬åœ°å§¿æ€ - ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨sapien.Pose()
            )

            # æ‰‹åŠ¨åˆ›å»ºDriveåŒ…è£…å™¨ä»¥ä¾¿åç»­ç®¡ç†
            constraint = Drive(
                _objs=[physx_drive],
                _scene_idxs=torch.tensor([target_env_idx], device=self.device),
                pose_in_child=sapien.Pose(),
                pose_in_parent=sapien.Pose(),
                scene=self.scene
            )
            
            # è®¾ç½®çº¦æŸå‚æ•°ä½¿å…¶è¡¨ç°ä¸ºå›ºå®šçº¦æŸï¼ˆç±»ä¼¼PyBulletçš„JOINT_FIXEDï¼‰
            # ç›´æ¥è°ƒç”¨åº•å±‚PhysxDriveComponentçš„æ–¹æ³•ï¼ˆè¿™äº›æ–¹æ³•æ²¡æœ‰@before_gpu_inité™åˆ¶ï¼‰
            try:
                # çº¿æ€§çº¦æŸï¼ˆX, Y, Zæ–¹å‘ï¼‰
                physx_drive.set_drive_property_x(stiffness=self.SUCTION_STIFFNESS, damping=self.SUCTION_DAMPING)
                physx_drive.set_drive_property_y(stiffness=self.SUCTION_STIFFNESS, damping=self.SUCTION_DAMPING)
                physx_drive.set_drive_property_z(stiffness=self.SUCTION_STIFFNESS, damping=self.SUCTION_DAMPING)
                print(f"ç¯å¢ƒ{env_idx}: âœ… å·²è®¾ç½®é©±åŠ¨å±æ€§")
            except Exception as drive_error:
                print(f"ç¯å¢ƒ{env_idx}: âŒ è®¾ç½®é©±åŠ¨å±æ€§å¤±è´¥: {drive_error}")
                return False
            
            # è®¾ç½®ä½ç½®é™åˆ¶æ¥æ¨¡æ‹Ÿå›ºå®šçº¦æŸ
            try:
                physx_drive.set_limit_x(0, 0)  # ä¸å…è®¸Xæ–¹å‘ç§»åŠ¨
                physx_drive.set_limit_y(0, 0)  # ä¸å…è®¸Yæ–¹å‘ç§»åŠ¨
                physx_drive.set_limit_z(0, 0)  # ä¸å…è®¸Zæ–¹å‘ç§»åŠ¨
                print(f"ç¯å¢ƒ{env_idx}: âœ… å·²è®¾ç½®ä½ç½®é™åˆ¶")
            except Exception as limit_error:
                print(f"ç¯å¢ƒ{env_idx}: âš ï¸ è®¾ç½®é™åˆ¶å¤±è´¥: {limit_error}")
                # ç»§ç»­æ‰§è¡Œï¼Œä»…ä½¿ç”¨é©±åŠ¨å±æ€§
            
            # å­˜å‚¨çº¦æŸ - ä½¿ç”¨ç¯å¢ƒç‰¹å®šçš„é”®
            constraint_key = f"{target_object.name}_env_{env_idx}"
            self.suction_constraints[constraint_key] = constraint
            self.is_suction_active[env_idx] = True
            self.current_suction_object[env_idx] = target_object
            
            print(f"ç¯å¢ƒ{env_idx}: âœ… å¸ç›˜çº¦æŸåˆ›å»ºæˆåŠŸ: {constraint_key}")
            return True
            
        except Exception as e:
            print(f"ç¯å¢ƒ{env_idx}: âŒ åˆ›å»ºå¸ç›˜çº¦æŸå¤±è´¥: {e}")
            import traceback
            print(f"ç¯å¢ƒ{env_idx}: è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            traceback.print_exc()
            return False

    def _remove_suction_constraint(self, env_idx: int = 0) -> bool:
        """
        ç§»é™¤å¸ç›˜çº¦æŸ
        
        Args:
            env_idx: ç¯å¢ƒç´¢å¼•ï¼ˆå¤šç¯å¢ƒæ”¯æŒï¼‰
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸç§»é™¤çº¦æŸ
        """
        if not self.is_suction_active[env_idx] or self.current_suction_object[env_idx] is None:
            #print("æ²¡æœ‰æ¿€æ´»çš„å¸ç›˜çº¦æŸéœ€è¦ç§»é™¤")
            return False
        
        try:
            # è·å–çº¦æŸå¯¹è±¡ - ä½¿ç”¨ç¯å¢ƒç‰¹å®šçš„é”®
            constraint_key = f"{self.current_suction_object[env_idx].name}_env_{env_idx}"
            if constraint_key in self.suction_constraints:
                constraint = self.suction_constraints[constraint_key]
                
                print(f"ç¯å¢ƒ{env_idx}: æ­£åœ¨ç§»é™¤å¸ç›˜çº¦æŸ: {constraint_key}")
                
                # å…³é”®ä¿®å¤ï¼šç›´æ¥æ“ä½œåº•å±‚PhysxDriveComponentå¯¹è±¡
                physx_drive = constraint._objs[0]  # è·å–åº•å±‚çš„PhysxDriveComponentå¯¹è±¡
                
                # æ–¹æ³•1: é€šè¿‡è®¾ç½®åˆšåº¦ä¸º0æ¥ç¦ç”¨çº¦æŸï¼ˆæœ€æœ‰æ•ˆï¼‰
                try:
                    print(f"ç¯å¢ƒ{env_idx}: è®¾ç½®çº¦æŸåˆšåº¦ä¸º0...")
                    physx_drive.set_drive_property_x(stiffness=0.0, damping=0.0)
                    physx_drive.set_drive_property_y(stiffness=0.0, damping=0.0)
                    physx_drive.set_drive_property_z(stiffness=0.0, damping=0.0)
                    print(f"ç¯å¢ƒ{env_idx}: âœ… æˆåŠŸç¦ç”¨çº¦æŸé©±åŠ¨å±æ€§")
                except Exception as disable_error:
                    print(f"ç¯å¢ƒ{env_idx}: âŒ ç¦ç”¨çº¦æŸé©±åŠ¨å±æ€§å¤±è´¥: {disable_error}")
                    return False
                
                # æ–¹æ³•2: é‡ç½®çº¦æŸé™åˆ¶ï¼ˆè¾…åŠ©æ–¹æ³•ï¼‰
                try:
                    print(f"ç¯å¢ƒ{env_idx}: é‡ç½®çº¦æŸé™åˆ¶...")
                    # è®¾ç½®éå¸¸å¤§çš„é™åˆ¶èŒƒå›´ï¼Œç›¸å½“äºå–æ¶ˆé™åˆ¶
                    physx_drive.set_limit_x(-1000, 1000)
                    physx_drive.set_limit_y(-1000, 1000)
                    physx_drive.set_limit_z(-1000, 1000)
                    print(f"ç¯å¢ƒ{env_idx}: âœ… æˆåŠŸé‡ç½®çº¦æŸé™åˆ¶")
                except Exception as limit_error:
                    print(f"ç¯å¢ƒ{env_idx}: âš ï¸ é‡ç½®çº¦æŸé™åˆ¶å¤±è´¥: {limit_error}")
                    # é™åˆ¶é‡ç½®å¤±è´¥ä¸å½±å“ä¸»è¦åŠŸèƒ½ï¼Œç»§ç»­æ‰§è¡Œ
                    pass
                
                # æ¸…ç†çº¦æŸå¼•ç”¨
                del self.suction_constraints[constraint_key]
                print(f"ç¯å¢ƒ{env_idx}: âœ… çº¦æŸå¼•ç”¨å·²æ¸…ç†: {constraint_key}")
            else:
                print(f"ç¯å¢ƒ{env_idx}: âš ï¸ æœªæ‰¾åˆ°çº¦æŸå¯¹è±¡: {constraint_key}")
                pass
            
            # åˆ é™¤è¢«å¸å–çš„ç‰©ä½“
            try:
                if self.current_suction_object[env_idx] is not None:
                    target_obj = self.current_suction_object[env_idx]
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ºGPUä»¿çœŸ
                    if self.scene.gpu_sim_enabled:
                        # GPUä»¿çœŸï¼šå°†ç‰©ä½“ç§»åŠ¨åˆ°è¿œå¤„ï¼ˆæ¨¡æ‹Ÿåˆ é™¤æ•ˆæœï¼‰
                        target_obj.set_pose(Pose.create_from_pq(p=[100.0, 100.0, 100.0]))
                        print(f"ç¯å¢ƒ{env_idx}: âœ… GPUä»¿çœŸæ¨¡å¼ - å°†ç‰©ä½“{target_obj.name}ç§»åŠ¨åˆ°è¿œå¤„")
                    else:
                        # CPUä»¿çœŸï¼šç‰©ç†åˆ é™¤ç‰©ä½“
                        target_obj.remove_from_scene()
                        print(f"ç¯å¢ƒ{env_idx}: âœ… CPUä»¿çœŸæ¨¡å¼ - å·²ä»åœºæ™¯ä¸­åˆ é™¤ç‰©ä½“{target_obj.name}")
                        
            except Exception as remove_error:
                print(f"ç¯å¢ƒ{env_idx}: âš ï¸ åˆ é™¤ç‰©ä½“å¤±è´¥: {remove_error}")
                # åˆ é™¤å¤±è´¥ä¸å½±å“ä¸»è¦æµç¨‹ï¼Œç»§ç»­æ‰§è¡Œ
                pass
            
            # é‡ç½®å¸ç›˜çŠ¶æ€
            self.is_suction_active[env_idx] = False
            self.current_suction_object[env_idx] = None
            
            print(f"ç¯å¢ƒ{env_idx}: âœ… å¸ç›˜çŠ¶æ€å·²é‡ç½®")
            
            return True
            
        except Exception as e:
            print(f"ç¯å¢ƒ{env_idx}: âŒ ç§»é™¤å¸ç›˜çº¦æŸå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
            # å³ä½¿ç§»é™¤å¤±è´¥ï¼Œä¹Ÿè¦é‡ç½®çŠ¶æ€
            self.is_suction_active[env_idx] = False
            self.current_suction_object[env_idx] = None
            return False

    def _is_contacting_object(self, target_object: Actor, threshold: float = 0.05, env_idx: int = 0) -> bool:
        """
        æ£€æµ‹TCPæ˜¯å¦ä¸ç‰©ä½“æ¥è§¦
        
        Args:
            target_object: ç›®æ ‡ç‰©ä½“
            threshold: è·ç¦»é˜ˆå€¼
            env_idx: ç¯å¢ƒç´¢å¼•ï¼ˆå¤šç¯å¢ƒæ”¯æŒï¼‰
            
        Returns:
            bool: æ˜¯å¦æ¥è§¦
        """
        try:
            # è®¡ç®—TCPåˆ°ç‰©ä½“çš„è·ç¦» - ä½¿ç”¨å¯¹åº”ç¯å¢ƒçš„TCPä½ç½®
            tcp_pos = self.agent.tcp.pose.p
            if tcp_pos.dim() > 1:
                if env_idx < tcp_pos.shape[0]:
                    tcp_pos = tcp_pos[env_idx]
                else:
                    tcp_pos = tcp_pos[0]
                    print(f"âš ï¸ ç¯å¢ƒ{env_idx}: TCPä½ç½®ç´¢å¼•è¶Šç•Œï¼Œä½¿ç”¨ç¯å¢ƒ0çš„ä½ç½®")
            
            # æ­£ç¡®è·å–å¤šç¯å¢ƒä¸‹çš„ç‰©ä½“ä½ç½®
            obj_pos = target_object.pose.p
            obj_pos = obj_pos[0]
            
            # è®¡ç®—è·ç¦»
            raw_distance = torch.linalg.norm(tcp_pos - obj_pos).item()
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ›´åˆç†çš„åŠå¾„ä¼°è®¡å€¼
            # TCPåŠå¾„çº¦2cmï¼Œç‰©ä½“å¹³å‡åŠå¾„çº¦3cmï¼Œæ€»è®¡çº¦5cm
            estimated_radius = 0.05  # 5cmçš„åŠå¾„ä¼°è®¡ï¼Œä¸_check_suction_grasp_successä¿æŒä¸€è‡´
            distance = raw_distance - estimated_radius
            
            print(f"ç¯å¢ƒ{env_idx}: TCPåˆ°ç‰©ä½“è·ç¦»æ£€æµ‹: åŸå§‹è·ç¦»={raw_distance:.4f}m, è°ƒæ•´åè·ç¦»={distance:.4f}m, é˜ˆå€¼={threshold:.4f}m, æ¥è§¦={'æ˜¯' if distance <= threshold else 'å¦'}")
            
            # æ£€æŸ¥æ˜¯å¦åœ¨æ¥è§¦é˜ˆå€¼å†…
            return distance <= threshold
            
        except Exception as e:
            print(f"ç¯å¢ƒ{env_idx}: æ£€æµ‹æ¥è§¦å¤±è´¥: {e}")
            return False

    def _check_suction_grasp_success(self, target_object: Actor, env_idx: int = 0) -> bool:
        """
        æ£€æŸ¥å¸ç›˜æŠ“å–æ˜¯å¦æˆåŠŸ
        
        Args:
            target_object: ç›®æ ‡ç‰©ä½“
            env_idx: ç¯å¢ƒç´¢å¼•ï¼ˆå¤šç¯å¢ƒæ”¯æŒï¼‰
            
        Returns:
            bool: æŠ“å–æ˜¯å¦æˆåŠŸ
        """
        try:
            # æ–¹æ³•1ï¼šæ£€æŸ¥å¸ç›˜çŠ¶æ€
            if (self.is_suction_active[env_idx] and 
                self.current_suction_object[env_idx] is not None and 
                self.current_suction_object[env_idx].name == target_object.name):
                
                # æ–¹æ³•2ï¼šæ£€æŸ¥ç‰©ä½“æ˜¯å¦ä»åœ¨TCPé™„è¿‘
                tcp_pos = self.agent.tcp.pose.p
                if tcp_pos.dim() > 1:
                    if env_idx < tcp_pos.shape[0]:
                        tcp_pos = tcp_pos[env_idx]
                    else:
                        tcp_pos = tcp_pos[0]
                        print(f"âš ï¸ ç¯å¢ƒ{env_idx}: TCPä½ç½®ç´¢å¼•è¶Šç•Œï¼Œä½¿ç”¨ç¯å¢ƒ0çš„ä½ç½®")
                
                obj_pos = target_object.pose.p
                obj_pos = obj_pos[0]
                
                raw_distance = torch.linalg.norm(tcp_pos - obj_pos).item()
                # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ä¸æ¥è§¦æ£€æµ‹ä¸€è‡´çš„åŠå¾„ä¼°è®¡
                estimated_radius = 0.05  # 5cmçš„åŠå¾„ä¼°è®¡ï¼Œä¸_is_contacting_objectä¿æŒä¸€è‡´
                distance = raw_distance - estimated_radius
                
                # è·ç¦»å°äº5cmè®¤ä¸ºæŠ“å–æˆåŠŸ
                success_threshold = 0.05
                success = distance < success_threshold
                
                print(f"ç¯å¢ƒ{env_idx}: æŠ“å–æˆåŠŸæ£€æµ‹ - åŸå§‹è·ç¦»={raw_distance:.4f}m, è°ƒæ•´åè·ç¦»={distance:.4f}m, æˆåŠŸ={'æ˜¯' if success else 'å¦'}")
                
                return success
            else:
                print(f"ç¯å¢ƒ{env_idx}: å¸ç›˜æœªæ¿€æ´»æˆ–ç‰©ä½“ä¸åŒ¹é…")
                return False
                
        except Exception as e:
            print(f"ç¯å¢ƒ{env_idx}: æ£€æŸ¥å¸ç›˜æŠ“å–æˆåŠŸå¤±è´¥: {e}")
            return False
    
    
    
    def _low_level_step(self, delta_pose: torch.Tensor):
        """å•æ­¥æ‰§è¡Œdelta poseï¼Œåªæ¨è¿›ä»¿çœŸï¼Œä¸èµ°ç¦»æ•£é€»è¾‘"""
        # è°ƒç”¨çˆ¶ç±»çš„stepæ–¹æ³•æ‰§è¡Œè¿ç»­åŠ¨ä½œ
        super().step(delta_pose)
    
    
    def _is_object_blocked(self, target_obj) -> bool:
        """
        ç®€åŒ–çš„é®æŒ¡æ£€æµ‹ï¼Œå¯¹åº”PyBulletçš„å°„çº¿æ£€æµ‹
        æ£€æŸ¥ç‰©ä½“ä¸Šæ–¹æ˜¯å¦æœ‰å…¶ä»–ç‰©ä½“
        """
        try:
            target_pos = target_obj.pose.p
            if target_pos.dim() > 1:
                target_pos = target_pos[0]
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–ç‰©ä½“åœ¨ç›®æ ‡ç‰©ä½“ä¸Šæ–¹
            for obj in self.all_objects:
                if obj == target_obj:
                    continue
                
                obj_pos = obj.pose.p
                if obj_pos.dim() > 1:
                    obj_pos = obj_pos[0]
                
                # æ£€æŸ¥æ˜¯å¦åœ¨ç›®æ ‡ç‰©ä½“ä¸Šæ–¹ï¼ˆxyå¹³é¢è·ç¦»å°äº5cmï¼Œzé«˜åº¦å¤§äºç›®æ ‡ç‰©ä½“ï¼‰
                xy_distance = torch.linalg.norm(obj_pos[:2] - target_pos[:2])
                if xy_distance < 0.05 and obj_pos[2] > target_pos[2]:
                    return True
            
            return False
            
        except Exception as e:
            #print(f"é®æŒ¡æ£€æµ‹å¤±è´¥: {e}")
            return False

    def _is_path_occluded_by_geometry(self, target_obj) -> bool:
        """
        å‡ ä½•é®æŒ¡æ£€æŸ¥ï¼šæ£€æŸ¥é¢„æŠ“å–è·¯å¾„æ˜¯å¦è¢«é˜»æŒ¡
        ä¼˜å…ˆä½¿ç”¨ç°æœ‰çš„ _is_object_blocked ä½œä¸ºå…œåº•
        
        Args:
            target_obj: ç›®æ ‡ç‰©ä½“
            
        Returns:
            bool: Trueè¡¨ç¤ºè¢«é®æŒ¡ï¼ŒFalseè¡¨ç¤ºè·¯å¾„ç•…é€š
        """
        try:
            # ä¼˜å…ˆä½¿ç”¨ç°æœ‰çš„ç®€åŒ–é®æŒ¡æ£€æµ‹
            return self._is_object_blocked(target_obj)
            
        except Exception as e:
            print(f"é®æŒ¡æ£€æŸ¥å¤±è´¥: {e}")
            return True  # å‡ºé”™æ—¶ä¿å®ˆè¿”å›è¢«é®æŒ¡

    def _is_supporting_others(self, target_obj) -> bool:
        """
        æ”¯æ’‘æ£€æŸ¥ï¼šæ£€æŸ¥ç›®æ ‡ç‰©ä½“æ˜¯å¦æ­£åœ¨æ”¯æ’‘å…¶ä»–ç‰©ä½“
        ä½¿ç”¨ManiSkillç‰©ç†æŸ¥è¯¢æ£€æµ‹æ¥è§¦åŠ›å’Œä½ç½®å…³ç³»
        
        Args:
            target_obj: ç›®æ ‡ç‰©ä½“
            
        Returns:
            bool: Trueè¡¨ç¤ºæ­£åœ¨æ”¯æ’‘å…¶ä»–ç‰©ä½“ï¼ŒFalseè¡¨ç¤ºæ²¡æœ‰æ”¯æ’‘å…³ç³»
        """
        try:
            target_pos = target_obj.pose.p
            if target_pos.dim() > 1:
                target_pos = target_pos[0]
            
            # æ£€æŸ¥ä¸æ‰€æœ‰å…¶ä»–ç‰©ä½“çš„æ¥è§¦å…³ç³»
            for other_obj in self.all_objects:
                if other_obj == target_obj:
                    continue
                
                other_pos = other_obj.pose.p
                if other_pos.dim() > 1:
                    other_pos = other_pos[0]
                
                # é¦–å…ˆæ£€æŸ¥ä½ç½®å…³ç³»ï¼šå…¶ä»–ç‰©ä½“æ˜¯å¦åœ¨ç›®æ ‡ç‰©ä½“ä¸Šæ–¹
                if other_pos[2] <= target_pos[2]:
                    continue  # å…¶ä»–ç‰©ä½“ä¸åœ¨ä¸Šæ–¹ï¼Œè·³è¿‡
                
                try:
                    # ä½¿ç”¨ManiSkillçš„æ¥è§¦åŠ›æŸ¥è¯¢
                    contact_forces = self.scene.get_pairwise_contact_forces(target_obj, other_obj)
                    
                    if contact_forces is not None:
                        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ¥è§¦åŠ›
                        force_magnitude = torch.linalg.norm(contact_forces, dim=-1)
                        
                        # å¦‚æœæœ‰æœ‰æ•ˆçš„æ¥è§¦åŠ›ï¼ˆé˜ˆå€¼è®¾ä¸º0.1Nï¼‰
                        if torch.any(force_magnitude > 0.1):
                            # æ£€æŸ¥åŠ›çš„æ–¹å‘ï¼šå‘ä¸‹çš„åŠ›è¡¨æ˜ç›®æ ‡ç‰©ä½“åœ¨æ”¯æ’‘å…¶ä»–ç‰©ä½“
                            if contact_forces.dim() > 1:
                                # å–ç¬¬ä¸€ä¸ªç¯å¢ƒçš„åŠ›å‘é‡
                                force_vec = contact_forces[0]
                            else:
                                force_vec = contact_forces
                            
                            # æ£€æŸ¥zæ–¹å‘çš„åŠ›ï¼šå¦‚æœåŠ›å‘ä¸‹ï¼ˆè´Ÿzæ–¹å‘ï¼‰ï¼Œè¯´æ˜ç›®æ ‡ç‰©ä½“åœ¨æ”¯æ’‘
                            if len(force_vec) >= 3 and force_vec[2] < -0.05:  # é˜ˆå€¼-0.05N
                                return True
                                
                except Exception as contact_error:
                    # æ¥è§¦æŸ¥è¯¢å¤±è´¥ï¼Œä½¿ç”¨å‡ ä½•ä½ç½®ä½œä¸ºå…œåº•åˆ¤æ®
                    # å¦‚æœå…¶ä»–ç‰©ä½“åœ¨ç›®æ ‡ç‰©ä½“æ­£ä¸Šæ–¹å¾ˆè¿‘çš„è·ç¦»ï¼ˆ<3cmï¼‰ï¼Œè®¤ä¸ºæœ‰æ”¯æ’‘å…³ç³»
                    xy_distance = torch.linalg.norm(other_pos[:2] - target_pos[:2])
                    z_distance = other_pos[2] - target_pos[2]
                    if xy_distance < 0.08 and z_distance < 0.03:  # xyè·ç¦»<8cm, zè·ç¦»<3cm
                        return True
            
            return False
            
        except Exception as e:
            print(f"æ”¯æ’‘æ£€æŸ¥å¤±è´¥: {e}")
            return True  # å‡ºé”™æ—¶ä¿å®ˆè¿”å›æ­£åœ¨æ”¯æ’‘

    def _get_ideal_world_grasp_pose(self, target_obj):
        """
        è®¡ç®—ç†æƒ³çš„ä¸–ç•Œåæ ‡ç³»æŠ“å–ä½å§¿
        ä»å±€éƒ¨åæ ‡ç³»çš„ç†æƒ³æŠ“å–å§¿æ€è½¬æ¢åˆ°ä¸–ç•Œåæ ‡ç³»
        
        Args:
            target_obj: ç›®æ ‡ç‰©ä½“
            
        Returns:
            tuple: (grasp_pose, pre_grasp_pose) - æŠ“å–ä½å§¿å’Œé¢„æŠ“å–ä½å§¿
        """
        try:
            # è·å–ç‰©ä½“åç§°ï¼Œå°è¯•åŒ¹é…å·²çŸ¥çš„ç†æƒ³æŠ“å–å§¿æ€
            obj_name = target_obj.name
            local_grasp_pose = None
            
            # å°è¯•ä»å·²çŸ¥ç‰©ä½“ç±»å‹ä¸­æŸ¥æ‰¾
            for key in self.ideal_grasp_poses_local:
                if key in obj_name:
                    local_grasp_pose = self.ideal_grasp_poses_local[key]
                    break
            
            # å¦‚æœæœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤æŠ“å–å§¿æ€
            if local_grasp_pose is None:
                local_grasp_pose = self.ideal_grasp_poses_local['default']
            
            # è·å–ç›®æ ‡ç‰©ä½“çš„ä¸–ç•Œä½å§¿
            target_world_pose = target_obj.pose
            if target_world_pose.p.dim() > 1:
                # å¤šç¯å¢ƒæƒ…å†µï¼Œå–ç¬¬ä¸€ä¸ªç¯å¢ƒçš„å§¿æ€
                target_world_pose = sapien.Pose(
                    p=target_world_pose.p[0],
                    q=target_world_pose.q[0]
                )
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šæ£€æŸ¥ç‰©ä½“ä½ç½®æ˜¯å¦åˆç†ï¼ˆé¿å…ç¬ç§»åçš„å¼‚å¸¸åæ ‡ï¼‰
            obj_pos = target_world_pose.p
            pos_magnitude = (obj_pos[0]**2 + obj_pos[1]**2 + obj_pos[2]**2)**0.5
            
            # å¦‚æœç‰©ä½“è·ç¦»åŸç‚¹è¶…è¿‡3ç±³ï¼Œè®¤ä¸ºæ˜¯å·²ç¬ç§»çš„ç‰©ä½“ï¼Œè·³è¿‡æŠ“å–
            if pos_magnitude > 3.0:
                print(f"âš ï¸ ç‰©ä½“ {target_obj.name} ä½ç½®å¼‚å¸¸ ({obj_pos})ï¼Œå¯èƒ½å·²è¢«ç¬ç§»ï¼Œè·³è¿‡æŠ“å–")
                # è¿”å›ä¸€ä¸ªå®‰å…¨çš„å·¥ä½œåŒºå†…ä½ç½®
                safe_pose = sapien.Pose(p=[0.0, 0.0, 0.5], q=[1, 0, 0, 0])
                safe_pre_pose = sapien.Pose(p=[0.0, 0.0, 0.58], q=[1, 0, 0, 0])
                return safe_pose, safe_pre_pose
            
            # è®¡ç®—ä¸–ç•Œåæ ‡ç³»ä¸‹çš„æŠ“å–ä½å§¿ï¼šworld_pose * local_pose
            world_grasp_pose = target_world_pose * local_grasp_pose
            
            # è®¡ç®—é¢„æŠ“å–ä½å§¿ï¼ˆåœ¨æŠ“å–ä½å§¿ä¸Šæ–¹å®‰å…¨è·ç¦»ï¼‰
            pre_grasp_pose = sapien.Pose(
                p=[world_grasp_pose.p[0], world_grasp_pose.p[1], world_grasp_pose.p[2] + 0.08],  # ä¸Šæ–¹8cm
                q=world_grasp_pose.q
            )
            
            return world_grasp_pose, pre_grasp_pose
            
        except Exception as e:
            print(f"è®¡ç®—ç†æƒ³æŠ“å–ä½å§¿å¤±è´¥: {e}")
            # å¤±è´¥æ—¶è¿”å›ç›®æ ‡ç‰©ä½“ä¸Šæ–¹çš„ç®€å•ä½å§¿
            obj_pos = target_obj.pose.p
            if obj_pos.dim() > 1:
                obj_pos = obj_pos[0]
            
            # ç®€å•çš„é¡¶æŠ“ä½å§¿ï¼ˆå‘ä¸‹ï¼‰
            grasp_pose = sapien.Pose(
                p=[obj_pos[0], obj_pos[1], obj_pos[2] + 0.05],
                q=[1, 0, 0, 0]  # æœä¸‹
            )
            pre_grasp_pose = sapien.Pose(
                p=[obj_pos[0], obj_pos[1], obj_pos[2] + 0.13],
                q=[1, 0, 0, 0]  # æœä¸‹
            )
            
            return grasp_pose, pre_grasp_pose


    def _load_scene(self, options: dict):
        # æ„å»ºæ¡Œé¢åœºæ™¯å¹¶åŠ è½½æ‰˜ç›˜
        self.scene_builder = TableSceneBuilder(
            self, robot_init_qpos_noise=self.robot_init_qpos_noise
        )
        self.scene_builder.build()
        
        # åŠ è½½æ‰˜ç›˜
        print("ğŸ“¦ åŠ è½½æ‰˜ç›˜...")
        self._load_tray()
        
        print("ğŸ—ï¸  å¼€å§‹æ„å»ºè®ºæ–‡å±•ç¤ºåœºæ™¯...")
        
        # åˆ›å»ºç‰©ä½“åˆ—è¡¨
        self.all_objects = []
        self.target_object = None  # ç›®æ ‡ç‰©ä½“O_i
        
        # ä¸ºæ¯ä¸ªç¯å¢ƒåˆ›å»ºåˆ†å±‚å †å åœºæ™¯
        for env_idx in range(self.num_envs):
            print(f"ğŸ“¦ æ„å»ºç¯å¢ƒ {env_idx} çš„å †å åœºæ™¯...")
            self._create_layered_stacking_scene(env_idx)
        
        # åˆå¹¶æ‰€æœ‰ç‰©ä½“
        if self.all_objects:
            self.merged_objects = Actor.merge(self.all_objects, name="stacked_objects")
            print(f"âœ… æˆåŠŸåˆ›å»º {len(self.all_objects)} ä¸ªç‰©ä½“çš„å †å åœºæ™¯")
        
        # ç‰©ç†ç¨³å®šåŒ–
        print("âš–ï¸  å¼€å§‹ç‰©ç†ç¨³å®šåŒ–...")
        self._stabilize_scene()

    def _create_layered_stacking_scene(self, env_idx: int):
        """
        ä¸ºæŒ‡å®šç¯å¢ƒåˆ›å»ºåˆ†æ•£å †å åœºæ™¯
        
        Args:
            env_idx: ç¯å¢ƒç´¢å¼•
        """
        config = self.scene_config
        objects_list = config['objects']
        target_index = config['target_object_index']
        
        # æ¡Œé¢é«˜åº¦
        table_height = 0.02  # TableSceneBuilderçš„æ ‡å‡†æ¡Œé¢é«˜åº¦
        
        # åˆ›å»ºåˆ†æ•£çš„ç‰©ä½“ä½ç½®è§„åˆ’
        object_positions = self._plan_scattered_positions(table_height, len(objects_list))
        
        # åˆ›å»ºæ‰€æœ‰ç‰©ä½“
        for i, obj_type in enumerate(objects_list):
            pos = object_positions[i]
            
            # ç¡®å®šç‰©ä½“åç§°åç¼€
            if i == target_index:
                name_suffix = "target_Oi"
            else:
                name_suffix = f"object_{i}"
            
            obj = self._create_object(obj_type, pos, env_idx, name_suffix)
            self.all_objects.append(obj)
            
            # è®¾ç½®å…¨å±€ç›®æ ‡ç‰©ä½“å¼•ç”¨ï¼ˆç¬¬ä¸€ä¸ªç¯å¢ƒçš„ç›®æ ‡ç‰©ä½“ï¼‰
            if env_idx == 0 and i == target_index:
                self.target_object = obj
        
        print(f"  âœ… ç¯å¢ƒ {env_idx}: åˆ›å»ºäº† {len(objects_list)} ä¸ªåˆ†æ•£å †å çš„ç‰©ä½“")
        
        return self.all_objects

    def _plan_scattered_positions(self, table_height: float, num_objects: int) -> List[np.ndarray]:
        """
        è§„åˆ’æ‰˜ç›˜å†…ç´§å¯†ä½†æœ‰é®æŒ¡çš„ç‰©ä½“ä½ç½®ï¼Œæ§åˆ¶å †å é«˜åº¦
        
        Args:
            table_height: æ¡Œé¢é«˜åº¦
            num_objects: ç‰©ä½“æ•°é‡
            
        Returns:
            ç‰©ä½“ä½ç½®åˆ—è¡¨
        """
        positions = []
        
        # æ‰˜ç›˜ä½ç½®å’Œå°ºå¯¸å‚æ•°
        tray_center_x = -0.2  # æ‰˜ç›˜ä¸­å¿ƒXåæ ‡
        tray_center_y = 0.0   # æ‰˜ç›˜ä¸­å¿ƒYåæ ‡
        tray_bottom_z = 0.02 + 0.02  # æ‰˜ç›˜åº•éƒ¨é«˜åº¦ + å°åç§»
        
        # æ‰˜ç›˜å†…å¯ç”¨åŒºåŸŸï¼ˆç•™å‡ºå®‰å…¨è¾¹è·ï¼‰
        safe_area_x = 0.32  # Xæ–¹å‘32cmï¼ˆæ‰˜ç›˜å†…éƒ¨çº¦36cmï¼Œç•™4cmè¾¹è·ï¼‰
        safe_area_y = 0.32  # Yæ–¹å‘32cmï¼ˆæ‰˜ç›˜å†…éƒ¨çº¦36cmï¼Œç•™4cmè¾¹è·ï¼‰
        
        # åˆ›å»ºå¯†é›†çš„ç½‘æ ¼å¸ƒå±€å®ç°ç´§å¯†å †å 
        grid_cols = 4  # 4åˆ—
        grid_rows = 4  # 4è¡Œ
        
        grid_spacing_x = safe_area_x / grid_cols
        grid_spacing_y = safe_area_y / grid_rows
        
        # ä¸ºæ¯ä¸ªç‰©ä½“åˆ†é…ç½‘æ ¼ä½ç½®
        grid_positions = []
        for row in range(grid_rows):
            for col in range(grid_cols):
                if len(grid_positions) >= num_objects:
                    break
                
                # åŸºç¡€ç½‘æ ¼ä½ç½®ï¼ˆç›¸å¯¹äºæ‰˜ç›˜ä¸­å¿ƒï¼‰
                base_x = tray_center_x + (col - grid_cols/2 + 0.5) * grid_spacing_x
                base_y = tray_center_y + (row - grid_rows/2 + 0.5) * grid_spacing_y
                
                # æ·»åŠ è¾ƒå°çš„éšæœºåç§»ï¼ˆ15%çš„ç½‘æ ¼é—´è·ï¼Œä¿æŒåœ¨æ‰˜ç›˜å†…ä½†å¢åŠ é‡å ï¼‰
                offset_x = np.random.uniform(-0.15 * grid_spacing_x, 0.15 * grid_spacing_x)
                offset_y = np.random.uniform(-0.15 * grid_spacing_y, 0.15 * grid_spacing_y)
                
                final_x = base_x + offset_x
                final_y = base_y + offset_y
                
                # ç¡®ä¿ä½ç½®åœ¨æ‰˜ç›˜å®‰å…¨åŒºåŸŸå†…
                final_x = np.clip(final_x, tray_center_x - safe_area_x/2, tray_center_x + safe_area_x/2)
                final_y = np.clip(final_y, tray_center_y - safe_area_y/2, tray_center_y + safe_area_y/2)
                
                grid_positions.append([final_x, final_y])
        
        # éšæœºæ‰“ä¹±ä½ç½®é¡ºåº
        np.random.shuffle(grid_positions)
        
        # ä¸ºæ¯ä¸ªç‰©ä½“åˆ†é…é«˜åº¦ - åœ¨æ‰˜ç›˜å†…æ§åˆ¶å †å é«˜åº¦
        for i in range(num_objects):
            x, y = grid_positions[i % len(grid_positions)]
            
            # æ‰˜ç›˜å†…ç´§å¯†å †å ç­–ç•¥ï¼Œæœ€å¤š2-3å±‚ï¼š
            # - åº•å±‚(0-8): æ‰˜ç›˜åº•éƒ¨æˆ–è½»å¾®å †å 
            # - ä¸­å±‚(9-12): é€‚ä¸­å †å ï¼Œå½¢æˆé®æŒ¡
            # - ä¸Šå±‚(13): å°‘é‡é¡¶å±‚ç‰©ä½“
            
            if i < 8:
                # åº•å±‚ - å¤§éƒ¨åˆ†ç‰©ä½“åœ¨åº•å±‚ï¼Œæœ‰äº›è½»å¾®å †å 
                if i < 4:
                    # å‰4ä¸ªç‰©ä½“ç›´æ¥æ”¾æ‰˜ç›˜åº•éƒ¨
                    z = tray_bottom_z + 0.02
                else:
                    # å4ä¸ªç‰©ä½“è½»å¾®å †å ï¼Œå½¢æˆé®æŒ¡
                    z = tray_bottom_z + 0.05 + np.random.uniform(0, 0.02)
            elif i < 12:
                # ä¸­å±‚ - é€‚åº¦å †å ï¼Œä¸è¶…è¿‡2å±‚é«˜åº¦
                z = tray_bottom_z + 0.09 + np.random.uniform(0, 0.03)
            else:
                # ä¸Šå±‚ - å°‘é‡é¡¶å±‚ç‰©ä½“ï¼Œæœ€é«˜ä¸è¶…è¿‡3å±‚
                z = tray_bottom_z + 0.13 + np.random.uniform(0, 0.02)
            
            positions.append(np.array([x, y, z]))
        
        return positions

    def _plan_object_positions(self, table_height: float) -> Dict:
        """
        è§„åˆ’ç‰©ä½“ä½ç½®ï¼Œå®ç°åˆ†å±‚å †å å¸ƒå±€
        
        Args:
            table_height: æ¡Œé¢é«˜åº¦
            
        Returns:
            å„å±‚ç‰©ä½“çš„ä½ç½®å­—å…¸
        """
        # å †å åŒºåŸŸä¸­å¿ƒï¼ˆæ¡Œé¢ä¸­å¤®åå‰ï¼‰
        stack_center = np.array([0.0, 0.0, table_height])
        
        # è·å–ç‰©ä½“å°ºå¯¸ä¿¡æ¯
        obj_sizes = {}
        for obj_type in (self.scene_config['support_objects'] + 
                        [self.scene_config['target_object']] +
                        [self.scene_config['direct_risk']] +
                        self.scene_config['indirect_risks'] +
                        self.scene_config['neutral_objects']):
            obj_sizes[obj_type] = self.SceneConfig.YCB_OBJECTS[obj_type]['size']
        
        positions = {}
        
        # 1. åº•å±‚æ”¯æ’‘ç‰©ä½“ä½ç½®ï¼ˆL0ï¼‰
        support_objects = self.scene_config['support_objects']
        positions['support'] = []
        
        # ç´§å‡‘æ’åˆ—åº•å±‚ç‰©ä½“
        base_positions = [
            np.array([-0.08, -0.08, 0]),  # å·¦å‰
            np.array([0.08, -0.08, 0]),   # å³å‰  
            np.array([0.0, 0.08, 0])      # åä¸­
        ]
        
        for i, obj_type in enumerate(support_objects):
            if i < len(base_positions):
                pos = stack_center + base_positions[i]
                pos[2] += obj_sizes[obj_type][2] / 2  # ç‰©ä½“åŠé«˜
                positions['support'].append(pos)
        
        # 2. ç›®æ ‡ç‰©ä½“O_iä½ç½®ï¼ˆL1 - ä¸­å±‚ï¼‰
        target_obj_type = self.scene_config['target_object']
        target_height = max([obj_sizes[obj][2] for obj in support_objects]) * 0.8  # 80%é‡å 
        
        positions['target'] = stack_center + np.array([0.0, -0.02, target_height + obj_sizes[target_obj_type][2]/2])
        
        # 3. ç›´æ¥é£é™©ç‰©ä½“ä½ç½®ï¼ˆL2 - å‹åœ¨O_iä¸Šï¼Œéƒ¨åˆ†é‡å ï¼‰
        direct_risk_type = self.scene_config['direct_risk']
        direct_risk_height = target_height + obj_sizes[target_obj_type][2] * 0.7  # 70%é‡å 
        
        # åç§»ä½ç½®å®ç°"ä¸å®Œå…¨é®æŒ¡"
        positions['direct_risk'] = stack_center + np.array([0.03, 0.02, direct_risk_height + obj_sizes[direct_risk_type][2]/2])
        
        # 4. é—´æ¥é£é™©ç‰©ä½“ä½ç½®ï¼ˆL3 - ä¸Šå±‚å­ç»“æ„ï¼‰
        positions['indirect_risks'] = []
        current_height = direct_risk_height + obj_sizes[direct_risk_type][2]
        
        for i, obj_type in enumerate(self.scene_config['indirect_risks']):
            if i == 0:
                # ç¬¬ä¸€ä¸ªé—´æ¥é£é™©ç‰©ä½“å‹åœ¨ç›´æ¥é£é™©ç‰©ä½“ä¸Š
                pos = positions['direct_risk'].copy()
                pos[2] = current_height + obj_sizes[obj_type][2]/2
                pos[0] += 0.02  # è½»å¾®åç§»
            else:
                # å…¶ä»–ç‰©ä½“å †å åœ¨ä¸Šé¢
                current_height += obj_sizes[self.scene_config['indirect_risks'][i-1]][2] * 0.8
                pos = positions['direct_risk'].copy()
                pos[2] = current_height + obj_sizes[obj_type][2]/2
                pos[0] += 0.01 * i  # é€æ¸åç§»
                pos[1] += 0.01 * i
            
            positions['indirect_risks'].append(pos)
        
        # 5. ä¸­æ€§ç‰©ä½“ä½ç½®ï¼ˆç‹¬ç«‹åˆ†å¸ƒï¼Œè¿œç¦»ä¸»å †å ï¼‰
        positions['neutral'] = []
        neutral_base_positions = [
            np.array([0.15, 0.15, 0]),    # å³åè§’
            np.array([-0.15, 0.12, 0]),   # å·¦å
            np.array([0.12, -0.15, 0])    # å³å‰è§’
        ]
        
        for i, obj_type in enumerate(self.scene_config['neutral_objects']):
            if i < len(neutral_base_positions):
                pos = stack_center + neutral_base_positions[i]
                pos[2] += obj_sizes[obj_type][2] / 2
                positions['neutral'].append(pos)
        
        return positions

    def _create_object(self, obj_type: str, position: np.ndarray, env_idx: int, name_suffix: str) -> Actor:
        """
        åˆ›å»ºå•ä¸ªç‰©ä½“
        
        Args:
            obj_type: YCBç‰©ä½“ç±»å‹
            position: ä¸–ç•Œåæ ‡ç³»ä½ç½®
            env_idx: ç¯å¢ƒç´¢å¼•
            name_suffix: åç§°åç¼€
            
        Returns:
            åˆ›å»ºçš„Actorå¯¹è±¡
        """
        # åˆ›å»ºActorBuilder
        builder = actors.get_actor_builder(self.scene, id=f"ycb:{obj_type}")
        
        # è®¾ç½®ä½ç½®å’Œå§¿æ€ - å¢åŠ æ›´å¤šéšæœºå€¾æ–œ
        # éšæœºç”Ÿæˆä¸‰ä¸ªè½´çš„æ—‹è½¬è§’åº¦
        roll = np.random.uniform(-np.pi/4, np.pi/4)   # Xè½´æ—‹è½¬ Â±45åº¦
        pitch = np.random.uniform(-np.pi/4, np.pi/4)  # Yè½´æ—‹è½¬ Â±45åº¦  
        yaw = np.random.uniform(-np.pi, np.pi)        # Zè½´æ—‹è½¬ Â±180åº¦ï¼ˆå®Œå…¨éšæœºæ–¹å‘ï¼‰
        
        # ä½¿ç”¨æ¬§æ‹‰è§’è½¬å››å…ƒæ•°ï¼Œè®©ç‰©ä½“æœ‰æ›´è‡ªç„¶çš„å€¾æ–œ
        from scipy.spatial.transform import Rotation
        rotation = Rotation.from_euler('xyz', [roll, pitch, yaw])
        quat = rotation.as_quat()  # [x, y, z, w] æ ¼å¼
        
        # è½¬æ¢ä¸ºsapiençš„å››å…ƒæ•°æ ¼å¼ [w, x, y, z]
        sapien_quat = [quat[3], quat[0], quat[1], quat[2]]
        
        initial_pose = sapien.Pose(p=position, q=sapien_quat)
        builder.initial_pose = initial_pose
        builder.set_scene_idxs([env_idx])
        
        # æ„å»ºç‰©ä½“
        obj_name = f"env_{env_idx}_{obj_type}_{name_suffix}"
        obj = builder.build(name=obj_name)
        
        return obj

    def _stabilize_scene(self):
        """
        ç‰©ç†ç¨³å®šåŒ–åœºæ™¯ - è®©ç‰©ä½“è‡ªç„¶æ²‰é™
        """
        physics_config = self.SceneConfig.PHYSICS_CONFIG
        stabilization_steps = physics_config['stabilization_steps']
        
        print(f"  ğŸ”„ è¿è¡Œ {stabilization_steps} æ­¥ç‰©ç†ä»¿çœŸè¿›è¡Œç¨³å®šåŒ–...")
        
        # è¿è¡Œç‰©ç†ä»¿çœŸè®©ç‰©ä½“ç¨³å®š
        for step in range(stabilization_steps):
            self.scene.step()
            
            # æ¯20æ­¥æ£€æŸ¥ä¸€æ¬¡ç¨³å®šæ€§
            if step % 20 == 0 and step > 0:
                all_static = True
                for obj in self.all_objects:
                    if hasattr(obj, 'is_static'):
                        if not obj.is_static(lin_thresh=0.01, ang_thresh=0.1):
                            all_static = False
                            break
                
                if all_static:
                    print(f"  âœ… åœºæ™¯åœ¨ç¬¬ {step} æ­¥è¾¾åˆ°ç¨³å®šçŠ¶æ€")
                    break
        
        print(f"  âœ… ç‰©ç†ç¨³å®šåŒ–å®Œæˆ")

    def _load_tray(self):
        """åŠ è½½æ‰˜ç›˜URDFæ–‡ä»¶"""
        # è·å–æ‰˜ç›˜URDFæ–‡ä»¶è·¯å¾„
        tray_urdf_path = "/home/linux/jzh/RL_Robot/assets/tray/traybox.urdf"
        
        if not os.path.exists(tray_urdf_path):
            raise FileNotFoundError(f"æ‰˜ç›˜URDFæ–‡ä»¶æœªæ‰¾åˆ°: {tray_urdf_path}")
        
        # åˆ›å»ºURDFåŠ è½½å™¨
        loader = self.scene.create_urdf_loader()
        
        # è®¾ç½®æ‰˜ç›˜çš„ç‰©ç†å±æ€§
        loader.set_material(static_friction=0.8, dynamic_friction=0.6, restitution=0.05)
        loader.fix_root_link = True  # å›ºå®šæ‰˜ç›˜ä¸åŠ¨
        loader.scale = 1.0  # ä¿æŒåŸå§‹å°ºå¯¸
        
        # è§£æURDFæ–‡ä»¶
        parsed_result = loader.parse(tray_urdf_path)
        
        # åªä½¿ç”¨ actor_builders æ–¹å¼
        actor_builders = parsed_result.get("actor_builders", [])
        
        if not actor_builders:
            raise ValueError("æ‰˜ç›˜URDFæ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°actor_builders")
        
        self.trays = []
        
        # ä½¿ç”¨ actor_builders åŠ è½½æ‰˜ç›˜
        for env_idx in range(self.num_envs):
            builder = actor_builders[0]
            # è®¾ç½®æ‰˜ç›˜ä½ç½® (æ”¾åœ¨æ¡Œé¢ä¸Šï¼Œæœºå™¨äººå‰æ–¹)
            tray_position = [-0.2, 0.0, 0.006]  # æ¡Œé¢é«˜åº¦åŠ ä¸Šæ‰˜ç›˜åº•éƒ¨åšåº¦
            builder.initial_pose = sapien.Pose(p=tray_position)
            builder.set_scene_idxs([env_idx])
            
            # ä½¿ç”¨ build_static åˆ›å»ºé™æ€æ‰˜ç›˜ï¼Œç¡®ä¿ä¸ä¼šç§»åŠ¨
            tray = builder.build_static(name=f"tray_{env_idx}")
            self.trays.append(tray)
        
        # åˆå¹¶æ‰€æœ‰æ‰˜ç›˜
        if self.trays:
            self.merged_trays = Actor.merge(self.trays, name="all_trays")
        
        #print(f"æˆåŠŸåŠ è½½æ‰˜ç›˜ï¼Œå…± {len(self.trays)} ä¸ª")

    def _generate_object_position_in_tray(self, stack_level=0):
        """åœ¨æ‰˜ç›˜å†…ç”Ÿæˆç‰©ä½“ä½ç½®"""
        # æ‰˜ç›˜ä¸­å¿ƒä½ç½®
        tray_center_x = -0.2
        tray_center_y = 0.0
        tray_bottom_z = 0.02 + 0.02  # æ‰˜ç›˜åº•éƒ¨ + å°åç§»
        
        # æ‰˜ç›˜è¾¹ç•Œè®¡ç®—ï¼ˆåŸºäºURDFæ–‡ä»¶ä¸­çš„è¾¹ç•Œå¢™ä½ç½®ï¼‰
        # è¾¹ç•Œå¢™åœ¨æ‰˜ç›˜ä¸­å¿ƒçš„Â±0.2ç±³å¤„
        # å®é™…å¯ç”¨ç©ºé—´ï¼šä»ä¸­å¿ƒå‘ä¸¤è¾¹å„0.18ç±³ï¼ˆç•™å‡ºå®‰å…¨è¾¹è·ï¼‰
        safe_spawn_area_x = 0.18
        safe_spawn_area_y = 0.18
        
        # åœ¨æ‰˜ç›˜å†…éšæœºç”Ÿæˆxyä½ç½®
        x = tray_center_x + random.uniform(-safe_spawn_area_x, safe_spawn_area_x)
        y = tray_center_y + random.uniform(-safe_spawn_area_y, safe_spawn_area_y)
        
        # å †å é«˜åº¦
        z = tray_bottom_z + stack_level * 0.04  # æ¯å±‚é«˜åº¦
        
        return x, y, z

    def _get_object_size(self, obj_type):
        """è·å–ç‰©ä½“çš„å¤§å°ä¿¡æ¯"""
        # åŸºäºYCBæ•°æ®é›†çš„å®é™…ç‰©ä½“å°ºå¯¸ï¼ˆå•ä½ï¼šç±³ï¼‰
        sizes = {
            #"003_cracker_box": [0.16, 0.21, 0.07],         # é¥¼å¹²ç›’: 16cm x 21cm x 7cm
            "004_sugar_box": [0.09, 0.175, 0.044],         # ç³–ç›’: 9cm x 17.5cm x 4.4cm
            "006_mustard_bottle": [0.095, 0.095, 0.177],   # èŠ¥æœ«ç“¶: 9.5cm x 9.5cm x 17.7cm
            "008_pudding_box": [0.078, 0.109, 0.032],      # å¸ƒä¸ç›’: 7.8cm x 10.9cm x 3.2cm
            #"009_gelatin_box": [0.028, 0.085, 0.114],      # æ˜èƒ¶ç›’: 2.8cm x 8.5cm x 11.4cm  
            #"010_potted_meat_can": [0.101, 0.051, 0.051],  # ç½è£…è‚‰ç½å¤´: 10.1cm x 5.1cm x 5.1cm
           
        }
        return sizes.get(obj_type, [0.05, 0.05, 0.05])

    def _sample_target_objects(self):
        """éšæœºé€‰æ‹©ç›®æ ‡ç‰©ä½“"""
        target_objects = []
        self.target_object_indices = []
        
        for env_idx in range(self.num_envs):
            if env_idx < len(self.selectable_objects) and self.selectable_objects[env_idx]:
                # éšæœºé€‰æ‹©ä¸€ä¸ªå¯é€‰æ‹©çš„ç‰©ä½“
                target_idx = random.randint(0, len(self.selectable_objects[env_idx]) - 1)
                target_obj = self.selectable_objects[env_idx][target_idx]
                target_objects.append(target_obj)
                self.target_object_indices.append(target_idx)
        
        if target_objects:
            self.target_object = Actor.merge(target_objects, name="target_object")

    def _calculate_exposed_area(self, env_idx):
        """è®¡ç®—ç‰©ä½“çš„æš´éœ²é¢ç§¯"""
        # è¿™é‡Œæ˜¯ç®€åŒ–çš„æš´éœ²é¢ç§¯è®¡ç®—
        # å®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦æ›´å¤æ‚çš„å‡ ä½•è®¡ç®—
        if env_idx < len(self.object_info):
            for i, obj_info in enumerate(self.object_info[env_idx]):
                # åŸºäºç‰©ä½“é«˜åº¦å’Œå‘¨å›´ç‰©ä½“æ•°é‡çš„ç®€å•ä¼°ç®—
                exposed_area = max(0.1, 1.0 - i * 0.1)  # è¶Šé«˜çš„ç‰©ä½“æš´éœ²é¢ç§¯è¶Šå¤§
                obj_info['exposed_area'] = exposed_area

    def _initialize_episode(self, env_idx: torch.Tensor, options: dict):
        """åˆå§‹åŒ–æ¯ä¸ªepisode - è®ºæ–‡å±•ç¤ºåœºæ™¯ï¼ˆé™æ€ï¼‰"""
        with torch.device(self.device):
            b = len(env_idx)
            self.scene_builder.initialize(env_idx)
            
            print("ğŸ¬ åˆå§‹åŒ–è®ºæ–‡å±•ç¤ºåœºæ™¯...")
            
            # é‡ç½®ç‰©ä½“åˆ°åˆå§‹å †å ä½ç½®
            if hasattr(self, 'merged_objects'):
                if b == self.num_envs:
                    self.merged_objects.pose = self.merged_objects.initial_pose
                else:
                    mask = torch.isin(self.merged_objects._scene_idxs, env_idx)
                    self.merged_objects.pose = self.merged_objects.initial_pose[mask]
            
            # é‡ç½®æœºå™¨äººåˆ°è§‚å¯Ÿä½ç½®ï¼ˆä¸é˜»æŒ¡è§†çº¿ï¼‰
            target_qpos = np.array([0.0, -0.785, 0.0, -2.356, 0.0, 1.571, 0.785, 0.04, 0.04])
            self.agent.reset(target_qpos)
            
            print("âœ… è®ºæ–‡å±•ç¤ºåœºæ™¯åˆå§‹åŒ–å®Œæˆ")

    def _get_obs_extra(self, info: Dict):
        """è·å–é¢å¤–è§‚æµ‹ä¿¡æ¯ - è®ºæ–‡å±•ç¤ºåœºæ™¯ï¼ˆç®€åŒ–ï¼‰"""
        batch_size = self.num_envs
        
        # é™æ€å±•ç¤ºåœºæ™¯çš„åŸºç¡€è§‚æµ‹
        obs = dict(
            tcp_pose=self.agent.tcp.pose.raw_pose,
        )
        
        if "state" in self.obs_mode:
            if hasattr(self, 'target_object') and self.target_object is not None:
                obs.update(
                    target_obj_pose=self.target_object.pose.raw_pose,
                    tcp_to_obj_pos=self.target_object.pose.p - self.agent.tcp.pose.p,
                )
            else:
                zero_pose = torch.zeros((batch_size, 7), device=self.device)
                zero_pos = torch.zeros((batch_size, 3), device=self.device)
                obs.update(
                    target_obj_pose=zero_pose,
                    tcp_to_obj_pos=zero_pos,
                )
            
            obs.update(
                num_objects=torch.tensor([len(self.all_objects)], device=self.device).repeat(batch_size),
            )
        
        return obs

    
    def _set_gripper_target(self, target_width: float, env_idx: int = None) -> torch.Tensor:
        """
        è®¾ç½®å¤¹çˆªç›®æ ‡å®½åº¦ï¼Œå‚è€ƒpandaé£æ ¼çš„å¤¹çˆªæ§åˆ¶
        
        Args:
            target_width: å¤¹çˆªç›®æ ‡å®½åº¦ (0.0=é—­åˆ, 0.04=å®Œå…¨æ‰“å¼€)
            env_idx: ç¯å¢ƒç´¢å¼•ï¼ŒNoneè¡¨ç¤ºæ‰€æœ‰ç¯å¢ƒ
            
        Returns:
            action: 7ç»´åŠ¨ä½œå‘é‡ï¼Œåªè®¾ç½®å¤¹çˆªéƒ¨åˆ†
        """
        # é™åˆ¶å¤¹çˆªå®½åº¦åœ¨æœ‰æ•ˆèŒƒå›´å†…ï¼ˆå‚è€ƒpanda.pyçš„é…ç½®ï¼‰
        target_width = max(0.0, min(0.04, target_width))
        
        # æ„å»º7ç»´åŠ¨ä½œå‘é‡ [dx, dy, dz, drx, dry, drz, gripper]
        if env_idx is not None:
            # å•ä¸ªç¯å¢ƒ
            action = torch.zeros(7, device=self.device, dtype=torch.float32)
            action[6] = target_width
        else:
            # æ‰€æœ‰ç¯å¢ƒ
            action = torch.zeros(self.num_envs, 7, device=self.device, dtype=torch.float32)
            action[:, 6] = target_width
        
        return action

    def _is_grasping_object(self, target_obj, env_idx: int = 0, min_force: float = 0.5) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦æˆåŠŸæŠ“å–ç‰©ä½“ï¼Œå‚è€ƒpanda.pyçš„is_graspingæ–¹æ³•
        åœ¨ç†æƒ³åŒ–æ¨¡å¼ä¸­ä¸»è¦ç”¨äºè°ƒè¯•å’ŒéªŒè¯
        
        Args:
            target_obj: ç›®æ ‡ç‰©ä½“
            env_idx: ç¯å¢ƒç´¢å¼•
            min_force: æœ€å°æ¥è§¦åŠ›é˜ˆå€¼
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸæŠ“å–
        """
        try:
            # è·å–æœºæ¢°è‡‚çš„fingeré“¾æ¥ï¼ˆå‡è®¾ä¸pandaç»“æ„ç›¸åŒï¼‰
            finger_links = []
            for link in self.agent.robot.get_links():
                if 'finger' in link.name:
                    finger_links.append(link)
            
            if len(finger_links) < 2:
                # å¦‚æœæ‰¾ä¸åˆ°fingeré“¾æ¥ï¼Œé€€å›åˆ°ç®€å•çš„è·ç¦»æ£€æŸ¥
                tcp_pos = self.agent.tcp.pose.p
                if tcp_pos.dim() > 1:
                    tcp_pos = tcp_pos[env_idx]
                
                obj_pos = target_obj.pose.p
                if obj_pos.dim() > 1:
                    obj_pos = obj_pos[env_idx]
                
                distance = torch.linalg.norm(tcp_pos - obj_pos).item()
                return distance < 0.1  # 10cmä»¥å†…è®¤ä¸ºæŠ“å–æˆåŠŸ
            
            # ä½¿ç”¨æ¥è§¦åŠ›æ£€æŸ¥ï¼ˆå‚è€ƒpanda.pyå®ç°ï¼‰
            total_force = 0.0
            for finger_link in finger_links:
                contact_forces = self.scene.get_pairwise_contact_forces(finger_link, target_obj)
                if contact_forces is not None:
                    force_magnitude = torch.linalg.norm(contact_forces, dim=-1)
                    if force_magnitude.dim() > 0:
                        total_force += force_magnitude[env_idx].item()
                    else:
                        total_force += force_magnitude.item()
            
            return total_force >= min_force
            
        except Exception as e:
            # å‡ºé”™æ—¶ä½¿ç”¨è·ç¦»æ£€æŸ¥ä½œä¸ºå…œåº•
            tcp_pos = self.agent.tcp.pose.p
            if tcp_pos.dim() > 1:
                tcp_pos = tcp_pos[env_idx]
            
            obj_pos = target_obj.pose.p
            if obj_pos.dim() > 1:
                obj_pos = obj_pos[env_idx]
            
            distance = torch.linalg.norm(tcp_pos - obj_pos).item()
            return distance < 0.1

    def step(self, action):
        """
        è®ºæ–‡å±•ç¤ºåœºæ™¯çš„stepæ–¹æ³• - é™æ€å±•ç¤ºï¼Œåªè°ƒç”¨çˆ¶ç±»step
        
        Args:
            action: è¿ç»­åŠ¨ä½œå‘é‡
        """
        # é™æ€å±•ç¤ºåœºæ™¯ï¼Œç›´æ¥è°ƒç”¨çˆ¶ç±»step
        return super().step(action)
    
    def _discrete_step(self, action):
        """
        å¤„ç†ç¦»æ•£åŠ¨ä½œçš„stepæ–¹æ³• - ä½¿ç”¨whileå¾ªç¯ç®¡ç†å¹¶è¡ŒFSM
        
        Args:
            action: è¦æŠ“å–çš„ç‰©ä½“ç´¢å¼•ï¼Œå½¢çŠ¶ä¸º(num_envs,)æˆ–æ ‡é‡
        """
        # ç¡®ä¿actionæ˜¯æ­£ç¡®çš„å½¢çŠ¶
        if isinstance(action, (int, np.integer)):
            # å•ä¸ªåŠ¨ä½œï¼Œå¤åˆ¶åˆ°æ‰€æœ‰ç¯å¢ƒ
            action = np.full(self.num_envs, action)
        elif isinstance(action, torch.Tensor):
            action = action.cpu().numpy()
        elif isinstance(action, np.ndarray):
            if action.shape == ():  # æ ‡é‡æ•°ç»„
                action = np.full(self.num_envs, action.item())
        
        # ç¡®ä¿actionæ˜¯æ­£ç¡®é•¿åº¦çš„æ•°ç»„
        if len(action) != self.num_envs:
            print(f"è­¦å‘Šï¼šåŠ¨ä½œé•¿åº¦{len(action)}ä¸ç¯å¢ƒæ•°é‡{self.num_envs}ä¸åŒ¹é…")
            action = np.full(self.num_envs, action[0] if len(action) > 0 else 0)
        
        # 1. ä¸ºç©ºé—²ç¯å¢ƒåˆ†é…æ–°ä»»åŠ¡
        for i in range(self.num_envs):
            if not self.env_busy[i]:
                pick = int(action[i])
                if pick >= 0 and pick < len(self.remaining_indices[i]):
                    # è·å–å®é™…çš„ç‰©ä½“ç´¢å¼•
                    target_idx = self.remaining_indices[i][pick]
                    self.env_target[i] = target_idx
                    self.remaining_indices[i].pop(pick)
                    self.env_stage[i] = 0
                    self.env_busy[i] = True
                    self.stage_tick[i] = 0
                    self.step_count[i] += 1
                    #print(f"ç¯å¢ƒ{i}: å¼€å§‹æ–°ä»»åŠ¡ - æŠ“å–ç‰©ä½“ç´¢å¼•{target_idx} (é€‰æ‹©{pick})")
        
        # 2. whileå¾ªç¯æ‰§è¡ŒFSMï¼Œç›´åˆ°æ‰€æœ‰ç¯å¢ƒå®Œæˆä»»åŠ¡
        max_fsm_steps = 2000  # é˜²æ­¢æ— é™å¾ªç¯çš„å®‰å…¨é™åˆ¶
        fsm_step_count = 0
        
        #print(f"å¼€å§‹FSMæ‰§è¡Œå¾ªç¯ - å¿™ç¢Œç¯å¢ƒ: {torch.sum(self.env_busy).item()}")
        
        while torch.any(self.env_busy) and fsm_step_count < max_fsm_steps:
            # ä¸ºæ‰€æœ‰ç¯å¢ƒè®¡ç®—å½“å‰FSMçŠ¶æ€å¯¹åº”çš„ä½çº§è¿ç»­åŠ¨ä½œ
            cmd = torch.zeros(self.num_envs, 7, device=self.device, dtype=torch.float32)
            active_envs = 0
            
            for i in range(self.num_envs):
                if self.env_busy[i]:
                    cmd[i] = self._pick_object_step(i)
                    active_envs += 1
            
            # æ‰¹å¤„ç†æ‰§è¡Œä¸€æ­¥ç‰©ç†ä»¿çœŸ - æ‰€æœ‰ç¯å¢ƒåŒæ­¥å‰è¿›
            super().step(cmd)
            fsm_step_count += 1
            
            # æ¯500æ­¥è¾“å‡ºä¸€æ¬¡è¿›åº¦ä¿¡æ¯ï¼ˆå‡å°‘è¾“å‡ºé¢‘ç‡ï¼‰
            if fsm_step_count % 500 == 0:
                busy_count = torch.sum(self.env_busy).item()
                print(f"FSMæ­¥éª¤ {fsm_step_count}: ä»æœ‰ {busy_count} ä¸ªç¯å¢ƒåœ¨æ‰§è¡Œä»»åŠ¡")
        
        # æ£€æŸ¥æ˜¯å¦å› ä¸ºè¶…æ—¶è€Œé€€å‡ºå¾ªç¯
        if fsm_step_count >= max_fsm_steps:
            print(f"âš ï¸ FSMæ‰§è¡Œè¾¾åˆ°æœ€å¤§æ­¥æ•°é™åˆ¶ ({max_fsm_steps})ï¼Œå¼ºåˆ¶ç»“æŸæ‰€æœ‰ä»»åŠ¡")
            # å¼ºåˆ¶ç»“æŸæ‰€æœ‰ä»»åŠ¡
            self.env_busy.fill_(False)
            for i in range(self.num_envs):
                if self.env_target[i] != -1:
                    self.env_target[i] = -1
        
        completed_envs = torch.sum(~self.env_busy).item()
        #print(f"FSMæ‰§è¡Œå®Œæˆ - æ€»æ­¥æ•°: {fsm_step_count}, å®Œæˆç¯å¢ƒæ•°: {completed_envs}")
        
        # 3. æ¸…ç†å·²å®Œæˆä»»åŠ¡çš„ç¯å¢ƒçŠ¶æ€
        for env_idx in range(self.num_envs):
            if not self.env_busy[env_idx] and self.env_target[env_idx] != -1:
                # é‡ç½®ç›®æ ‡
                old_target = self.env_target[env_idx].item()
                self.env_target[env_idx] = -1
                #print(f"ç¯å¢ƒ{env_idx}: ä»»åŠ¡å®Œæˆï¼Œé‡ç½®ç›®æ ‡ {old_target}")
        
        # 4. è®¡ç®—æœ€ç»ˆå¥–åŠ±å’Œè§‚æµ‹ - åŸºäºå®Œæ•´åŠ¨ä½œçš„æœ€ç»ˆç»“æœ
        info = self.get_info()
        obs = self.get_obs(info)
        reward = self.get_reward(obs=obs, action=action, info=info)
        
        # 5. æ£€æŸ¥ç»ˆæ­¢æ¡ä»¶
        terminated = torch.zeros(self.num_envs, dtype=torch.bool, device=self.device)
        truncated = torch.zeros(self.num_envs, dtype=torch.bool, device=self.device)
        
        # ä½¿ç”¨ info ä¸­çš„ success å’Œ fail çŠ¶æ€
        if "success" in info and "fail" in info:
            terminated = torch.logical_or(info["success"], info["fail"])
        elif "success" in info:
            terminated = info["success"].clone()
        elif "fail" in info:
            terminated = info["fail"].clone()
        
        return obs, reward, terminated, truncated, info
    
    def _pick_object_step(self, env_idx: int) -> torch.Tensor:
        """
        ç†æƒ³åŒ–æŠ“å–çŠ¶æ€æœº - æ¯æ¬¡è°ƒç”¨åªæ‰§è¡Œå½“å‰çŠ¶æ€çš„ä¸€å°æ­¥
        ä½¿ç”¨ç¥è°•é€»è¾‘ï¼šé®æŒ¡/æ”¯æ’‘æ£€æŸ¥é€šè¿‡åˆ™100%æˆåŠŸï¼Œå¦åˆ™100%å¤±è´¥
        
        Args:
            env_idx: ç¯å¢ƒç´¢å¼•
            
        Returns:
            action: è¯¥ç¯å¢ƒçš„è¿ç»­åŠ¨ä½œå‘é‡ [dx, dy, dz, drx, dry, drz, gripper]
        """
        stage = self.env_stage[env_idx].item()
        target_idx = self.env_target[env_idx].item()
        tick = self.stage_tick[env_idx].item()
        
        # åˆå§‹åŒ–åŠ¨ä½œå‘é‡
        action = torch.zeros(7, device=self.device, dtype=torch.float32)
        
        try:
            # éªŒè¯ç›®æ ‡ç´¢å¼•æœ‰æ•ˆæ€§
            if target_idx < 0 or env_idx >= len(self.selectable_objects) or target_idx >= len(self.selectable_objects[env_idx]):
                print(f"ç¯å¢ƒ{env_idx}: æ— æ•ˆç›®æ ‡ç´¢å¼• target_idx={target_idx}")
                self.env_busy[env_idx] = False
                return action
            
            # è·å–ç›®æ ‡ç‰©ä½“
            target_obj = self.selectable_objects[env_idx][target_idx]
            
            # è·å–å½“å‰TCPä½ç½®
            tcp_pos = self.agent.tcp.pose.p
            if tcp_pos.dim() > 1:
                tcp_pos = tcp_pos[env_idx] if env_idx < tcp_pos.shape[0] else tcp_pos[0]

            # ğŸ”§ è®°å½•åˆå§‹TCPä½ç½®ï¼ˆä»…åœ¨ç¬¬ä¸€æ¬¡åŠ¨ä½œæ—¶è®°å½•ï¼‰
            if hasattr(self, 'tcp_recorded') and not self.tcp_recorded[env_idx]:
                self.initial_tcp_positions[env_idx] = tcp_pos.clone().detach()
                self.tcp_recorded[env_idx] = True
                print(f"ç¯å¢ƒ{env_idx}: ğŸ“ è®°å½•åˆå§‹TCPä½ç½®: {self.initial_tcp_positions[env_idx].cpu().numpy()}")

            # æ ¹æ®æ˜¯å¦å¯ç”¨ç†æƒ³åŒ–ç¥è°•é€‰æ‹©ä¸åŒçš„FSMé€»è¾‘
            if self.use_ideal_oracle:
                return self._ideal_oracle_fsm(env_idx, stage, tick, target_obj, target_idx, tcp_pos, action)
            else:
                return self._legacy_suction_fsm(env_idx, stage, tick, target_obj, target_idx, tcp_pos, action)
                
        except Exception as e:
            print(f"çŠ¶æ€æœºæ‰§è¡Œé”™è¯¯ env={env_idx}, stage={stage}: {e}")
            self.env_busy[env_idx] = False
            return action

    def _ideal_oracle_fsm(self, env_idx: int, stage: int, tick: int, target_obj, target_idx: int, tcp_pos, action: torch.Tensor) -> torch.Tensor:
        """
        ç†æƒ³åŒ–ç¥è°•FSM: é¢„æµ‹æ€§çš„å®Œç¾æŠ“å–æµç¨‹
        Stage 0: é€»è¾‘æ£€æŸ¥ï¼ˆé®æŒ¡+æ”¯æ’‘ï¼‰
        Stage 1: ç§»åŠ¨åˆ°é¢„æŠ“å–ä½å§¿
        Stage 2: ä¸‹æ¢åˆ°æŠ“å–ä½å§¿å¹¶é—­åˆå¤¹çˆª
        Stage 3: æå‡ç‰©ä½“ï¼ˆç†æƒ³åŒ–è·Ÿéšï¼‰
        Stage 4: ç¬ç§»ç‰©ä½“åˆ°è¿œå¤„
        Stage 5: å›åˆ°åˆå§‹ä½ç½®å¹¶å¼ å¼€å¤¹çˆª
        """
        if stage == 0:
            # Stage 0: ç¥è°•é€»è¾‘æ£€æŸ¥
            if tick == 0:
                print(f"ç¯å¢ƒ{env_idx}: ğŸ”® ç¥è°•æ£€æŸ¥ - ç›®æ ‡ç‰©ä½“: {target_obj.name}")
                
                # ğŸ”§ é¦–å…ˆæ£€æŸ¥ç‰©ä½“ä½ç½®æ˜¯å¦å¼‚å¸¸ï¼ˆæ˜¯å¦å·²è¢«ç¬ç§»ï¼‰
                obj_pos = target_obj.pose.p
                if obj_pos.dim() > 1:
                    obj_pos = obj_pos[0]
                pos_magnitude = (obj_pos[0]**2 + obj_pos[1]**2 + obj_pos[2]**2)**0.5
                
                if pos_magnitude > 3.0:
                    print(f"ç¯å¢ƒ{env_idx}: âš ï¸ ç¥è°•åˆ¤å®šï¼šç‰©ä½“å·²è¢«ç¬ç§» ({obj_pos.cpu().numpy()}) -> è·³è¿‡æŠ“å–")
                    self.env_busy[env_idx] = False
                    return action
                
                # é®æŒ¡æ£€æŸ¥
                is_occluded = self._is_path_occluded_by_geometry(target_obj)
                if is_occluded:
                    print(f"ç¯å¢ƒ{env_idx}: âŒ ç¥è°•åˆ¤å®šï¼šè·¯å¾„è¢«é®æŒ¡ -> æŠ“å–å¿…å¤±è´¥")
                    self.env_busy[env_idx] = False
                    return action
                
                # æ”¯æ’‘æ£€æŸ¥
                is_supporting = self._is_supporting_others(target_obj)
                if is_supporting:
                    print(f"ç¯å¢ƒ{env_idx}: âŒ ç¥è°•åˆ¤å®šï¼šç‰©ä½“æ­£æ”¯æ’‘å…¶ä»–ç‰©ä½“ -> æŠ“å–å¿…å¤±è´¥")
                    self.env_busy[env_idx] = False
                    return action
                
                print(f"ç¯å¢ƒ{env_idx}: âœ… ç¥è°•åˆ¤å®šï¼šé€»è¾‘æ¡ä»¶é€šè¿‡ -> æŠ“å–å¿…æˆåŠŸ")
                
                # è®¡ç®—ç†æƒ³æŠ“å–ä½å§¿
                grasp_pose, pre_grasp_pose = self._get_ideal_world_grasp_pose(target_obj)
                
                # ä¿å­˜æŠ“å–ç›¸å…³ä¿¡æ¯
                self.stage_positions[env_idx] = torch.tensor(pre_grasp_pose.p, device=self.device)
                # å°†æŠ“å–ä½å§¿ä¿å­˜åˆ°é¢å¤–å­—æ®µï¼ˆå¦‚æœéœ€è¦ï¼‰
                if not hasattr(self, 'grasp_poses'):
                    self.grasp_poses = [None] * self.num_envs
                self.grasp_poses[env_idx] = grasp_pose
                
                print(f"ç¯å¢ƒ{env_idx}: é¢„æŠ“å–ä½ç½®: {pre_grasp_pose.p}")
            
            # ç›´æ¥è¿›å…¥ä¸‹ä¸€é˜¶æ®µï¼ˆé€»è¾‘æ£€æŸ¥åªéœ€1æ­¥ï¼‰
            self.env_stage[env_idx] = 1
            self.stage_tick[env_idx] = 0
        
        elif stage == 1:
            # Stage 1: ç§»åŠ¨åˆ°é¢„æŠ“å–ä½å§¿
            if tick == 0:
                print(f"ç¯å¢ƒ{env_idx}: Stage 1 - ç§»åŠ¨åˆ°é¢„æŠ“å–ä½ç½®")
            
            target_pos = self.stage_positions[env_idx]
            action[:3], reached = self._get_move_action(tcp_pos, target_pos, max_steps=100)
            
            if reached or tick >= 100:
                print(f"ç¯å¢ƒ{env_idx}: Stage 1å®Œæˆ - åˆ°è¾¾é¢„æŠ“å–ä½ç½®")
                # è®¾ç½®çœŸæ­£çš„æŠ“å–ä½ç½®
                if hasattr(self, 'grasp_poses') and self.grasp_poses[env_idx] is not None:
                    grasp_pos = self.grasp_poses[env_idx].p
                    self.stage_positions[env_idx] = torch.tensor(grasp_pos, device=self.device)
                
                self.env_stage[env_idx] = 2
                self.stage_tick[env_idx] = 0
            else:
                self.stage_tick[env_idx] += 1
            
            # ä¿æŒå¤¹çˆªå¼ å¼€
            action[6] = 0.04
        
        elif stage == 2:
            # Stage 2: ä¸‹æ¢åˆ°æŠ“å–ä½å§¿å¹¶é—­åˆå¤¹çˆª
            if tick == 0:
                print(f"ç¯å¢ƒ{env_idx}: Stage 2 - ä¸‹æ¢åˆ°æŠ“å–ä½ç½®å¹¶é—­åˆå¤¹çˆª")
            
            target_pos = self.stage_positions[env_idx]
            action[:3], reached = self._get_move_action(tcp_pos, target_pos, max_steps=60)
            
            # é€æ¸é—­åˆå¤¹çˆª
            if tick >= 20:  # å‰20æ­¥ç”¨äºç§»åŠ¨ï¼Œåé¢å¼€å§‹é—­åˆå¤¹çˆª
                action[6] = max(0.0, 0.04 - 0.04 * (tick - 20) / 20)  # é€æ¸ä»0.04é—­åˆåˆ°0.0
            else:
                action[6] = 0.04
            
            if reached or tick >= 60:
                # å»ºç«‹ç†æƒ³åŒ–è¿æ¥
                self.oracle_attached_object[env_idx] = target_obj
                print(f"ç¯å¢ƒ{env_idx}: Stage 2å®Œæˆ - ç†æƒ³åŒ–æŠ“å–è¿æ¥å»ºç«‹")
                
                # è®¾ç½®æå‡ç›®æ ‡ä½ç½®
                current_pos = self.stage_positions[env_idx].clone()
                current_pos[2] += 0.20  # ä¸Šå‡20cm
                self.stage_positions[env_idx] = current_pos
                
                self.env_stage[env_idx] = 3
                self.stage_tick[env_idx] = 0
            else:
                self.stage_tick[env_idx] += 1
        
        elif stage == 3:
            # Stage 3: æå‡ç‰©ä½“ï¼ˆç†æƒ³åŒ–è·Ÿéšï¼‰
            if tick == 0:
                print(f"ç¯å¢ƒ{env_idx}: Stage 3 - æå‡ç‰©ä½“")
            
            target_pos = self.stage_positions[env_idx]
            action[:3], reached = self._get_move_action(tcp_pos, target_pos, max_steps=80)
            
            # ä¿æŒå¤¹çˆªé—­åˆ
            action[6] = 0.0
            
            # ç†æƒ³åŒ–è·Ÿéšï¼šè®©ç‰©ä½“è·ŸéšTCPç§»åŠ¨
            if self.oracle_attached_object[env_idx] is not None:
                try:
                    # è·å–TCPå½“å‰ä½ç½®å¹¶è®¾ç½®ç‰©ä½“ä½ç½®
                    current_tcp_pos = tcp_pos.clone()
                    # ç‰©ä½“ä½ç½®ç¨ä½äºTCPï¼ˆæ¨¡æ‹Ÿè¢«æŠ“å–çš„æ•ˆæœï¼‰
                    object_target_pos = current_tcp_pos.clone()
                    object_target_pos[2] -= 0.05  # ç‰©ä½“åœ¨TCPä¸‹æ–¹5cm
                    
                    # ç›´æ¥è®¾ç½®ç‰©ä½“ä½ç½®ï¼ˆç†æƒ³åŒ–è·Ÿéšï¼‰
                    new_pose = sapien.Pose(p=object_target_pos.cpu().numpy())
                    self.oracle_attached_object[env_idx].set_pose(new_pose)
                except Exception as e:
                    print(f"ç¯å¢ƒ{env_idx}: ç†æƒ³åŒ–è·Ÿéšå¤±è´¥: {e}")
            
            if reached or tick >= 80:
                # æå‡å®Œæˆåï¼Œç­‰å¾…ä¸€å°ä¼šè®©ç‰©ä½“ç¨³å®š
                if tick >= 80 + 15:  # æå‡å®Œæˆåå†ç­‰å¾…15æ­¥ï¼ˆçº¦0.25ç§’ï¼‰
                    print(f"ç¯å¢ƒ{env_idx}: Stage 3å®Œæˆ - ç‰©ä½“æå‡å®Œæ¯•ï¼Œç­‰å¾…ç»“æŸ")
                    self.env_stage[env_idx] = 4
                    self.stage_tick[env_idx] = 0
                elif tick == 80:  # åˆšåˆ°è¾¾æ—¶çš„æç¤º
                    print(f"ç¯å¢ƒ{env_idx}: ç‰©ä½“æå‡åˆ°ä½ï¼Œç­‰å¾…ç¨³å®šä¸­...")
                    self.stage_tick[env_idx] += 1
                else:
                    # ç»§ç»­ç­‰å¾…ï¼Œä¿æŒç‰©ä½“è·Ÿéš
                    self.stage_tick[env_idx] += 1
            else:
                self.stage_tick[env_idx] += 1
        
        elif stage == 4:
            # Stage 4: ç¬ç§»ç‰©ä½“åˆ°è¿œå¤„ï¼ˆä¸å¼ å¼€å¤¹çˆªï¼‰
            if tick == 0:
                print(f"ç¯å¢ƒ{env_idx}: Stage 4 - ç¬ç§»ç‰©ä½“åˆ°è¿œå¤„")
                
                if self.oracle_attached_object[env_idx] is not None:
                    try:
                        # ç¬ç§»åˆ°è¿œå¤„ï¼ˆä¾‹å¦‚ (10, 10, 10)ï¼‰
                        far_pose = sapien.Pose(p=[10.0, 10.0, 10.0])
                        self.oracle_attached_object[env_idx].set_pose(far_pose)
                        print(f"ç¯å¢ƒ{env_idx}: âœ… ç‰©ä½“å·²ç¬ç§»åˆ°è¿œå¤„")
                        
                        # æ–­å¼€ç†æƒ³åŒ–è¿æ¥
                        self.oracle_attached_object[env_idx] = None
                    except Exception as e:
                        print(f"ç¯å¢ƒ{env_idx}: ç¬ç§»ç‰©ä½“å¤±è´¥: {e}")
                
                # ğŸ”§ å…³é”®ä¿®å¤ï¼šä½¿ç”¨åŠ¨æ€è®°å½•çš„çœŸå®åˆå§‹TCPä½ç½®
                if hasattr(self, 'initial_tcp_positions') and self.initial_tcp_positions[env_idx] is not None:
                    initial_pos = self.initial_tcp_positions[env_idx]
                    print(f"ç¯å¢ƒ{env_idx}: ä½¿ç”¨è®°å½•çš„åˆå§‹TCPä½ç½®: {initial_pos.cpu().numpy()}")
                else:
                    # å…œåº•ï¼šå¦‚æœæ²¡æœ‰è®°å½•åˆ°åˆå§‹ä½ç½®ï¼Œä½¿ç”¨å®‰å…¨é»˜è®¤ä½ç½®
                    initial_pos = torch.tensor([0.0, 0.0, 0.4], device=self.device)
                    print(f"ç¯å¢ƒ{env_idx}: âš ï¸ æœªæ‰¾åˆ°è®°å½•çš„åˆå§‹ä½ç½®ï¼Œä½¿ç”¨é»˜è®¤ä½ç½®")
                
                self.stage_positions[env_idx] = initial_pos
            
            # ç›´æ¥è¿›å…¥ä¸‹ä¸€é˜¶æ®µï¼ˆç¬ç§»åªéœ€1æ­¥ï¼‰
            self.env_stage[env_idx] = 5
            self.stage_tick[env_idx] = 0
            
            # ä¿æŒå¤¹çˆªé—­åˆ
            action[6] = 0.0
        
        elif stage == 5:
            # Stage 5: å›åˆ°åˆå§‹ä½ç½®å¹¶å¼ å¼€å¤¹çˆª
            if tick == 0:
                print(f"ç¯å¢ƒ{env_idx}: Stage 5 - å›åˆ°åˆå§‹ä½ç½®")
            
            target_pos = self.stage_positions[env_idx]
            action[:3], reached = self._get_move_action(tcp_pos, target_pos, max_steps=100)
            
            # åˆ°è¾¾åå¼ å¼€å¤¹çˆª
            if reached or tick >= 80:
                action[6] = 0.04  # å¼ å¼€å¤¹çˆª
            else:
                action[6] = 0.0   # ä¿æŒé—­åˆ
            
            if reached and tick >= 90:  # ç¡®ä¿æ—¢åˆ°è¾¾ä½ç½®åˆå¼ å¼€äº†å¤¹çˆª
                # å®Œæˆæ•´ä¸ªç†æƒ³åŒ–æµç¨‹
                self.env_busy[env_idx] = False
                self.grasped_objects[env_idx].append(target_idx)
                self.stage_tick[env_idx] = 0
                self.env_stage[env_idx] = 0  # é‡ç½®çŠ¶æ€
                print(f"ç¯å¢ƒ{env_idx}: âœ… ç†æƒ³åŒ–æŠ“å–æµç¨‹å®Œæˆ - {target_obj.name}")
            else:
                self.stage_tick[env_idx] += 1
        
        else:
            # æœªçŸ¥çŠ¶æ€ï¼Œç»“æŸæµç¨‹
            self.env_busy[env_idx] = False
        
        # å§¿æ€æ§åˆ¶ï¼šä¿æŒå‚ç›´å‘ä¸‹
        action[3:6] = 0.0
        
        return action

    def _legacy_suction_fsm(self, env_idx: int, stage: int, tick: int, target_obj, target_idx: int, tcp_pos, action: torch.Tensor) -> torch.Tensor:
        """
        ä¼ ç»Ÿå¸ç›˜FSMï¼ˆä¿ç•™å…¼å®¹æ€§ï¼‰
        """
        # è¿™é‡Œä¿ç•™åŸæœ‰çš„å¸ç›˜é€»è¾‘ä½œä¸ºfallback
        print(f"ç¯å¢ƒ{env_idx}: ä½¿ç”¨ä¼ ç»Ÿå¸ç›˜æ¨¡å¼ï¼ˆç†æƒ³åŒ–ç¥è°•æœªå¯ç”¨ï¼‰")
        
        # è·å–ç›®æ ‡ç‰©ä½“ä½ç½®
        obj_pos = target_obj.pose.p[0].cpu().numpy()
        
        if stage == 0:
            # ç§»åŠ¨åˆ°ç‰©ä½“ä¸Šæ–¹
            if tick == 0:
                target_pos = obj_pos.copy()
                target_pos[2] += 0.15  # ä¸Šæ–¹15cm
                self.stage_positions[env_idx] = torch.tensor(target_pos, device=self.device)
            
            target_pos = self.stage_positions[env_idx]
            action[:3], reached = self._get_move_action(tcp_pos, target_pos, max_steps=150)
            
            if reached or tick >= 150:
                self.env_stage[env_idx] = 1
                self.stage_tick[env_idx] = 0
            else:
                self.stage_tick[env_idx] += 1
        
        # å…¶ä»–stageçš„ä¼ ç»Ÿé€»è¾‘...ï¼ˆç®€åŒ–ç‰ˆï¼Œå¦‚éœ€å®Œæ•´ç‰ˆå¯ç»§ç»­æ·»åŠ ï¼‰
        else:
            self.env_busy[env_idx] = False
        
        action[3:6] = 0.0  # å§¿æ€æ§åˆ¶
        action[6] = 0.0   # å¤¹çˆªé—­åˆ
        
        return action
    
    def _get_move_action(self, current_pos: torch.Tensor, target_pos: torch.Tensor, 
                        max_steps: int = 100) -> Tuple[torch.Tensor, bool]:
        """
        è·å–ç§»åŠ¨åŠ¨ä½œå’Œæ˜¯å¦åˆ°è¾¾ç›®æ ‡
        
        Args:
            current_pos: å½“å‰ä½ç½®
            target_pos: ç›®æ ‡ä½ç½®
            max_steps: æœ€å¤§æ­¥æ•°ï¼ˆç”¨äºåˆ¤æ–­è¶…æ—¶ï¼‰
            
        Returns:
            action: ä½ç½®åŠ¨ä½œ [dx, dy, dz]
            reached: æ˜¯å¦åˆ°è¾¾ç›®æ ‡
        """
        if isinstance(target_pos, np.ndarray):
            target_pos = torch.tensor(target_pos, device=self.device, dtype=torch.float32)
        
        # è®¡ç®—ä½ç½®è¯¯å·®
        pos_error = target_pos - current_pos
        current_distance = torch.linalg.norm(pos_error).item()
        
        # åˆ¤æ–­æ˜¯å¦åˆ°è¾¾ - æ”¾å®½é˜ˆå€¼åˆ°6cmï¼ˆé¿å…Stage 5æ”¶æ•›é—®é¢˜ï¼‰
        reached = current_distance < 0.06
        
        if reached:
            print(f"_get_move_action: å·²åˆ°è¾¾ç›®æ ‡ï¼Œè·ç¦»={current_distance:.4f}m")
            return torch.zeros(3, device=self.device, dtype=torch.float32), True
        
        # è®¡ç®—ç§»åŠ¨åŠ¨ä½œ
        max_controller_step = 0.1  # æ§åˆ¶å™¨æ”¯æŒçš„æœ€å¤§å¢é‡ï¼š10cm
        
        # ä¼˜åŒ–æ­¥é•¿ç­–ç•¥ - æé«˜æ”¶æ•›é€Ÿåº¦
        if current_distance > 0.15:
            scale_factor = 1.0  # ä½¿ç”¨100%çš„æ§åˆ¶å™¨èƒ½åŠ›
        elif current_distance > 0.10:
            scale_factor = 0.95  # ç¨å¾®å‡é€Ÿ
        elif current_distance > 0.05:
            scale_factor = 0.8  # ä¸­ç­‰é€Ÿåº¦
        else:
            scale_factor = 0.7  # æé«˜ç²¾ç»†æ§åˆ¶é€Ÿåº¦ï¼ˆä»0.5æå‡åˆ°0.7ï¼‰
        
        actual_max_step = max_controller_step * scale_factor
        
        # å½’ä¸€åŒ–ä½ç½®è¯¯å·®
        pos_error_norm = torch.linalg.norm(pos_error)
        if pos_error_norm > actual_max_step:
            action = (pos_error / pos_error_norm) * actual_max_step
        else:
            action = pos_error
        
        #print(f"_get_move_action: è·ç¦»={current_distance:.4f}m, åŠ¨ä½œ={action.cpu().numpy()}, scale_factor={scale_factor}")
        
        return action, False
    
    def _get_failed_step_result(self):
        """è·å–å¤±è´¥æ­¥éª¤çš„ç»“æœ"""
        # æƒ©ç½šæ€§å¥–åŠ± - è½¬æ¢ä¸ºtorch.Tensor
        reward = torch.tensor([-1.0], device=self.device, dtype=torch.float32)
        
        # ä¸ç»ˆæ­¢ï¼Œè®©æ™ºèƒ½ä½“å­¦ä¹  - è½¬æ¢ä¸ºtorch.Tensor
        terminated = torch.tensor([False], device=self.device, dtype=torch.bool)
        truncated = torch.tensor([False], device=self.device, dtype=torch.bool)
        
        # è·å–å½“å‰è§‚æµ‹
        info = self.evaluate()
        info.update({
            'success': False,
            'displacement': 0.0,
            'remaining_objects': sum(len(env_remaining) for env_remaining in self.remaining_indices),
            'grasped_objects': sum(len(env_grasped) for env_grasped in self.grasped_objects),
        })
        
        obs = self._get_obs_extra(info)
        
        return obs, reward, terminated, truncated, info



    @property
    def discrete_action_space(self):
        """è·å–ç¦»æ•£åŠ¨ä½œç©ºé—´"""
        if self.use_discrete_action:
            import gymnasium as gym
            return gym.spaces.Discrete(self.MAX_N)
        else:
            return None

    def evaluate(self):
        """è¯„ä¼°ä»»åŠ¡å®Œæˆæƒ…å†µ - è®ºæ–‡å±•ç¤ºåœºæ™¯ï¼ˆé™æ€ï¼‰"""
        # é™æ€å±•ç¤ºåœºæ™¯ï¼Œå§‹ç»ˆè¿”å›æœªå®ŒæˆçŠ¶æ€
        success = torch.zeros(self.num_envs, device=self.device, dtype=bool)
        fail = torch.zeros(self.num_envs, device=self.device, dtype=bool)
        is_grasped = torch.zeros(self.num_envs, device=self.device, dtype=bool)
        is_robot_static = torch.ones(self.num_envs, device=self.device, dtype=bool)  # æœºå™¨äººä¿æŒé™æ­¢
        is_obj_placed = torch.zeros(self.num_envs, device=self.device, dtype=bool)
        
        return {
            "success": success,
            "fail": fail,
            "is_obj_placed": is_obj_placed,
            "is_robot_static": is_robot_static,
            "is_grasped": is_grasped,
        }

    def _calculate_other_objects_displacement(self):
        """è®¡ç®—å…¶ä»–ç‰©ä½“çš„ä½ç§»è·ç¦»"""
        total_displacement = torch.zeros(self.num_envs, device=self.device)
        
        for env_idx in range(self.num_envs):
            displacement = 0.0
            obj_count = 0
            
            for i, obj in enumerate(self.all_objects):
                if hasattr(obj, '_scene_idxs') and len(obj._scene_idxs) > 0:
                    if obj._scene_idxs[0] == env_idx:
                        # è·³è¿‡ç›®æ ‡ç‰©ä½“
                        if hasattr(self, 'target_object_indices') and env_idx < len(self.target_object_indices):
                            if i == self.target_object_indices[env_idx]:
                                continue
                        
                        # è®¡ç®—ä½ç§»
                        if hasattr(self, 'initial_object_positions') and env_idx < len(self.initial_object_positions):
                            if obj_count < len(self.initial_object_positions[env_idx]):
                                initial_pos = self.initial_object_positions[env_idx][obj_count]
                                current_pos = obj.pose.p
                                displacement += torch.linalg.norm(current_pos - initial_pos)
                                obj_count += 1
            
            total_displacement[env_idx] = displacement
        
        return total_displacement

    def compute_dense_reward(self, obs: Any, action: torch.Tensor, info: Dict):
        """è®¡ç®—å¯†é›†å¥–åŠ± - è®ºæ–‡å±•ç¤ºåœºæ™¯ï¼ˆé™æ€ï¼Œæ— å¥–åŠ±ï¼‰"""
        return torch.zeros(self.num_envs, device=self.device)
    
    def _compute_discrete_action_reward(self, info: Dict):
        """è®¡ç®—ç¦»æ•£åŠ¨ä½œæ¨¡å¼çš„å¥–åŠ± - åŸºäºå®Œæ•´åŠ¨ä½œçš„æœ€ç»ˆç»“æœ
        
        æ³¨æ„ï¼šåœ¨æ–°æ¶æ„ä¸‹ï¼Œæ¯ä¸ªRLæ­¥éª¤å¯¹åº”ä¸€ä¸ªå®Œæ•´çš„æŠ“å–åŠ¨ä½œï¼Œ
        å¥–åŠ±åŸºäºè¯¥åŠ¨ä½œçš„æœ€ç»ˆç»“æœè®¡ç®—ï¼Œæ›´ç®€æ´ä¸”æ˜“äºæ”¶æ•›
        """
        reward = torch.zeros(self.num_envs, device=self.device)
        
        # å¥–åŠ±ç³»æ•° - é’ˆå¯¹å®Œæ•´åŠ¨ä½œä¼˜åŒ–
        R_success = 3.0      # æˆåŠŸæŠ“å–ä¸€ä¸ªç‰©ä½“çš„å¥–åŠ±
        R_complete = 15.0    # å®Œæˆæ‰€æœ‰ç‰©ä½“çš„é¢å¤–å¥–åŠ±
        R_failure = -0.5     # æŠ“å–å¤±è´¥çš„æƒ©ç½š
        w_disp = 0.8         # ä½ç§»æƒ©ç½šæƒé‡
        
        for env_idx in range(self.num_envs):
            current_grasped = len(self.grasped_objects[env_idx])
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„æˆåŠŸæŠ“å–
            if not hasattr(self, '_prev_grasped_count'):
                self._prev_grasped_count = [0] * self.num_envs
            
            prev_grasped = self._prev_grasped_count[env_idx]
            
            if current_grasped > prev_grasped:
                # æˆåŠŸæŠ“å–äº†æ–°ç‰©ä½“
                new_grasps = current_grasped - prev_grasped
                reward[env_idx] += R_success * new_grasps
                
                # æ£€æŸ¥æ˜¯å¦å®Œæˆæ‰€æœ‰ç‰©ä½“
                if current_grasped == self.total_objects_per_env:
                    reward[env_idx] += R_complete
                    
            # elif hasattr(self, 'step_count') and self.step_count[env_idx] > prev_grasped:
            #     # æœ‰æŠ“å–å°è¯•ä½†æ²¡æœ‰æˆåŠŸï¼ˆstep_countå¢åŠ ä½†grasped_countæ²¡å˜ï¼‰
            #     reward[env_idx] += R_failure
            
            # # ç®€åŒ–çš„ä½ç§»æƒ©ç½š
            # other_displacement = self._calculate_other_objects_displacement()
            # if env_idx < len(other_displacement):
            #     # å°†ä½ç§»æƒ©ç½šé™åˆ¶åœ¨åˆç†èŒƒå›´å†…
            #     displacement_penalty = torch.clamp(other_displacement[env_idx] * w_disp, 0, 2.0)
            #     reward[env_idx] -= displacement_penalty
        
        # æ›´æ–°è®°å½•
        for env_idx in range(self.num_envs):
            self._prev_grasped_count[env_idx] = len(self.grasped_objects[env_idx])
        
        return reward
    
    def _compute_continuous_action_reward(self, info: Dict):
        """è®¡ç®—è¿ç»­åŠ¨ä½œæ¨¡å¼çš„å¥–åŠ±"""
        reward = torch.zeros(self.num_envs, device=self.device)
        
        if not hasattr(self, 'target_object') or self.target_object is None:
            return reward
        
        # 1. æ¥è¿‘å¥–åŠ±ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        tcp_to_obj_dist = torch.linalg.norm(
            self.target_object.pose.p - self.agent.tcp.pose.p, axis=1
        )
        reaching_reward = 1 - torch.tanh(5 * tcp_to_obj_dist)
        reward += reaching_reward * 2.0  # æƒé‡2.0
        
        # 2. æŠ“å–å¥–åŠ±
        is_grasped = info["is_grasped"]
        reward += is_grasped * 3.0  # æƒé‡3.0
        
        # 3. æ”¾ç½®å¥–åŠ±
        obj_to_goal_dist = torch.linalg.norm(
            self.goal_site.pose.p - self.target_object.pose.p, axis=1
        )
        place_reward = 1 - torch.tanh(5 * obj_to_goal_dist)
        reward += place_reward * is_grasped * 2.0  # åªæœ‰æŠ“å–æ—¶æ‰ç»™æ”¾ç½®å¥–åŠ±
        
        # 4. å…¶ä»–ç‰©ä½“ä½ç§»æƒ©ç½šï¼ˆä¼˜å…ˆçº§ç¬¬äºŒï¼‰
        other_displacement = self._calculate_other_objects_displacement()
        displacement_penalty = torch.tanh(other_displacement)
        reward -= displacement_penalty * 1.5  # æƒé‡1.5
        
        # 5. æ—¶é—´æƒ©ç½šï¼ˆä¼˜å…ˆçº§ç¬¬ä¸‰ï¼‰
        time_penalty = 0.01  # æ¯æ­¥å°æƒ©ç½š
        reward -= time_penalty
        
        # 6. é™æ­¢å¥–åŠ±
        static_reward = 1 - torch.tanh(
            5 * torch.linalg.norm(self.agent.robot.get_qvel()[..., :-2], axis=1)
        )
        reward += static_reward * info["is_obj_placed"] * 1.0
        
        # 7. æˆåŠŸå¥–åŠ±
        reward[info["success"]] = 10.0
        
        return reward

    def compute_sparse_reward(self, obs: Any, action: torch.Tensor, info: Dict):
        """è®¡ç®—ç¨€ç–å¥–åŠ± - è®ºæ–‡å±•ç¤ºåœºæ™¯ï¼ˆé™æ€ï¼Œæ— å¥–åŠ±ï¼‰"""
        return torch.zeros(self.num_envs, device=self.device)

    def compute_normalized_dense_reward(self, obs: Any, action: torch.Tensor, info: Dict):
        """è®¡ç®—å½’ä¸€åŒ–å¯†é›†å¥–åŠ± - è®ºæ–‡å±•ç¤ºåœºæ™¯ï¼ˆé™æ€ï¼Œæ— å¥–åŠ±ï¼‰"""
        return torch.zeros(self.num_envs, device=self.device) 

 

    def _init_fsm_states(self):
        """åˆå§‹åŒ–æœ‰é™çŠ¶æ€æœºçŠ¶æ€å¼ é‡"""
        self.env_stage = torch.zeros(self.num_envs, dtype=torch.int8, device=self.device)
        self.env_target = torch.full((self.num_envs,), -1, dtype=torch.int16, device=self.device)
        self.env_busy = torch.zeros(self.num_envs, dtype=torch.bool, device=self.device)
        self.stage_tick = torch.zeros(self.num_envs, dtype=torch.int16, device=self.device)
        self.stage_positions = torch.zeros(self.num_envs, 3, dtype=torch.float32, device=self.device)
    
    def _init_anygrasp(self):
        """åˆå§‹åŒ–AnyGraspæ¨¡å‹ï¼ˆåªåœ¨ç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶åŠ è½½ï¼‰"""
        if not ANYGRASP_AVAILABLE:
            print("AnyGraspä¸å¯ç”¨ï¼Œè·³è¿‡åˆå§‹åŒ–")
            return
            
        if self.anygrasp_model is not None:
            return  # å·²ç»åˆå§‹åŒ–è¿‡äº†
        
        try:
            print("æ­£åœ¨åˆå§‹åŒ–AnyGraspæ¨¡å‹...")
            # åˆ›å»ºé…ç½®å¯¹è±¡
            import argparse
            cfgs = argparse.Namespace()
            cfgs.checkpoint_path = self.ANYGRASP_CHECKPOINT
            cfgs.max_gripper_width = self.ANYGRASP_MAX_GRIPPER_WIDTH
            cfgs.gripper_height = self.ANYGRASP_GRIPPER_HEIGHT
            cfgs.top_down_grasp = self.ANYGRASP_TOP_DOWN_GRASP
            cfgs.debug = False  # å…³é—­è°ƒè¯•å¯è§†åŒ–
            
            # åˆå§‹åŒ–AnyGrasp
            self.anygrasp_model = AnyGrasp(cfgs)
            self.anygrasp_model.load_net()
            print("âœ… AnyGraspæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ AnyGraspæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self.anygrasp_enabled = False
            self.anygrasp_model = None
    
    def _get_camera_observations(self, camera_name: str = "base_camera") -> Dict:
        """
        è·å–ç›¸æœºè§‚æµ‹æ•°æ®ï¼ŒåŒ…æ‹¬RGBã€æ·±åº¦å’Œåˆ†å‰²
        
        Args:
            camera_name: ç›¸æœºåç§°
            
        Returns:
            åŒ…å«sensor_dataå’Œsensor_paramçš„å­—å…¸
        """
        # ä½¿ç”¨æ ‡å‡†çš„ManiSkillæ–¹å¼è·å–sensoræ•°æ®
        # è¿™ä¼šè‡ªåŠ¨å¤„ç†éšè—å¯¹è±¡ã€æ›´æ–°æ¸²æŸ“ç­‰
        for obj in self._hidden_objects:
            obj.hide_visual()
        self.scene.update_render(update_sensors=True, update_human_render_cameras=False)
        self.capture_sensor_data()
        
        # è·å–sensoræ•°æ®å’Œå‚æ•°
        sensor_data = {}
        sensor_params = {}
        
        if camera_name in self._sensors:
            camera = self._sensors[camera_name]
            sensor_data[camera_name] = camera.get_obs(
                rgb=True,
                depth=True,
                segmentation=True,
                position=True
            )
            sensor_params[camera_name] = camera.get_params()
        
        return {
            'sensor_data': sensor_data,
            'sensor_param': sensor_params
        }
    
    def _extract_target_pointcloud(self, target_obj: Actor, env_idx: int = 0, camera_name: str = "base_camera") -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:
        """
        ä½¿ç”¨å®ä¾‹åˆ†å‰²æå–ç›®æ ‡ç‰©ä½“çš„ç‚¹äº‘ - ä½¿ç”¨æ·±åº¦å›¾åæŠ•å½±æ–¹æ³•
        
        Args:
            target_obj: ç›®æ ‡ç‰©ä½“Actorå¯¹è±¡
            env_idx: ç¯å¢ƒç´¢å¼•
            camera_name: ä½¿ç”¨çš„ç›¸æœºåç§°
            
        Returns:
            (points, colors): ç›¸æœºåæ ‡ç³»ä¸‹çš„ç‚¹äº‘å’Œé¢œè‰²ï¼Œå¤±è´¥è¿”å›(None, None)
        """
        try:
            # è·å–ç›¸æœºè§‚æµ‹æ•°æ®å’Œå‚æ•°
            camera_obs = self._get_camera_observations(camera_name)
            if camera_obs is None:
                return None, None
            
            sensor_data = camera_obs['sensor_data'][camera_name]
            sensor_params = camera_obs['sensor_param'][camera_name]
            
            # æå–å„é€šé“æ•°æ®
            rgb = sensor_data["rgb"]  # [B, H, W, 3]
            depth = sensor_data["depth"]  # [B, H, W, 1]
            segmentation = sensor_data["segmentation"]  # [B, H, W, 1]
            
            print(f"ç¯å¢ƒ{env_idx}: sensor_dataåŒ…å«çš„é€šé“: {list(sensor_data.keys())}")
            
            # è·å–å½“å‰ç¯å¢ƒçš„æ•°æ®
            if env_idx >= rgb.shape[0]:
                print(f"ç¯å¢ƒç´¢å¼•{env_idx}è¶…å‡ºèŒƒå›´")
                return None, None
            
            rgb_env = rgb[env_idx]  # [H, W, 3]
            depth_env = depth[env_idx]  # [H, W, 1]
            seg_env = segmentation[env_idx]  # [H, W, 1]
            
            # è·å–ç›®æ ‡ç‰©ä½“çš„å®ä¾‹ID
            target_seg_ids = target_obj.per_scene_id  # torch.int32 tensor
            if target_seg_ids.numel() == 0:
                print(f"ç›®æ ‡ç‰©ä½“æ²¡æœ‰å®ä¾‹ID")
                return None, None
            
            # ç¡®ä¿åœ¨åŒä¸€è®¾å¤‡ä¸Š
            if target_seg_ids.device != seg_env.device:
                target_seg_ids = target_seg_ids.to(seg_env.device)
            
            # æå–Actorå±‚çš„åˆ†å‰²ï¼ˆç¬¬0é€šé“ï¼‰
            actor_seg = seg_env[..., 0]  # [H, W]
            
            # åˆ›å»ºç›®æ ‡ç‰©ä½“çš„åŸºç¡€mask
            if target_seg_ids.numel() == 1:
                base_mask = (actor_seg == target_seg_ids.item())
            else:
                # å¤šä¸ªIDçš„æƒ…å†µ
                base_mask = torch.isin(actor_seg, target_seg_ids)
            
            # æ£€æŸ¥åŸºç¡€maskæ˜¯å¦æœ‰æ•ˆ
            base_pixels = base_mask.sum().item()
            if base_pixels == 0:
                print(f"ç¯å¢ƒ{env_idx}: ç›®æ ‡ç‰©ä½“åœ¨å½“å‰è§†è§’ä¸‹ä¸å¯è§")
                return None, None
            
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ›´å¤šä¸Šä¸‹æ–‡çš„ç‚¹äº‘æå–ç­–ç•¥ï¼Œç±»ä¼¼å®˜æ–¹demo
            
            # è·å–æ‰˜ç›˜çš„segmentation IDï¼ˆç”¨äºæ’é™¤ï¼‰
            tray_seg_ids = set()
            if hasattr(self, 'trays') and self.trays:
                for tray in self.trays:
                    if hasattr(tray, 'per_scene_id') and tray.per_scene_id.numel() > 0:
                        tray_seg_ids.add(tray.per_scene_id.item())
            
            # ğŸ”§ ç­–ç•¥æ”¹è¿›ï¼šæä¾›æ›´å¤šä¸Šä¸‹æ–‡ä¿¡æ¯ç»™AnyGraspï¼Œä½†æ™ºèƒ½è¿‡æ»¤
            import torch.nn.functional as F
            
            # 1. åŸºç¡€ç›®æ ‡ç‰©ä½“mask
            target_mask = base_mask
            
            # 2. æ‰©å±•åŒºåŸŸåŒ…å«å‘¨å›´ç‰©ä½“ï¼ˆä¸åŒ…æ‹¬æ‰˜ç›˜ï¼‰
            # ä½¿ç”¨æ›´å¤§çš„è†¨èƒ€æ ¸æ¥è·å–å‘¨å›´ä¸Šä¸‹æ–‡ï¼Œä½†ä¼šæ™ºèƒ½è¿‡æ»¤
            kernel = torch.ones((1,1,7,7), device=base_mask.device)  # ä½¿ç”¨7x7æ ¸è·å–æ›´å¤šä¸Šä¸‹æ–‡
            expanded_mask = F.conv2d(base_mask.float().unsqueeze(0).unsqueeze(0), kernel, padding=3).squeeze()
            expanded_mask = (expanded_mask > 0)
            
            # 3. åˆ›å»ºæ‰˜ç›˜æ’é™¤mask  
            tray_exclusion_mask = torch.zeros_like(actor_seg, dtype=torch.bool)
            if tray_seg_ids:
                for tray_id in tray_seg_ids:
                    tray_exclusion_mask |= (actor_seg == tray_id)
            
            # 4. æ·±åº¦æœ‰æ•ˆæ€§æ£€æŸ¥ - ğŸ”§ ä¿®å¤ï¼šé€‚åº”æ–°çš„æ·±åº¦ç¼©æ”¾
            depth_valid = (depth_env[..., 0] > 0) & (depth_env[..., 0] / 1000.0 < 1.0)
            
            # 5. åˆ›å»ºä¸Šä¸‹æ–‡maskï¼šåŒ…å«ç›®æ ‡ç‰©ä½“å‘¨å›´çš„å…¶ä»–ç‰©ä½“ï¼Œä½†æ’é™¤æ‰˜ç›˜
            # è¿™æ ·AnyGraspå¯ä»¥çœ‹åˆ°ç›®æ ‡ç‰©ä½“åŠå…¶å‘¨å›´ç¯å¢ƒï¼Œè·å¾—æ›´å¥½çš„æŠ“å–è¯„åˆ†
            context_mask = expanded_mask & depth_valid & (actor_seg > 0) & (~tray_exclusion_mask)
            
            # 6. æœ€ç»ˆmaskï¼šç›®æ ‡ç‰©ä½“ + å‘¨å›´ä¸Šä¸‹æ–‡ï¼Œä½†æ’é™¤æ‰˜ç›˜
            mask = context_mask
            valid_pixels = mask.sum().item()
            
            print(f"ç¯å¢ƒ{env_idx}: åŸå§‹ç›®æ ‡åƒç´ : {base_pixels}, å¢å¼ºååƒç´ : {valid_pixels} (+{valid_pixels-base_pixels})")
            
            # ä½¿ç”¨æ·±åº¦å›¾åæŠ•å½±æ–¹æ³•
            # ä»sensor_paramsè·å–ç›¸æœºå†…å‚
            if 'intrinsic_cv' in sensor_params:
                # ä½¿ç”¨OpenCVæ ¼å¼çš„å†…å‚çŸ©é˜µ
                intrinsic = sensor_params['intrinsic_cv'][env_idx].cpu().numpy()  # [3, 3]
                fx, fy = intrinsic[0, 0], intrinsic[1, 1]
                cx, cy = intrinsic[0, 2], intrinsic[1, 2]
            else:
                # å¤‡é€‰æ–¹æ¡ˆï¼šä»å…¶ä»–å‚æ•°è®¡ç®—
                print(f"è­¦å‘Šï¼šæœªæ‰¾åˆ°intrinsic_cvï¼Œä½¿ç”¨å¤‡é€‰æ–¹æ³•")
                # æ£€æŸ¥å¯ç”¨çš„å‚æ•°
                print(f"å¯ç”¨çš„sensorå‚æ•°: {list(sensor_params.keys())}")
                # ä½¿ç”¨é»˜è®¤å€¼æˆ–ä»å…¶ä»–å‚æ•°æ¨å¯¼
                H, W = depth_env.shape[:2]
                fx = fy = W / 2.0  # ç®€å•ä¼°ç®—
                cx, cy = W / 2.0, H / 2.0
            
            print(f"ç¯å¢ƒ{env_idx}: ç›¸æœºå†…å‚ fx={fx:.2f}, fy={fy:.2f}, cx={cx:.2f}, cy={cy:.2f}")
            
            # è·å–maskå†…çš„åƒç´ åæ ‡å’Œæ·±åº¦å€¼
            v, u = torch.where(mask)  # æ³¨æ„ï¼štorch.whereè¿”å›(row, col)å³(y, x)
            z = depth_env[v, u, 0]  # æ·±åº¦å€¼
            
            # ğŸ”§ ä¿®å¤æ·±åº¦æ•°æ®æ ¼å¼å’Œç¼©æ”¾ - é€‚åº”é«˜åˆ†è¾¨ç‡ç›¸æœº
            if z.dtype == torch.int16:
                # ManiSkillçš„æ·±åº¦æ•°æ®éœ€è¦ç‰¹æ®Šçš„ç¼©æ”¾å› å­
                # ğŸ”§ ä¿®å¤ï¼šé«˜åˆ†è¾¨ç‡ç›¸æœºéœ€è¦è°ƒæ•´ç¼©æ”¾å› å­
                # 640x480ç›¸æœºçš„æ·±åº¦ç¼©æ”¾å› å­éœ€è¦é‡æ–°æ ¡å‡†
                scale_factor = 1000.0  # æ›´æ¥è¿‘å®˜æ–¹demoçš„scale=1000.0
                z = z.float() / scale_factor  
                print(f"ç¯å¢ƒ{env_idx}: æ·±åº¦æ•°æ®ä»int16è½¬æ¢ä¸ºç±³ï¼ˆç¼©æ”¾å› å­{scale_factor}ï¼‰")
            elif z.dtype in [torch.float32, torch.float64]:
                # å·²ç»æ˜¯æµ®ç‚¹æ•°ï¼Œå‡è®¾å•ä½æ˜¯ç±³
                z = z.float()
            
            # è¿‡æ»¤æ— æ•ˆæ·±åº¦
            valid_depth = z > 0
            u_valid = u[valid_depth]
            v_valid = v[valid_depth]
            z_valid = z[valid_depth]
            
            if len(z_valid) == 0:
                print(f"ç¯å¢ƒ{env_idx}: æ²¡æœ‰æœ‰æ•ˆçš„æ·±åº¦å€¼")
                return None, None
            
            print(f"ç¯å¢ƒ{env_idx}: æœ‰æ•ˆæ·±åº¦ç‚¹æ•°: {len(z_valid)}, æ·±åº¦èŒƒå›´: [{z_valid.min():.3f}, {z_valid.max():.3f}]ç±³")
            
            # åæŠ•å½±åˆ°ç›¸æœºåæ ‡ç³»
            # ç›¸æœºåæ ‡ç³»ï¼šXå³ï¼ŒYä¸‹ï¼ŒZå‰ï¼ˆOpenGLé£æ ¼ï¼‰
            x = (u_valid.float() - cx) / fx * z_valid
            y = (v_valid.float() - cy) / fy * z_valid
            
            # ç»„åˆæˆç‚¹äº‘ [N, 3]
            points_cam = torch.stack([x, y, z_valid], dim=-1).cpu().numpy().astype(np.float32)
            
            # è·å–å¯¹åº”çš„é¢œè‰²
            colors = rgb_env[v_valid, u_valid, :3].cpu().numpy().astype(np.float32)
            
            # ç¡®ä¿é¢œè‰²åœ¨[0,1]èŒƒå›´å†…
            if colors.max() > 1.0:
                colors = colors / 255.0
            
            print(f"ç¯å¢ƒ{env_idx}: æˆåŠŸæå–{len(points_cam)}ä¸ª3Dç‚¹")
            print(f"ç‚¹äº‘èŒƒå›´: X[{points_cam[:, 0].min():.3f}, {points_cam[:, 0].max():.3f}], Y[{points_cam[:, 1].min():.3f}, {points_cam[:, 1].max():.3f}], Z[{points_cam[:, 2].min():.3f}, {points_cam[:, 2].max():.3f}]")
            
            return points_cam, colors
                
        except Exception as e:
            print(f"ç¯å¢ƒ{env_idx}: æå–ç›®æ ‡ç‚¹äº‘å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None, None
    
    def _detect_grasps_for_target(self, target_obj: Actor, env_idx: int = 0, 
                                  top_k: int = 20, visualize: bool = False, 
                                  visualize_in_env: bool = False) -> Optional[List[Dict]]:
        """
        ä¸ºç›®æ ‡ç‰©ä½“æ£€æµ‹æŠ“å–ç‚¹
        
        Args:
            target_obj: ç›®æ ‡ç‰©ä½“
            env_idx: ç¯å¢ƒç´¢å¼•
            top_k: è¿”å›å‰kä¸ªæœ€ä½³æŠ“å–
            visualize: æ˜¯å¦ä½¿ç”¨Open3D/matplotlibå¯è§†åŒ–æŠ“å–ç»“æœ
            visualize_in_env: æ˜¯å¦åœ¨ä»¿çœŸç¯å¢ƒæ¸²æŸ“å›¾åƒä¸­å¯è§†åŒ–æŠ“å–
            
        Returns:
            æŠ“å–å€™é€‰åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«:
            - pose: æŠ“å–ä½å§¿ (4x4 transformation matrix in world frame)
            - score: æŠ“å–è´¨é‡åˆ†æ•°
            - width: å¤¹çˆªå®½åº¦
            å¤±è´¥è¿”å›None
        """
        if not self.anygrasp_enabled or self.anygrasp_model is None:
            print("AnyGraspæœªå¯ç”¨æˆ–æœªåˆå§‹åŒ–")
            return None
        
        try:
            # 1. æå–ç›®æ ‡ç‰©ä½“ç‚¹äº‘
            points, colors = self._extract_target_pointcloud(target_obj, env_idx)
            if points is None or len(points) == 0:
                print(f"ç¯å¢ƒ{env_idx}: æ— æ³•æå–ç›®æ ‡ç‰©ä½“ç‚¹äº‘")
                return None
            
            # è·å–ç›¸æœºå‚æ•°ï¼ˆç”¨äºåç»­åæ ‡å˜æ¢ï¼‰
            camera_obs = self._get_camera_observations("base_camera")
            sensor_params = camera_obs['sensor_param']["base_camera"]
            
            # 2. è®¾ç½®å·¥ä½œç©ºé—´é™åˆ¶ï¼ˆç›¸æœºåæ ‡ç³»ï¼‰- ğŸ”§ ä¿®å¤ï¼šæ›´å®½æ¾çš„å·¥ä½œç©ºé—´ï¼Œç±»ä¼¼å®˜æ–¹demo
            if len(points) > 0:
                # è·å–ç‚¹äº‘çš„æ•´ä½“èŒƒå›´
                point_min = points.min(axis=0)
                point_max = points.max(axis=0)
                obj_center = points.mean(axis=0)
                
                # ğŸ”§ ä½¿ç”¨æ›´å®½æ¾çš„å·¥ä½œç©ºé—´è®¾ç½®ï¼Œå‚è€ƒå®˜æ–¹demo
                # å®˜æ–¹demo: X[-0.19, 0.12], Y[0.02, 0.15], Z[0.0, 1.0]
                # åœ¨ç›¸æœºåæ ‡ç³»ä¸‹ï¼Œç»™äºˆè¶³å¤Ÿçš„ç©ºé—´è®©AnyGraspæ£€æµ‹
                
                # åŸºäºç‚¹äº‘èŒƒå›´ï¼Œä½†ç»™äºˆå……è¶³çš„è¾¹è·
                x_range = point_max[0] - point_min[0]
                y_range = point_max[1] - point_min[1] 
                z_range = point_max[2] - point_min[2]
                
                # ä½¿ç”¨ç‚¹äº‘èŒƒå›´çš„1.5å€ä½œä¸ºå·¥ä½œç©ºé—´ï¼Œä½†æœ‰æœ€å°å€¼ä¿è¯
                x_margin = max(x_range * 0.75, 0.12)  # è‡³å°‘12cmè¾¹è·
                y_margin = max(y_range * 0.75, 0.12)  # è‡³å°‘12cmè¾¹è·
                z_margin = max(z_range * 1.0, 0.15)   # è‡³å°‘15cmæ·±åº¦è¾¹è·
                
                xmin = obj_center[0] - x_margin
                xmax = obj_center[0] + x_margin
                ymin = obj_center[1] - y_margin
                ymax = obj_center[1] + y_margin
                zmin = max(0.01, point_min[2] - z_margin/2)
                zmax = point_max[2] + z_margin
                
                # ğŸ”§ ç¡®ä¿ä¸ä¼šæ£€æµ‹åˆ°æ‰˜ç›˜åº•éƒ¨ï¼Œä½†å…è®¸è¶³å¤Ÿçš„ç©ºé—´
                # æ‰˜ç›˜åœ¨ç›¸æœºåæ ‡ç³»ä¸­çš„å¤§è‡´æ·±åº¦æ˜¯0.33+ï¼Œæˆ‘ä»¬è®¾ç½®ä¸Šé™ä¸º0.4
                zmax = min(zmax, 0.4)
                
                print(f"ç¯å¢ƒ{env_idx}: ç‚¹äº‘èŒƒå›´: X[{points[:, 0].min():.3f}, {points[:, 0].max():.3f}], Y[{points[:, 1].min():.3f}, {points[:, 1].max():.3f}], Z[{points[:, 2].min():.3f}, {points[:, 2].max():.3f}]")
                print(f"ç¯å¢ƒ{env_idx}: ç›®æ ‡ä¸­å¿ƒ: [{obj_center[0]:.3f}, {obj_center[1]:.3f}, {obj_center[2]:.3f}]")
                print(f"ç¯å¢ƒ{env_idx}: å·¥ä½œç©ºé—´è¾¹è·: XÂ±{x_margin:.3f}, YÂ±{y_margin:.3f}, Z+{z_margin:.3f}")
            else:
                # ä½¿ç”¨ç±»ä¼¼å®˜æ–¹demoçš„é»˜è®¤èŒƒå›´ï¼ˆç›¸æœºåæ ‡ç³»ï¼‰
                xmin, xmax = -0.2, 0.2
                ymin, ymax = -0.2, 0.2
                zmin, zmax = 0.01, 0.4
            
            lims = [xmin, xmax, ymin, ymax, zmin, zmax]
            print(f"ç¯å¢ƒ{env_idx}: å·¥ä½œç©ºé—´é™åˆ¶: X[{xmin:.3f}, {xmax:.3f}], Y[{ymin:.3f}, {ymax:.3f}], Z[{zmin:.3f}, {zmax:.3f}]")
            
            # 3. è°ƒç”¨AnyGraspæ£€æµ‹æŠ“å–
            print(f"ç¯å¢ƒ{env_idx}: å¼€å§‹æ£€æµ‹æŠ“å–ç‚¹ï¼Œè¾“å…¥ç‚¹äº‘å¤§å°: {points.shape}")
            print(f"ç¯å¢ƒ{env_idx}: ç‚¹äº‘æ•°æ®ç±»å‹: {points.dtype}, é¢œè‰²æ•°æ®ç±»å‹: {colors.dtype}")
            print(f"ç¯å¢ƒ{env_idx}: ç‚¹äº‘èŒƒå›´æ£€æŸ¥: X[{points[:, 0].min():.3f}, {points[:, 0].max():.3f}], Y[{points[:, 1].min():.3f}, {points[:, 1].max():.3f}], Z[{points[:, 2].min():.3f}, {points[:, 2].max():.3f}]")
            print(f"ç¯å¢ƒ{env_idx}: é¢œè‰²èŒƒå›´æ£€æŸ¥: [{colors.min():.3f}, {colors.max():.3f}]")
            
            # ç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®
            points = points.astype(np.float32)
            colors = colors.astype(np.float32)
            
            # ğŸ”§ ä¿®å¤ï¼šä¼˜åŒ–ç‚¹äº‘å¯†åº¦æ£€æŸ¥å’ŒAnyGraspå‚æ•°
            min_points_threshold = 50  # é™ä½é˜ˆå€¼ï¼Œæ›´ç°å®
            if len(points) < min_points_threshold:
                print(f"ç¯å¢ƒ{env_idx}: ç‚¹äº‘ç¨€ç–({len(points)}ä¸ªç‚¹ï¼Œéœ€è¦è‡³å°‘{min_points_threshold}ä¸ª)ï¼Œä½†ç»§ç»­å°è¯•æ£€æµ‹")
            
            # ğŸ”§ ä¿®å¤ï¼šä¼˜åŒ–AnyGraspå‚æ•°ï¼Œæé«˜æŠ“å–è´¨é‡
            gg, cloud = self.anygrasp_model.get_grasp(
                points, 
                colors, 
                lims=lims, 
                apply_object_mask=False,  # æˆ‘ä»¬å·²ç»æä¾›äº†ç²¾ç¡®çš„ç›®æ ‡ç‚¹äº‘
                dense_grasp=False,        # ğŸ”§ ä¿®å¤ï¼šå…³é—­å¯†é›†æ£€æµ‹ï¼Œæé«˜æŠ“å–è´¨é‡
                collision_detection=True  # ğŸ”§ ä¿®å¤ï¼šå¯ç”¨ç¢°æ’æ£€æµ‹ï¼Œè¿‡æ»¤ä¸åˆç†çš„æŠ“å–
            )
            
            if len(gg) == 0:
                print(f"ç¯å¢ƒ{env_idx}: æœªæ£€æµ‹åˆ°æœ‰æ•ˆæŠ“å–")
                return None
            
            # 4. NMSå’Œæ’åº
            gg = gg.nms().sort_by_score()
            
            # 5. é€‰æ‹©Top-KæŠ“å–
            gg_top = gg[:min(top_k, len(gg))]
            
            # 6. è½¬æ¢æŠ“å–è¡¨ç¤º
            grasps = []
            for i in range(len(gg_top)):
                grasp = gg_top[i]
                
                # âœ… ä½¿ç”¨æ­£ç¡®çš„æ–¹æ³•æ„å»º4x4å˜æ¢çŸ©é˜µ
                # åŸºäºè°ƒè¯•ç»“æœï¼šgrasp.grasp_arrayæ˜¯17ç»´å‘é‡ï¼Œåº”è¯¥ä½¿ç”¨grasp.translationå’Œgrasp.rotation_matrix
                try:
                    if hasattr(grasp, 'translation') and hasattr(grasp, 'rotation_matrix'):
                        translation = grasp.translation  # [3] - æŠ“å–ä¸­å¿ƒä½ç½®
                        rotation = grasp.rotation_matrix  # [3, 3] - æ—‹è½¬çŸ©é˜µ
                        
                        # æ„å»º4x4å˜æ¢çŸ©é˜µï¼ˆç›¸æœºåæ ‡ç³»ï¼‰
                        grasp_pose_cam = np.eye(4, dtype=np.float64)
                        grasp_pose_cam[:3, :3] = rotation
                        grasp_pose_cam[:3, 3] = translation
                        
                        # åªåœ¨è°ƒè¯•æ¨¡å¼ä¸‹æ‰“å°è¯¦ç»†ä¿¡æ¯
                        if i == 0:  # åªä¸ºç¬¬ä¸€ä¸ªæŠ“å–æ‰“å°
                            print(f"ç¯å¢ƒ{env_idx}: âœ… æˆåŠŸæ„å»ºæŠ“å–çŸ©é˜µ")
                            print(f"  translation: {translation}")
                            print(f"  rotation shape: {rotation.shape}")
                            print(f"  æ„å»ºçš„4x4çŸ©é˜µå½¢çŠ¶: {grasp_pose_cam.shape}")
                    else:
                        print(f"ç¯å¢ƒ{env_idx}: âŒ æŠ“å–å¯¹è±¡ç¼ºå°‘translationæˆ–rotation_matrixå±æ€§")
                        continue
                        
                except Exception as e:
                    print(f"ç¯å¢ƒ{env_idx}: âŒ æ„å»ºæŠ“å–çŸ©é˜µå¤±è´¥: {e}")
                    continue
                
                # è·å–ç›¸æœºåˆ°ä¸–ç•Œçš„å˜æ¢
                if 'cam2world_gl' in sensor_params:
                    # ä½¿ç”¨cam2worldå˜æ¢çŸ©é˜µ
                    cam2world = sensor_params['cam2world_gl'][env_idx].cpu().numpy().astype(np.float64)
                    T_world_cam = cam2world
                else:
                    # å¤‡é€‰æ–¹æ¡ˆï¼šä½¿ç”¨ç›¸æœºé…ç½®ä¸­çš„å›ºå®šä½å§¿
                    camera_config_pose = self._default_sensor_configs[0].pose
                    cam_pos = np.array(camera_config_pose.p, dtype=np.float64)
                    cam_quat = np.array(camera_config_pose.q, dtype=np.float64)
                    
                    # æ„å»ºç›¸æœºåˆ°ä¸–ç•Œçš„å˜æ¢çŸ©é˜µ
                    T_world_cam = np.eye(4, dtype=np.float64)
                    from scipy.spatial.transform import Rotation
                    R = Rotation.from_quat(cam_quat)  # [x,y,z,w]æ ¼å¼
                    T_world_cam[:3, :3] = R.as_matrix()
                    T_world_cam[:3, 3] = cam_pos
                
                # å°†æŠ“å–ä½å§¿è½¬æ¢åˆ°ä¸–ç•Œåæ ‡ç³»
                try:
                    grasp_pose_world = T_world_cam @ grasp_pose_cam
                    # åªä¸ºç¬¬ä¸€ä¸ªæŠ“å–æ‰“å°æˆåŠŸä¿¡æ¯
                    if i == 0:
                        print(f"ç¯å¢ƒ{env_idx}: âœ… åæ ‡å˜æ¢æˆåŠŸï¼ŒçŸ©é˜µå½¢çŠ¶: {T_world_cam.shape} @ {grasp_pose_cam.shape} -> {grasp_pose_world.shape}")
                except Exception as matmul_error:
                    print(f"ç¯å¢ƒ{env_idx}: âŒ åæ ‡å˜æ¢å¤±è´¥: {matmul_error}")
                    # æš‚æ—¶ä½¿ç”¨ç›¸æœºåæ ‡ç³»ç»“æœ
                    grasp_pose_world = grasp_pose_cam
                    if i == 0:
                        print(f"ç¯å¢ƒ{env_idx}: ä½¿ç”¨ç›¸æœºåæ ‡ç³»ç»“æœ")
                
                grasps.append({
                    'pose': grasp_pose_world,
                    'score': float(grasp.score),
                    'width': float(grasp.width),
                    'translation': grasp_pose_world[:3, 3],  # æŠ“å–ä¸­å¿ƒä½ç½®
                    'rotation': grasp_pose_world[:3, :3],    # æŠ“å–å§¿æ€
                })
            
            # ğŸ”§ ä¿®å¤ï¼šåœ¨ä¸–ç•Œåæ ‡ç³»ä¸­è¿›ä¸€æ­¥è¿‡æ»¤æ‰˜ç›˜åŒºåŸŸçš„æŠ“å–
            filtered_grasps = []
            tray_center = np.array([-0.2, 0.0, 0.006])  # æ‰˜ç›˜ä¸­å¿ƒä½ç½®ï¼ˆä¸–ç•Œåæ ‡ï¼‰
            tray_size = np.array([0.6, 0.6, 0.15])       # æ‰˜ç›˜å°ºå¯¸
            tray_safety_margin = 0.05  # 5cmå®‰å…¨è¾¹è·
            
            for grasp in grasps:
                grasp_pos = grasp['translation']
                
                # æ£€æŸ¥æ˜¯å¦åœ¨æ‰˜ç›˜å†…éƒ¨ï¼ˆè€ƒè™‘å®‰å…¨è¾¹è·ï¼‰
                relative_pos = np.abs(grasp_pos - tray_center)
                is_in_tray = (
                    relative_pos[0] <= (tray_size[0]/2 + tray_safety_margin) and
                    relative_pos[1] <= (tray_size[1]/2 + tray_safety_margin) and
                    grasp_pos[2] <= (tray_center[2] + tray_size[2] + tray_safety_margin)
                )
                
                if not is_in_tray:
                    filtered_grasps.append(grasp)
                else:
                    print(f"ç¯å¢ƒ{env_idx}: è¿‡æ»¤æ‰æ‰˜ç›˜å†…çš„æŠ“å–ç‚¹: [{grasp_pos[0]:.3f}, {grasp_pos[1]:.3f}, {grasp_pos[2]:.3f}], åˆ†æ•°={grasp['score']:.3f}")
            
            # ä½¿ç”¨è¿‡æ»¤åçš„æŠ“å–åˆ—è¡¨
            if not filtered_grasps:
                print(f"ç¯å¢ƒ{env_idx}: æ‰€æœ‰æŠ“å–éƒ½åœ¨æ‰˜ç›˜åŒºåŸŸå†…ï¼Œä½¿ç”¨åŸå§‹ç»“æœ")
                filtered_grasps = grasps  # å¦‚æœå…¨éƒ¨è¢«è¿‡æ»¤ï¼Œåˆ™ä½¿ç”¨åŸå§‹ç»“æœ
            else:
                grasps = filtered_grasps
                print(f"ç¯å¢ƒ{env_idx}: æ‰˜ç›˜è¿‡æ»¤åå‰©ä½™{len(grasps)}ä¸ªæŠ“å–å€™é€‰")
            
            print(f"ç¯å¢ƒ{env_idx}: æœ€ç»ˆæ£€æµ‹åˆ°{len(grasps)}ä¸ªæŠ“å–å€™é€‰")
            if grasps:
                print(f"æœ€ä½³æŠ“å–åˆ†æ•°: {grasps[0]['score']:.3f}")
                print(f"æœ€ä½³æŠ“å–ä½ç½®: [{grasps[0]['translation'][0]:.3f}, {grasps[0]['translation'][1]:.3f}, {grasps[0]['translation'][2]:.3f}]")
            
            # ğŸ¨ å¯è§†åŒ–åŠŸèƒ½
            if visualize:
                # æ™ºèƒ½é€‰æ‹©å¯è§†åŒ–æ–¹å¼
                try:
                    # æ£€æµ‹æ˜¯å¦æœ‰å›¾å½¢ç•Œé¢ç¯å¢ƒ
                    if os.environ.get('DISPLAY') is None and os.environ.get('WAYLAND_DISPLAY') is None:
                        print("ğŸ” æ£€æµ‹åˆ°æ— å›¾å½¢ç•Œé¢ç¯å¢ƒï¼Œä½¿ç”¨matplotlibå¯è§†åŒ–")
                        self._visualize_grasps_matplotlib(points, colors, gg_top, f"grasp_env_{env_idx}_{target_obj.name}.png")
                    else:
                        print("ğŸ” å°è¯•Open3D 3Då¯è§†åŒ–...")
                        self._visualize_grasps(points, colors, gg_top, f"ç¯å¢ƒ{env_idx}æŠ“å–æ£€æµ‹ç»“æœ")
                except Exception as viz_error:
                    print(f"Open3Då¯è§†åŒ–å¤±è´¥: {viz_error}")
                    print("ğŸ”„ è‡ªåŠ¨åˆ‡æ¢åˆ°matplotlibå¯è§†åŒ–...")
                    self._visualize_grasps_matplotlib(points, colors, gg_top, f"grasp_env_{env_idx}_{target_obj.name}.png")
            
            # ğŸ¬ åœ¨ä»¿çœŸç¯å¢ƒä¸­å¯è§†åŒ–æŠ“å–
            if visualize_in_env:
                try:
                    self._visualize_grasps_in_simulation(grasps, target_obj, env_idx)
                except Exception as env_viz_error:
                    print(f"ç¯å¢ƒå¯è§†åŒ–å¤±è´¥: {env_viz_error}")
            
            return grasps
            
        except Exception as e:
            print(f"ç¯å¢ƒ{env_idx}: æŠ“å–æ£€æµ‹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _visualize_grasps(self, points: np.ndarray, colors: np.ndarray, 
                          grasps, title: str = "æŠ“å–æ£€æµ‹ç»“æœ"):
        """
        ä½¿ç”¨Open3Då¯è§†åŒ–æŠ“å–ç»“æœ
        
        Args:
            points: ç‚¹äº‘åæ ‡ [N, 3]
            colors: ç‚¹äº‘é¢œè‰² [N, 3] 
            grasps: GraspGroupå¯¹è±¡æˆ–æŠ“å–åˆ—è¡¨
            title: å¯è§†åŒ–çª—å£æ ‡é¢˜
        """
        try:
            import open3d as o3d
            print(f"ğŸ¨ å¼€å§‹å¯è§†åŒ–: {title}")
            
            # 1. åˆ›å»ºç‚¹äº‘å¯¹è±¡
            pcd = o3d.geometry.PointCloud()
            pcd.points = o3d.utility.Vector3dVector(points.astype(np.float64))
            pcd.colors = o3d.utility.Vector3dVector(colors.astype(np.float64))
            
            print(f"ç‚¹äº‘åŒ…å« {len(points)} ä¸ªç‚¹")
            
            # 2. è·å–æŠ“å–å‡ ä½•å¯¹è±¡
            if hasattr(grasps, 'to_open3d_geometry_list'):
                # GraspGroupå¯¹è±¡
                grippers = grasps.to_open3d_geometry_list()
                print(f"ç”Ÿæˆäº† {len(grippers)} ä¸ªæŠ“å–å™¨å‡ ä½•å¯¹è±¡")
            else:
                print("âŒ æ— æ³•ä»æŠ“å–å¯¹è±¡ç”Ÿæˆå‡ ä½•å¯¹è±¡")
                return
            
            # 3. åæ ‡å˜æ¢ï¼ˆä¸demo.pyä¿æŒä¸€è‡´ï¼‰
            # ç¿»è½¬Zè½´ä»¥é€‚åº”å¯è§†åŒ–åæ ‡ç³»
            trans_mat = np.array([
                [1, 0, 0, 0],
                [0, 1, 0, 0], 
                [0, 0, -1, 0],
                [0, 0, 0, 1]
            ], dtype=np.float64)
            
            pcd.transform(trans_mat)
            for gripper in grippers:
                gripper.transform(trans_mat)
            
            # 4. å¯è§†åŒ–é€‰é¡¹
            print("ğŸ¨ æ˜¾ç¤ºå¯è§†åŒ–çª—å£...")
            print("æ“ä½œæç¤º:")
            print("  - é¼ æ ‡å·¦é”®æ‹–æ‹½: æ—‹è½¬è§†è§’")
            print("  - é¼ æ ‡å³é”®æ‹–æ‹½: å¹³ç§»è§†è§’") 
            print("  - æ»šè½®: ç¼©æ”¾")
            print("  - æŒ‰Qæˆ–å…³é—­çª—å£: é€€å‡º")
            
            # å°è¯•æ˜¾ç¤ºæ‰€æœ‰æŠ“å–
            print(f"æ˜¾ç¤ºç‚¹äº‘ + æ‰€æœ‰{len(grippers)}ä¸ªæŠ“å–å€™é€‰")
            try:
                success = o3d.visualization.draw_geometries(
                    [pcd] + grippers,
                    window_name=f"{title} - æ‰€æœ‰æŠ“å–",
                    width=800,
                    height=600
                )
                
                # æ˜¾ç¤ºæœ€ä½³æŠ“å–ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                if len(grippers) > 0:
                    print("æ˜¾ç¤ºç‚¹äº‘ + æœ€ä½³æŠ“å–")
                    o3d.visualization.draw_geometries(
                        [pcd, grippers[0]],
                        window_name=f"{title} - æœ€ä½³æŠ“å–",
                        width=800,
                        height=600
                    )
                
                print("âœ… å¯è§†åŒ–å®Œæˆ")
                
            except Exception as display_error:
                print(f"Open3Dçª—å£æ˜¾ç¤ºå¤±è´¥: {display_error}")
                # è¿™é‡Œä¸æŠ›å‡ºå¼‚å¸¸ï¼Œå› ä¸ºå¯è§†åŒ–å¤±è´¥ä¸åº”è¯¥å½±å“ä¸»è¦åŠŸèƒ½
                print("âš ï¸ Open3Då¯è§†åŒ–å¤±è´¥ï¼Œä½†æ£€æµ‹åŠŸèƒ½æ­£å¸¸")
            
        except ImportError:
            print("âŒ éœ€è¦å®‰è£…Open3Dæ‰èƒ½ä½¿ç”¨å¯è§†åŒ–åŠŸèƒ½: pip install open3d")
        except Exception as e:
            print(f"âŒ å¯è§†åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    def _visualize_grasps_matplotlib(self, points: np.ndarray, colors: np.ndarray, 
                                   grasps, filename: str = "grasp_result.png"):
        """
        ä½¿ç”¨matplotlibç”Ÿæˆ2DæŠ“å–å¯è§†åŒ–ï¼ˆæœåŠ¡å™¨å‹å¥½ï¼‰
        
        Args:
            points: ç‚¹äº‘åæ ‡ [N, 3]
            colors: ç‚¹äº‘é¢œè‰² [N, 3] 
            grasps: GraspGroupå¯¹è±¡æˆ–æŠ“å–åˆ—è¡¨
            filename: è¾“å‡ºæ–‡ä»¶å
        """
        try:
            import matplotlib.pyplot as plt
            from mpl_toolkits.mplot3d import Axes3D
            import matplotlib
            matplotlib.use('Agg')  # æ— ç•Œé¢åç«¯
            
            print(f"ğŸ¨ ä½¿ç”¨matplotlibç”Ÿæˆå¯è§†åŒ–: {filename}")
            
            # æå–æŠ“å–ä¿¡æ¯
            grasp_positions = []
            grasp_scores = []
            for i in range(len(grasps)):
                grasp = grasps[i]
                if hasattr(grasp, 'translation') and hasattr(grasp, 'score'):
                    pos = grasp.translation
                    grasp_positions.append(pos)
                    grasp_scores.append(grasp.score)
            
            if not grasp_positions:
                print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„æŠ“å–æ•°æ®")
                return
            
            grasp_positions = np.array(grasp_positions)
            grasp_scores = np.array(grasp_scores)
            
            # åˆ›å»ºå¤šå­å›¾
            fig = plt.figure(figsize=(12, 8))
            
            # 3Dç‚¹äº‘+æŠ“å–ç‚¹
            ax1 = fig.add_subplot(2, 2, 1, projection='3d')
            ax1.scatter(points[:, 0], points[:, 1], points[:, 2], 
                       c=colors, s=2, alpha=0.6, label='Point Cloud')
            ax1.scatter(grasp_positions[:, 0], grasp_positions[:, 1], grasp_positions[:, 2],
                       c=grasp_scores, s=50, cmap='viridis', marker='^', alpha=0.8, label='Grasps')
            ax1.set_title('3D Point Cloud + Grasp Candidates')
            ax1.set_xlabel('X (m)')
            ax1.set_ylabel('Y (m)')
            ax1.set_zlabel('Z (m)')
            ax1.legend()
            
            # XYå¹³é¢è§†å›¾
            ax2 = fig.add_subplot(2, 2, 2)
            ax2.scatter(points[:, 0], points[:, 1], c=colors[:, 0], s=5, alpha=0.6, label='Points')
            scatter = ax2.scatter(grasp_positions[:, 0], grasp_positions[:, 1], 
                                c=grasp_scores, s=80, cmap='viridis', marker='^', alpha=0.8)
            best_idx = np.argmax(grasp_scores)
            ax2.scatter(grasp_positions[best_idx, 0], grasp_positions[best_idx, 1], 
                       s=150, facecolors='none', edgecolors='red', linewidth=2, label='Best')
            plt.colorbar(scatter, ax=ax2, label='Score')
            ax2.set_title('XY Plane View')
            ax2.set_xlabel('X (m)')
            ax2.set_ylabel('Y (m)')
            ax2.legend()
            ax2.grid(True, alpha=0.3)
            
            # æŠ“å–åˆ†æ•°æŸ±çŠ¶å›¾
            ax3 = fig.add_subplot(2, 2, 3)
            bars = ax3.bar(range(len(grasp_scores)), grasp_scores, color='skyblue', alpha=0.7)
            bars[best_idx].set_color('red')  # é«˜äº®æœ€ä½³æŠ“å–
            ax3.axhline(y=np.mean(grasp_scores), color='orange', linestyle='--', 
                       label=f'Mean: {np.mean(grasp_scores):.4f}')
            ax3.set_title('Grasp Quality Distribution')
            ax3.set_xlabel('Grasp Index')
            ax3.set_ylabel('Score')
            ax3.legend()
            ax3.grid(True, alpha=0.3)
            
            # ç»Ÿè®¡ä¿¡æ¯æ–‡æœ¬
            ax4 = fig.add_subplot(2, 2, 4)
            ax4.axis('off')
            
            stats_text = f"""
æŠ“å–æ£€æµ‹ç»Ÿè®¡:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ ç‚¹äº‘å¤§å°: {len(points)} ä¸ªç‚¹
â€¢ æ£€æµ‹æŠ“å–: {len(grasps)} ä¸ª
â€¢ æœ€ä½³åˆ†æ•°: {np.max(grasp_scores):.4f}
â€¢ å¹³å‡åˆ†æ•°: {np.mean(grasp_scores):.4f}
â€¢ åˆ†æ•°æ ‡å‡†å·®: {np.std(grasp_scores):.4f}

æœ€ä½³æŠ“å–ä½ç½®:
â€¢ X: {grasp_positions[best_idx, 0]:.3f} m
â€¢ Y: {grasp_positions[best_idx, 1]:.3f} m  
â€¢ Z: {grasp_positions[best_idx, 2]:.3f} m

ç‚¹äº‘èŒƒå›´:
â€¢ X: [{points[:, 0].min():.3f}, {points[:, 0].max():.3f}]
â€¢ Y: [{points[:, 1].min():.3f}, {points[:, 1].max():.3f}]
â€¢ Z: [{points[:, 2].min():.3f}, {points[:, 2].max():.3f}]
"""
            
            ax4.text(0.05, 0.95, stats_text, transform=ax4.transAxes, fontsize=10,
                    verticalalignment='top', fontfamily='monospace',
                    bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))
            
            plt.tight_layout()
            plt.savefig(filename, dpi=150, bbox_inches='tight', facecolor='white')
            plt.close()
            
            print(f"âœ… matplotlibå¯è§†åŒ–å·²ä¿å­˜: {filename}")
            
        except ImportError:
            print("âŒ éœ€è¦å®‰è£…matplotlibæ‰èƒ½ä½¿ç”¨å¤‡ç”¨å¯è§†åŒ–åŠŸèƒ½")
        except Exception as e:
            print(f"âŒ matplotlibå¯è§†åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    def _visualize_grasps_in_simulation(self, grasps: List[Dict], target_obj: Actor, env_idx: int = 0):
        """
        åœ¨ä»¿çœŸç¯å¢ƒæ¸²æŸ“å›¾åƒä¸­å¯è§†åŒ–æŠ“å–ä½å§¿
        
        Args:
            grasps: æŠ“å–å€™é€‰åˆ—è¡¨
            target_obj: ç›®æ ‡ç‰©ä½“
            env_idx: ç¯å¢ƒç´¢å¼•
        """
        try:
            import cv2
            import matplotlib.pyplot as plt
            import matplotlib
            matplotlib.use('Agg')
            
            print(f"ğŸ¬ åœ¨ä»¿çœŸç¯å¢ƒä¸­å¯è§†åŒ–æŠ“å–...")
            
            # 1. è·å–ç¯å¢ƒæ¸²æŸ“å›¾åƒ
            env_image = self.render_rgb_array()  # è·å–ç¯å¢ƒRGBå›¾åƒ
            if env_image is None:
                print("âŒ æ— æ³•è·å–ç¯å¢ƒæ¸²æŸ“å›¾åƒ")
                return
            
            # å¦‚æœæ˜¯å¤šç¯å¢ƒï¼Œé€‰æ‹©å¯¹åº”ç¯å¢ƒçš„å›¾åƒ
            if len(env_image.shape) == 4:  # [num_envs, H, W, C]
                if env_idx < env_image.shape[0]:
                    env_image = env_image[env_idx]
                else:
                    env_image = env_image[0]
                    print(f"âš ï¸ ç¯å¢ƒç´¢å¼•{env_idx}è¶Šç•Œï¼Œä½¿ç”¨ç¯å¢ƒ0çš„å›¾åƒ")
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„å’Œ0-255èŒƒå›´çš„uint8æ ¼å¼
            if isinstance(env_image, torch.Tensor):
                env_image = env_image.cpu().numpy()
            
            if env_image.dtype == np.float32 or env_image.dtype == np.float64:
                if env_image.max() <= 1.0:
                    env_image = (env_image * 255).astype(np.uint8)
                else:
                    env_image = env_image.astype(np.uint8)
            
            print(f"ç¯å¢ƒå›¾åƒå½¢çŠ¶: {env_image.shape}, æ•°æ®ç±»å‹: {env_image.dtype}")
            
            # 2. è·å–ç›¸æœºå‚æ•°
            camera_obs = self._get_camera_observations("base_camera")
            if camera_obs is None or "base_camera" not in camera_obs['sensor_param']:
                print("âŒ æ— æ³•è·å–ç›¸æœºå‚æ•°")
                return
            
            sensor_params = camera_obs['sensor_param']["base_camera"]
            
            # 3. åœ¨å›¾åƒä¸Šç»˜åˆ¶æŠ“å–
            annotated_image = self._draw_grasps_on_image(env_image.copy(), grasps, sensor_params, env_idx)
            
            # 4. ä¿å­˜ç»“æœ
            output_filename = f"grasp_simulation_env_{env_idx}_{target_obj.name}.png"
            
            # ä½¿ç”¨matplotlibä¿å­˜ï¼ˆæ›´å¥½çš„è´¨é‡æ§åˆ¶ï¼‰
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
            
            # åŸå§‹ç¯å¢ƒå›¾åƒ
            ax1.imshow(env_image)
            ax1.set_title('Original Environment View')
            ax1.axis('off')
            
            # å¸¦æŠ“å–æ ‡æ³¨çš„å›¾åƒ
            ax2.imshow(annotated_image)
            ax2.set_title(f'Grasp Candidates ({len(grasps)} detected)')
            ax2.axis('off')
            
            plt.tight_layout()
            plt.savefig(output_filename, dpi=150, bbox_inches='tight')
            plt.close()
            
            print(f"âœ… ç¯å¢ƒå¯è§†åŒ–å·²ä¿å­˜: {output_filename}")
            
            # 5. ä¿å­˜æŠ“å–ä¿¡æ¯
            info_filename = output_filename.replace('.png', '_info.txt')
            with open(info_filename, 'w', encoding='utf-8') as f:
                f.write(f"ç¯å¢ƒæŠ“å–å¯è§†åŒ–æŠ¥å‘Š\n")
                f.write(f"========================\n")
                f.write(f"ç›®æ ‡ç‰©ä½“: {target_obj.name}\n")
                f.write(f"ç¯å¢ƒç´¢å¼•: {env_idx}\n")
                f.write(f"å›¾åƒå°ºå¯¸: {env_image.shape}\n")
                f.write(f"æ£€æµ‹åˆ°æŠ“å–æ•°é‡: {len(grasps)}\n\n")
                
                for i, grasp in enumerate(grasps):
                    f.write(f"æŠ“å– {i+1}:\n")
                    f.write(f"  åˆ†æ•°: {grasp['score']:.4f}\n")
                    f.write(f"  ä½ç½®: [{grasp['translation'][0]:.3f}, {grasp['translation'][1]:.3f}, {grasp['translation'][2]:.3f}]\n")
                    f.write(f"  å®½åº¦: {grasp['width']:.3f}m\n\n")
            
            print(f"ğŸ“‹ æŠ“å–ä¿¡æ¯å·²ä¿å­˜: {info_filename}")
            
        except ImportError as e:
            print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
            print("éœ€è¦å®‰è£…: pip install opencv-python")
        except Exception as e:
            print(f"âŒ ç¯å¢ƒå¯è§†åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    def _draw_grasps_on_image(self, image: np.ndarray, grasps: List[Dict], 
                             sensor_params: Dict, env_idx: int = 0) -> np.ndarray:
        """
        åœ¨å›¾åƒä¸Šç»˜åˆ¶æŠ“å–ä½å§¿
        
        Args:
            image: ç¯å¢ƒå›¾åƒ [H, W, 3]
            grasps: æŠ“å–å€™é€‰åˆ—è¡¨
            sensor_params: ç›¸æœºå‚æ•°
            env_idx: ç¯å¢ƒç´¢å¼•
            
        Returns:
            å¸¦æŠ“å–æ ‡æ³¨çš„å›¾åƒ
        """
        try:
            import cv2
            
            # è·å–ç›¸æœºå†…å‚
            if 'intrinsic_cv' in sensor_params:
                intrinsic = sensor_params['intrinsic_cv'][env_idx].cpu().numpy()
                fx, fy = intrinsic[0, 0], intrinsic[1, 1]
                cx, cy = intrinsic[0, 2], intrinsic[1, 2]
            else:
                # ä½¿ç”¨é»˜è®¤å†…å‚
                H, W = image.shape[:2]
                fx = fy = W / 2.0
                cx, cy = W / 2.0, H / 2.0
            
            # è·å–ç›¸æœºä½å§¿ï¼ˆä¸–ç•Œåˆ°ç›¸æœºçš„å˜æ¢ï¼‰
            if 'cam2world_gl' in sensor_params:
                cam2world = sensor_params['cam2world_gl'][env_idx].cpu().numpy()
                world2cam = np.linalg.inv(cam2world)
            else:
                # ä½¿ç”¨å•ä½çŸ©é˜µï¼ˆå‡è®¾ç›¸æœºåœ¨ä¸–ç•ŒåŸç‚¹ï¼‰
                world2cam = np.eye(4)
            
            annotated_image = image.copy()
            colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255)]  # BGRæ ¼å¼
            
            for i, grasp in enumerate(grasps):
                try:
                    # è·å–æŠ“å–ä½ç½®ï¼ˆä¸–ç•Œåæ ‡ç³»ï¼‰
                    world_pos = np.array([grasp['translation'][0], grasp['translation'][1], grasp['translation'][2], 1.0])
                    
                    # è½¬æ¢åˆ°ç›¸æœºåæ ‡ç³»
                    cam_pos = world2cam @ world_pos
                    x_cam, y_cam, z_cam = cam_pos[:3]
                    
                    # æŠ•å½±åˆ°å›¾åƒå¹³é¢
                    if z_cam > 0:  # ç¡®ä¿åœ¨ç›¸æœºå‰æ–¹
                        u = int(fx * x_cam / z_cam + cx)
                        v = int(fy * y_cam / z_cam + cy)
                        
                        # æ£€æŸ¥æ˜¯å¦åœ¨å›¾åƒèŒƒå›´å†…
                        if 0 <= u < image.shape[1] and 0 <= v < image.shape[0]:
                            color = colors[i % len(colors)]
                            
                            # ç»˜åˆ¶æŠ“å–ç‚¹
                            radius = max(5, int(20 * grasp['score'] / 0.1))  # æ ¹æ®åˆ†æ•°è°ƒæ•´å¤§å°
                            cv2.circle(annotated_image, (u, v), radius, color, -1)
                            
                            # ç»˜åˆ¶æŠ“å–è½®å»“ï¼ˆç®€åŒ–çš„å¤¹çˆªè¡¨ç¤ºï¼‰
                            gripper_size = int(grasp['width'] * 1000)  # è½¬æ¢ä¸ºåƒç´ 
                            gripper_size = max(10, min(50, gripper_size))  # é™åˆ¶å¤§å°
                            
                            # ç»˜åˆ¶å¤¹çˆªè½®å»“
                            cv2.rectangle(annotated_image, 
                                        (u - gripper_size//2, v - gripper_size//2),
                                        (u + gripper_size//2, v + gripper_size//2),
                                        color, 2)
                            
                            # æ·»åŠ æ–‡æœ¬æ ‡ç­¾
                            label = f"G{i+1}: {grasp['score']:.3f}"
                            cv2.putText(annotated_image, label, (u + 10, v - 10),
                                      cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
                            
                            print(f"  æŠ“å–{i+1}: ä¸–ç•Œ({world_pos[:3]}) -> ç›¸æœº({x_cam:.2f},{y_cam:.2f},{z_cam:.2f}) -> å›¾åƒ({u},{v})")
                    else:
                        print(f"  æŠ“å–{i+1}: åœ¨ç›¸æœºåæ–¹ï¼Œè·³è¿‡ (z_cam={z_cam:.2f})")
                        
                except Exception as draw_error:
                    print(f"ç»˜åˆ¶æŠ“å–{i+1}å¤±è´¥: {draw_error}")
                    continue
            
            # æ·»åŠ å›¾ä¾‹
            legend_y = 30
            for i, grasp in enumerate(grasps[:5]):  # æœ€å¤šæ˜¾ç¤º5ä¸ª
                color = colors[i % len(colors)]
                cv2.rectangle(annotated_image, (10, legend_y + i*25), (30, legend_y + i*25 + 15), color, -1)
                text = f"Grasp {i+1}: Score {grasp['score']:.3f}"
                cv2.putText(annotated_image, text, (35, legend_y + i*25 + 12),
                          cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
            
            return annotated_image
            
        except Exception as e:
            print(f"âŒ å›¾åƒæ ‡æ³¨å¤±è´¥: {e}")
            return image