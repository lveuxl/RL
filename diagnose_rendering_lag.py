#!/usr/bin/env python3
"""
ManiSkillæ¸²æŸ“æ€§èƒ½è¯Šæ–­å·¥å…·
åˆ†æå¯è§†åŒ–å¡é¡¿çš„æ ¹æœ¬åŸå› å¹¶æä¾›è§£å†³æ–¹æ¡ˆ
"""

import time
import os
import psutil
import torch
import numpy as np
import cv2
import gymnasium as gym
from typing import Dict, Any, List

# ManiSkillç›¸å…³å¯¼å…¥
import mani_skill.envs
from mani_skill.vector.wrappers.gymnasium import ManiSkillVectorEnv


class RenderingPerformanceDiagnostic:
    """æ¸²æŸ“æ€§èƒ½è¯Šæ–­å·¥å…·"""
    
    def __init__(self):
        self.results = {}
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
    def diagnose_all(self) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´è¯Šæ–­"""
        print("ğŸ” ManiSkillæ¸²æŸ“æ€§èƒ½è¯Šæ–­å¼€å§‹...")
        print("=" * 60)
        
        # 1. ç³»ç»Ÿç¯å¢ƒæ£€æŸ¥
        self.results['system'] = self._check_system_environment()
        
        # 2. GPUå’ŒCUDAæ£€æŸ¥
        self.results['gpu'] = self._check_gpu_status()
        
        # 3. ManiSkillç¯å¢ƒåˆ›å»ºæ€§èƒ½
        self.results['env_creation'] = self._test_env_creation_performance()
        
        # 4. æ¸²æŸ“è°ƒç”¨æ€§èƒ½
        self.results['rendering'] = self._test_rendering_performance()
        
        # 5. ä¸åŒæ¸²æŸ“æ¨¡å¼å¯¹æ¯”
        self.results['render_modes'] = self._test_different_render_modes()
        
        # 6. å†…å­˜ä½¿ç”¨åˆ†æ
        self.results['memory'] = self._analyze_memory_usage()
        
        # 7. ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š
        self._generate_diagnostic_report()
        
        return self.results
    
    def _check_system_environment(self) -> Dict[str, Any]:
        """æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒ"""
        print("1. ç³»ç»Ÿç¯å¢ƒæ£€æŸ¥...")
        
        system_info = {
            'python_version': f"{psutil.sys.version_info.major}.{psutil.sys.version_info.minor}",
            'cpu_count': psutil.cpu_count(),
            'memory_total_gb': psutil.virtual_memory().total / (1024**3),
            'memory_available_gb': psutil.virtual_memory().available / (1024**3),
            'platform': os.name
        }
        
        # æ£€æŸ¥OpenCV
        try:
            cv2_version = cv2.__version__
            system_info['opencv_version'] = cv2_version
        except:
            system_info['opencv_version'] = "æœªå®‰è£…"
        
        print(f"   Python: {system_info['python_version']}")
        print(f"   CPUæ ¸å¿ƒ: {system_info['cpu_count']}")
        print(f"   å†…å­˜: {system_info['memory_available_gb']:.1f}GB / {system_info['memory_total_gb']:.1f}GB")
        print(f"   OpenCV: {system_info['opencv_version']}")
        
        return system_info
    
    def _check_gpu_status(self) -> Dict[str, Any]:
        """æ£€æŸ¥GPUçŠ¶æ€"""
        print("\n2. GPUå’ŒCUDAæ£€æŸ¥...")
        
        gpu_info = {
            'cuda_available': torch.cuda.is_available(),
            'device_count': 0,
            'current_device': str(self.device)
        }
        
        if torch.cuda.is_available():
            gpu_info['device_count'] = torch.cuda.device_count()
            gpu_info['device_name'] = torch.cuda.get_device_name(0)
            gpu_info['cuda_version'] = torch.version.cuda
            
            # GPUå†…å­˜ä¿¡æ¯
            memory_allocated = torch.cuda.memory_allocated(0) / (1024**3)
            memory_reserved = torch.cuda.memory_reserved(0) / (1024**3)
            
            gpu_info['memory_allocated_gb'] = memory_allocated
            gpu_info['memory_reserved_gb'] = memory_reserved
            
            print(f"   CUDAå¯ç”¨: âœ…")
            print(f"   GPUè®¾å¤‡: {gpu_info['device_name']}")
            print(f"   CUDAç‰ˆæœ¬: {gpu_info['cuda_version']}")
            print(f"   GPUå†…å­˜: {memory_allocated:.2f}GB / {memory_reserved:.2f}GB")
        else:
            print(f"   CUDAå¯ç”¨: âŒ (å¯èƒ½å½±å“æ¸²æŸ“æ€§èƒ½)")
        
        return gpu_info
    
    def _test_env_creation_performance(self) -> Dict[str, Any]:
        """æµ‹è¯•ç¯å¢ƒåˆ›å»ºæ€§èƒ½"""
        print("\n3. ç¯å¢ƒåˆ›å»ºæ€§èƒ½æµ‹è¯•...")
        
        creation_times = []
        
        for i in range(3):
            start_time = time.time()
            
            try:
                # åˆ›å»ºæœ€ç®€å•çš„ç¯å¢ƒ
                env = gym.make(
                    "StackPickingManiSkill-v1",
                    num_envs=1,
                    obs_mode="state",
                    render_mode="rgb_array",
                    max_objects=3,
                    sim_backend="gpu" if torch.cuda.is_available() else "cpu"
                )
                
                # åŒ…è£…ç¯å¢ƒ
                vec_env = ManiSkillVectorEnv(env, 1, ignore_terminations=True)
                
                # é‡ç½®ç¯å¢ƒ
                vec_env.reset()
                
                creation_time = time.time() - start_time
                creation_times.append(creation_time)
                
                print(f"   ç¬¬{i+1}æ¬¡åˆ›å»º: {creation_time:.2f}ç§’")
                
                # å…³é—­ç¯å¢ƒ
                vec_env.close()
                
            except Exception as e:
                print(f"   ç¬¬{i+1}æ¬¡åˆ›å»ºå¤±è´¥: {e}")
                creation_times.append(float('inf'))
        
        avg_creation_time = np.mean([t for t in creation_times if t != float('inf')])
        
        creation_info = {
            'creation_times': creation_times,
            'avg_creation_time': avg_creation_time,
            'creation_success_rate': len([t for t in creation_times if t != float('inf')]) / len(creation_times)
        }
        
        print(f"   å¹³å‡åˆ›å»ºæ—¶é—´: {avg_creation_time:.2f}ç§’")
        
        return creation_info
    
    def _test_rendering_performance(self) -> Dict[str, Any]:
        """æµ‹è¯•æ¸²æŸ“æ€§èƒ½"""
        print("\n4. æ¸²æŸ“æ€§èƒ½æµ‹è¯•...")
        
        try:
            # åˆ›å»ºç¯å¢ƒ
            env = gym.make(
                "StackPickingManiSkill-v1",
                num_envs=1,
                obs_mode="state",
                render_mode="rgb_array",
                max_objects=3,
                sim_backend="gpu" if torch.cuda.is_available() else "cpu"
            )
            
            vec_env = ManiSkillVectorEnv(env, 1, ignore_terminations=True)
            vec_env.reset()
            
            # æµ‹è¯•å¤šæ¬¡æ¸²æŸ“
            render_times = []
            render_sizes = []
            
            for i in range(10):
                start_time = time.time()
                
                # æ‰§è¡Œæ¸²æŸ“
                rendered = vec_env.render()
                
                render_time = time.time() - start_time
                render_times.append(render_time)
                
                if rendered is not None:
                    if isinstance(rendered, np.ndarray):
                        render_sizes.append(rendered.shape)
                    elif isinstance(rendered, list) and len(rendered) > 0:
                        render_sizes.append(rendered[0].shape if hasattr(rendered[0], 'shape') else 'unknown')
                
                print(f"   ç¬¬{i+1}æ¬¡æ¸²æŸ“: {render_time*1000:.1f}ms")
            
            vec_env.close()
            
            avg_render_time = np.mean(render_times)
            max_render_time = np.max(render_times)
            min_render_time = np.min(render_times)
            
            render_info = {
                'render_times': render_times,
                'avg_render_time': avg_render_time,
                'max_render_time': max_render_time,
                'min_render_time': min_render_time,
                'render_sizes': render_sizes,
                'fps': 1.0 / avg_render_time if avg_render_time > 0 else 0
            }
            
            print(f"   å¹³å‡æ¸²æŸ“æ—¶é—´: {avg_render_time*1000:.1f}ms")
            print(f"   æ¸²æŸ“FPS: {render_info['fps']:.1f}")
            print(f"   å›¾åƒå°ºå¯¸: {render_sizes[0] if render_sizes else 'unknown'}")
            
            return render_info
            
        except Exception as e:
            print(f"   æ¸²æŸ“æµ‹è¯•å¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _test_different_render_modes(self) -> Dict[str, Any]:
        """æµ‹è¯•ä¸åŒæ¸²æŸ“æ¨¡å¼"""
        print("\n5. ä¸åŒæ¸²æŸ“æ¨¡å¼å¯¹æ¯”...")
        
        render_modes = ["rgb_array", "human"]
        mode_results = {}
        
        for mode in render_modes:
            print(f"   æµ‹è¯•æ¸²æŸ“æ¨¡å¼: {mode}")
            
            try:
                start_time = time.time()
                
                env = gym.make(
                    "StackPickingManiSkill-v1",
                    num_envs=1,
                    obs_mode="state",
                    render_mode=mode,
                    max_objects=3,
                    sim_backend="gpu" if torch.cuda.is_available() else "cpu"
                )
                
                vec_env = ManiSkillVectorEnv(env, 1, ignore_terminations=True)
                vec_env.reset()
                
                # æµ‹è¯•å‡ æ¬¡æ¸²æŸ“
                render_times = []
                for _ in range(3):
                    render_start = time.time()
                    vec_env.render()
                    render_times.append(time.time() - render_start)
                
                vec_env.close()
                
                total_time = time.time() - start_time
                avg_render_time = np.mean(render_times)
                
                mode_results[mode] = {
                    'total_time': total_time,
                    'avg_render_time': avg_render_time,
                    'success': True
                }
                
                print(f"     æ€»æ—¶é—´: {total_time:.2f}s, å¹³å‡æ¸²æŸ“: {avg_render_time*1000:.1f}ms")
                
            except Exception as e:
                print(f"     å¤±è´¥: {e}")
                mode_results[mode] = {
                    'error': str(e),
                    'success': False
                }
        
        return mode_results
    
    def _analyze_memory_usage(self) -> Dict[str, Any]:
        """åˆ†æå†…å­˜ä½¿ç”¨"""
        print("\n6. å†…å­˜ä½¿ç”¨åˆ†æ...")
        
        process = psutil.Process()
        initial_memory = process.memory_info().rss / (1024**2)  # MB
        
        print(f"   åˆå§‹å†…å­˜: {initial_memory:.1f}MB")
        
        try:
            # åˆ›å»ºç¯å¢ƒå¹¶è¿è¡Œä¸€äº›æ­¥éª¤
            env = gym.make(
                "StackPickingManiSkill-v1",
                num_envs=1,
                obs_mode="state",
                render_mode="rgb_array",
                max_objects=3,
                sim_backend="gpu" if torch.cuda.is_available() else "cpu"
            )
            
            vec_env = ManiSkillVectorEnv(env, 1, ignore_terminations=True)
            vec_env.reset()
            
            after_creation_memory = process.memory_info().rss / (1024**2)
            print(f"   åˆ›å»ºç¯å¢ƒå: {after_creation_memory:.1f}MB (+{after_creation_memory-initial_memory:.1f}MB)")
            
            # æ‰§è¡Œä¸€äº›æ¸²æŸ“
            for i in range(5):
                vec_env.render()
                current_memory = process.memory_info().rss / (1024**2)
                print(f"   ç¬¬{i+1}æ¬¡æ¸²æŸ“å: {current_memory:.1f}MB")
            
            final_memory = process.memory_info().rss / (1024**2)
            vec_env.close()
            
            memory_info = {
                'initial_memory_mb': initial_memory,
                'after_creation_mb': after_creation_memory,
                'final_memory_mb': final_memory,
                'creation_overhead_mb': after_creation_memory - initial_memory,
                'total_increase_mb': final_memory - initial_memory
            }
            
            return memory_info
            
        except Exception as e:
            print(f"   å†…å­˜åˆ†æå¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _generate_diagnostic_report(self):
        """ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("ğŸ”§ è¯Šæ–­æŠ¥å‘Šå’Œå»ºè®®")
        print("=" * 60)
        
        # ç³»ç»Ÿå»ºè®®
        if not self.results['gpu']['cuda_available']:
            print("âš ï¸  CUDAä¸å¯ç”¨ - å»ºè®®:")
            print("   â€¢ å®‰è£…æ”¯æŒCUDAçš„PyTorchç‰ˆæœ¬")
            print("   â€¢ æ£€æŸ¥GPUé©±åŠ¨ç¨‹åº")
            print("   â€¢ ä½¿ç”¨GPUåŠ é€Ÿå¯æ˜¾è‘—æå‡æ¸²æŸ“æ€§èƒ½")
        
        # æ¸²æŸ“æ€§èƒ½å»ºè®®
        if 'rendering' in self.results and 'avg_render_time' in self.results['rendering']:
            avg_time = self.results['rendering']['avg_render_time']
            
            if avg_time > 0.1:  # 100ms
                print("âŒ æ¸²æŸ“æ€§èƒ½è¾ƒå·® - å»ºè®®:")
                print("   â€¢ é™ä½æ¸²æŸ“åˆ†è¾¨ç‡")
                print("   â€¢ å‡å°‘æ¸²æŸ“é¢‘ç‡")
                print("   â€¢ ä½¿ç”¨rgb_arrayè€Œéhumanæ¨¡å¼")
                print("   â€¢ å‡å°‘åœºæ™¯å¤æ‚åº¦ï¼ˆç‰©ä½“æ•°é‡ï¼‰")
            elif avg_time > 0.05:  # 50ms
                print("âš ï¸  æ¸²æŸ“æ€§èƒ½ä¸€èˆ¬ - å»ºè®®:")
                print("   â€¢ è€ƒè™‘é™ä½æ¸²æŸ“é¢‘ç‡")
                print("   â€¢ ä½¿ç”¨å¼‚æ­¥æ¸²æŸ“")
            else:
                print("âœ… æ¸²æŸ“æ€§èƒ½è‰¯å¥½")
        
        # å†…å­˜ä½¿ç”¨å»ºè®®
        if 'memory' in self.results and 'total_increase_mb' in self.results['memory']:
            memory_increase = self.results['memory']['total_increase_mb']
            
            if memory_increase > 500:  # 500MB
                print("âš ï¸  å†…å­˜ä½¿ç”¨è¾ƒé«˜ - å»ºè®®:")
                print("   â€¢ å®šæœŸæ¸…ç†GPUç¼“å­˜")
                print("   â€¢ å‡å°‘å¹¶è¡Œç¯å¢ƒæ•°é‡")
                print("   â€¢ æ£€æŸ¥æ˜¯å¦å­˜åœ¨å†…å­˜æ³„æ¼")
        
        # å…·ä½“ä¼˜åŒ–å»ºè®®
        print("\nğŸš€ é’ˆå¯¹å¯è§†åŒ–å¡é¡¿çš„å…·ä½“ä¼˜åŒ–å»ºè®®:")
        print("1. ä½¿ç”¨è¶…è½»é‡çº§å¯è§†åŒ–å›è°ƒ")
        print("2. è®¾ç½®æ¸²æŸ“é¢‘ç‡ä¸º500æ­¥ä»¥ä¸Š")
        print("3. é™åˆ¶æœ€å¤§FPSä¸º5")
        print("4. ä½¿ç”¨rgb_arrayæ¨¡å¼è€Œéhumanæ¨¡å¼")
        print("5. é™ä½æ¸²æŸ“åˆ†è¾¨ç‡è‡³256x256")
        print("6. å‡å°‘åœºæ™¯ç‰©ä½“æ•°é‡è‡³6ä¸ªä»¥ä¸‹")


def main():
    """ä¸»å‡½æ•°"""
    print("ManiSkillæ¸²æŸ“æ€§èƒ½è¯Šæ–­å·¥å…·")
    print("åˆ†æå¯è§†åŒ–å¡é¡¿é—®é¢˜å¹¶æä¾›è§£å†³æ–¹æ¡ˆ")
    
    diagnostic = RenderingPerformanceDiagnostic()
    results = diagnostic.diagnose_all()
    
    # ä¿å­˜è¯Šæ–­ç»“æœ
    import json
    with open('rendering_diagnostic_report.json', 'w') as f:
        # è½¬æ¢numpyæ•°ç»„ä¸ºåˆ—è¡¨ä»¥ä¾¿JSONåºåˆ—åŒ–
        def convert_for_json(obj):
            if isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, np.float32) or isinstance(obj, np.float64):
                return float(obj)
            elif isinstance(obj, (np.int32, np.int64)):
                return int(obj)
            return obj
        
        def recursive_convert(obj):
            if isinstance(obj, dict):
                return {k: recursive_convert(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [recursive_convert(v) for v in obj]
            else:
                return convert_for_json(obj)
        
        json.dump(recursive_convert(results), f, indent=2)
    
    print(f"\nğŸ“„ å®Œæ•´è¯Šæ–­æŠ¥å‘Šå·²ä¿å­˜è‡³: rendering_diagnostic_report.json")


if __name__ == "__main__":
    main() 