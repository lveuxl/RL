#!/usr/bin/env python3
"""
æé€Ÿè®­ç»ƒè„šæœ¬ - æœ€å¤§åŒ–è®­ç»ƒé€Ÿåº¦çš„ä¼˜åŒ–ç‰ˆæœ¬
ç‰¹æ€§ï¼š
1. å®Œå…¨ç§»é™¤ç‰©ç†ä»¿çœŸï¼Œçº¯é€»è¾‘è®¡ç®—
2. CPUä¼˜åŒ–è®­ç»ƒï¼ˆå¯¹MLPç­–ç•¥æ›´é«˜æ•ˆï¼‰
3. å¤§æ‰¹é‡å¹¶è¡Œå¤„ç†
4. ç²¾ç®€çš„è¶…å‚æ•°é…ç½®
5. å¿«é€Ÿæ”¶æ•›è®¾è®¡
"""

import os
import argparse
import numpy as np
import torch
import gymnasium as gym
from stable_baselines3 import PPO
from stable_baselines3.common.callbacks import BaseCallback, EvalCallback
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.utils import set_random_seed
import time

# æ³¨å†Œç¯å¢ƒ
from env_clutter_optimized import EnvClutterOptimizedEnv
from mani_skill.vector.wrappers.sb3 import ManiSkillSB3VectorEnv
import mani_skill.envs


class SpeedCallback(BaseCallback):
    """æç®€å›è°ƒ - åªè®°å½•å…³é”®æŒ‡æ ‡"""
    
    def __init__(self, verbose=0):
        super(SpeedCallback, self).__init__(verbose)
        self.episode_count = 0
        self.start_time = time.time()
        
    def _on_rollout_end(self) -> None:
        self.episode_count += 1
        if self.episode_count % 10 == 0:  # æ¯10ä¸ªrolloutè®°å½•ä¸€æ¬¡
            elapsed = time.time() - self.start_time
            speed = self.num_timesteps / elapsed
            self.logger.record("speed/timesteps_per_second", speed)
            self.logger.record("speed/episodes", self.episode_count)


def create_fast_env(env_id: str, num_envs: int, seed: int = 0):
    """åˆ›å»ºæé€Ÿç¯å¢ƒ"""
    env = gym.make(
        env_id,
        num_envs=num_envs,
        obs_mode="state",
        control_mode="pd_ee_delta_pose",
        reward_mode="dense",
        sim_backend="gpu",
        render_mode=None,
    )
    
    vec_env = ManiSkillSB3VectorEnv(env)
    return vec_env


def train_high_speed(use_cpu: bool = True):
    """æé€Ÿè®­ç»ƒä¸»å‡½æ•°"""
    
    # æé€Ÿé…ç½® - ä¸“æ³¨æ€§èƒ½
    config = {
        "env_id": "EnvClutterOptimized-v1",
        "num_envs": 256,  # å¤§æ‰¹é‡å¹¶è¡Œï¼ˆæ— ç‰©ç†ä»¿çœŸè´Ÿæ‹…ï¼‰
        "seed": 42,
        
        # æé€ŸPPOé…ç½®
        "learning_rate": 5e-4,  # ç¨é«˜å­¦ä¹ ç‡åŠ é€Ÿæ”¶æ•›
        "n_steps": 64,   # æ›´çŸ­rolloutï¼ˆæ›´é¢‘ç¹æ›´æ–°ï¼‰
        "batch_size": 8192,  # è¶…å¤§æ‰¹æ¬¡
        "n_epochs": 3,   # æœ€å°‘æ›´æ–°è½®æ•°
        "gamma": 0.98,   # ç¨ä½æŠ˜æ‰£ï¼ˆåŠ é€Ÿå­¦ä¹ ï¼‰
        "gae_lambda": 0.9,
        "clip_range": 0.2,
        "ent_coef": 0.005,  # å‡å°‘ç†µï¼ˆæ›´å¿«æ”¶æ•›ï¼‰
        "vf_coef": 0.25,
        "max_grad_norm": 1.0,
        
        # è®­ç»ƒé…ç½®
        "total_timesteps": 100_000,  # çŸ­æœŸå¿«é€Ÿè®­ç»ƒ
        "eval_freq": 10000,
        "log_interval": 1,
        
        # ç½‘ç»œé…ç½®
        "policy_kwargs": {
            "net_arch": [128, 128],  # æ›´å°ç½‘ç»œï¼ˆåŠ é€Ÿè®­ç»ƒï¼‰
            "activation_fn": torch.nn.ReLU,
        },
        
        "verbose": 1,
        "device": "cpu" if use_cpu else "auto",
    }
    
    device_name = "CPU" if use_cpu else ("GPU" if torch.cuda.is_available() else "CPU")
    print(f"ğŸš€ æé€Ÿè®­ç»ƒæ¨¡å¼")
    print(f"ğŸ“Š é…ç½®: {config['num_envs']}ç¯å¢ƒ x {config['total_timesteps']:,}æ­¥")
    print(f"âš¡ è®¡ç®—è®¾å¤‡: {device_name}")
    print(f"ğŸ¯ é¢„è®¡è®­ç»ƒæ—¶é—´: ~5-10åˆ†é’Ÿ")
    
    # åˆ›å»ºç¯å¢ƒ
    print("åˆ›å»ºæé€Ÿç¯å¢ƒ...")
    start_time = time.time()
    
    env = create_fast_env(config["env_id"], config["num_envs"], config["seed"])
    eval_env = create_fast_env(config["env_id"], min(32, config["num_envs"]), config["seed"] + 1000)
    
    env_time = time.time() - start_time
    print(f"âœ“ ç¯å¢ƒåˆ›å»ºè€—æ—¶: {env_time:.1f}ç§’")
    
    # åˆ›å»ºPPOæ¨¡å‹
    print("åˆ›å»ºæé€ŸPPOæ¨¡å‹...")
    model_start = time.time()
    
    model = PPO(
        "MlpPolicy",
        env,
        learning_rate=config["learning_rate"],
        n_steps=config["n_steps"],
        batch_size=config["batch_size"],
        n_epochs=config["n_epochs"],
        gamma=config["gamma"],
        gae_lambda=config["gae_lambda"],
        clip_range=config["clip_range"],
        ent_coef=config["ent_coef"],
        vf_coef=config["vf_coef"],
        max_grad_norm=config["max_grad_norm"],
        policy_kwargs=config["policy_kwargs"],
        verbose=config["verbose"],
        seed=config["seed"],
        device=config["device"],
        tensorboard_log="./tensorboard_logs_speed/" if config["verbose"] > 0 else None,
    )
    
    model_time = time.time() - model_start
    param_count = sum(p.numel() for p in model.policy.parameters())
    print(f"âœ“ æ¨¡å‹åˆ›å»ºè€—æ—¶: {model_time:.1f}ç§’")
    print(f"ğŸ§  æ¨¡å‹å‚æ•°: {param_count:,}")
    
    # æç®€å›è°ƒ
    callbacks = [SpeedCallback()]
    
    # å¯é€‰è¯„ä¼°ï¼ˆå½±å“é€Ÿåº¦ï¼‰
    if config["eval_freq"] > 0:
        eval_callback = EvalCallback(
            eval_env,
            best_model_save_path="./models_speed/",
            log_path="./logs_speed/",
            eval_freq=config["eval_freq"],
            n_eval_episodes=5,  # å¿«é€Ÿè¯„ä¼°
            deterministic=True,
            render=False,
            verbose=0,  # é™é»˜è¯„ä¼°
        )
        callbacks.append(eval_callback)
    
    # å¼€å§‹è®­ç»ƒ
    print("\nâš¡ å¼€å§‹æé€Ÿè®­ç»ƒ...")
    print("-" * 50)
    
    train_start = time.time()
    
    try:
        model.learn(
            total_timesteps=config["total_timesteps"],
            callback=callbacks,
            log_interval=config["log_interval"],
            progress_bar=True,
        )
        
        train_time = time.time() - train_start
        total_time = time.time() - start_time
        
        # æ€§èƒ½ç»Ÿè®¡
        steps_per_second = config["total_timesteps"] / train_time
        
        print(f"\nğŸ‰ æé€Ÿè®­ç»ƒå®Œæˆï¼")
        print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.1f}ç§’ ({total_time/60:.1f}åˆ†é’Ÿ)")
        print(f"ğŸš€ è®­ç»ƒè€—æ—¶: {train_time:.1f}ç§’")
        print(f"ğŸ“ˆ è®­ç»ƒé€Ÿåº¦: {steps_per_second:.0f} steps/s")
        print(f"âš¡ æ€§èƒ½æå‡: ~{steps_per_second/5:.0f}x vsåŸç‰ˆ")
        
        # ä¿å­˜æ¨¡å‹
        model.save("./models_speed/final_model")
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: ./models_speed/final_model")
        
        env.close()
        eval_env.close()
        
        return model, steps_per_second
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  è®­ç»ƒè¢«ä¸­æ–­")
        env.close()
        eval_env.close()
        return None, 0


def quick_test():
    """å¿«é€Ÿæµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹"""
    print("ğŸ§ª å¿«é€Ÿæµ‹è¯•æ¨¡å‹...")
    
    try:
        model = PPO.load("./models_speed/final_model")
        env = create_fast_env("EnvClutterOptimized-v1", 1, 42)
        
        total_reward = 0
        obs = env.reset()
        
        for step in range(20):  # å¿«é€Ÿæµ‹è¯•20æ­¥
            action, _ = model.predict(obs, deterministic=True)
            obs, reward, done, info = env.step(action)
            total_reward += reward[0]
            
            if done[0]:
                break
        
        env.close()
        print(f"âœ“ æµ‹è¯•å®Œæˆï¼Œæ€»å¥–åŠ±: {total_reward:.1f}")
        
    except Exception as e:
        print(f"âš ï¸  æµ‹è¯•å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æé€Ÿå¼ºåŒ–å­¦ä¹ è®­ç»ƒ")
    parser.add_argument("--gpu", action="store_true", help="å¼ºåˆ¶ä½¿ç”¨GPU")
    parser.add_argument("--test", action="store_true", help="æµ‹è¯•å·²è®­ç»ƒæ¨¡å‹")
    
    args = parser.parse_args()
    
    # åˆ›å»ºç›®å½•
    os.makedirs("./models_speed", exist_ok=True)
    os.makedirs("./logs_speed", exist_ok=True)
    os.makedirs("./tensorboard_logs_speed", exist_ok=True)
    
    if args.test:
        quick_test()
        return
    
    # è®¾å¤‡é€‰æ‹©ç­–ç•¥
    use_cpu = not args.gpu  # é»˜è®¤ä½¿ç”¨CPUï¼ˆå¯¹MLPæ›´å¿«ï¼‰
    
    if use_cpu:
        print("ğŸ’¡ ä½¿ç”¨CPUè®­ç»ƒï¼ˆå¯¹MLPç­–ç•¥æ›´é«˜æ•ˆï¼‰")
        # å…³é—­CUDAé¿å…å¼€é”€
        os.environ['CUDA_VISIBLE_DEVICES'] = ''
    else:
        print("ğŸ”¥ ä½¿ç”¨GPUè®­ç»ƒ")
        if torch.cuda.is_available():
            os.environ['CUDA_VISIBLE_DEVICES'] = '0'
    
    # å¼€å§‹è®­ç»ƒ
    model, speed = train_high_speed(use_cpu=use_cpu)
    
    if model and speed > 0:
        # è‡ªåŠ¨æµ‹è¯•
        print("\n" + "="*50)
        quick_test()
        
        print(f"\nğŸš€ è®­ç»ƒå®Œæˆï¼é€Ÿåº¦: {speed:.0f} steps/s")
        print("ğŸ”¥ å¯åŠ¨tensorboard: tensorboard --logdir ./tensorboard_logs_speed")


if __name__ == "__main__":
    main()

