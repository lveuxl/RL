#!/usr/bin/env python3
"""
ç†æƒ³åŒ–æŠ“å–é¡ºåºå­¦ä¹ ç¯å¢ƒæµ‹è¯•
ä¸»è¦ç‰¹æ€§ï¼š
1. æµ‹è¯•æŠ“å–é¡ºåºå­¦ä¹ ä»»åŠ¡ - æ¯å›åˆæŠ“å–9ä¸ªç‰©ä½“
2. éªŒè¯å¥–åŠ±å‡½æ•°ä¼˜å…ˆçº§ - æŠ“å–æˆåŠŸ > ä½ç§»å° > æ—¶é—´çŸ­
3. æ£€éªŒåŠ¨ä½œæ©ç æ›´æ–°æœºåˆ¶ - ç¡®ä¿å¹¶è¡Œç¯å¢ƒç´¢å¼•æ­£ç¡®
4. æ”¯æŒè§†é¢‘å½•åˆ¶ - è§‚å¯ŸæŠ“å–é¡ºåºå­¦ä¹ æ•ˆæœ
"""

import os
import sys
import torch
import numpy as np
import gymnasium as gym
import time

# å¯¼å…¥ä¿®æ­£åçš„ç¯å¢ƒä»¥ç¡®ä¿æ³¨å†Œ
import sys
import os
sys.path.append(os.getcwd())

# å¯¼å…¥ç¯å¢ƒä»¥ç¡®ä¿æ³¨å†Œ
try:
    # å°è¯•å¯¼å…¥copyç‰ˆæœ¬ï¼ˆæ–°çš„æŠ“å–é¡ºåºå­¦ä¹ ç¯å¢ƒï¼‰
    from env_clutter import EnvClutterEnv
    print("âœ… ä½¿ç”¨env_clutterç¯å¢ƒï¼ˆæŠ“å–é¡ºåºå­¦ä¹ ç‰ˆæœ¬ï¼‰")
except ImportError:
    try:
        # å›é€€åˆ°åŸå§‹ç¯å¢ƒ
        from env_clutter import EnvClutterEnv
        print("âš ï¸ ä½¿ç”¨åŸå§‹env_clutterç¯å¢ƒï¼ˆå¯èƒ½åŠŸèƒ½ä¸å®Œæ•´ï¼‰")
    except ImportError as e:
        print(f"âŒ ç¯å¢ƒå¯¼å…¥å¤±è´¥: {e}")
        raise

import mani_skill.envs
from mani_skill.utils.wrappers.record import RecordEpisode
from mani_skill.vector.wrappers.gymnasium import ManiSkillVectorEnv


def test_ideal_grasp_sequence():
    """æµ‹è¯•ç†æƒ³åŒ–æŠ“å–é¡ºåºå­¦ä¹ ç¯å¢ƒ"""
    print("=== ç†æƒ³åŒ–æŠ“å–é¡ºåºå­¦ä¹ ç¯å¢ƒæµ‹è¯• ===")
    print("ğŸ¯ ä»»åŠ¡ç›®æ ‡ï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ æŒ‘é€‰æœ€é€‚åˆçš„æŠ“å–é¡ºåº")
    print("ğŸ“‹ ä»»åŠ¡è¦æ±‚ï¼šæ¯å›åˆæŠ“å–9ä¸ªç‰©ä½“")
    print("ğŸ† å¥–åŠ±ä¼˜å…ˆçº§ï¼š1.æŠ“å–æˆåŠŸ 2.å…¶ä»–ç‰©ä½“ä½ç§»å° 3.æ€»æ—¶é—´çŸ­")
    print("ğŸ”§ æµ‹è¯•å†…å®¹ï¼šåŠ¨ä½œæ©ç æ›´æ–°ã€å¹¶è¡Œç¯å¢ƒç´¢å¼•ã€å¥–åŠ±å‡½æ•°")
    print()
    
    # é…ç½®æµ‹è¯•å‚æ•°
    num_envs = 2  # æµ‹è¯•2ä¸ªå¹¶è¡Œç¯å¢ƒä»¥éªŒè¯æ©ç æ›´æ–°
    capture_video = True
    save_trajectory = False
    test_name = f"ideal_grasp_sequence_{int(time.time())}"
    video_output_dir = f"test_videos/{test_name}"
    
    # åˆ›å»ºç†æƒ³åŒ–æŠ“å–ç¯å¢ƒ
    try:
        env = gym.make(
            "EnvClutter-v1",
            render_mode="rgb_array",
            obs_mode="state", 
            control_mode="pd_ee_delta_pose",
            reward_mode="dense",  # ä½¿ç”¨å¯†é›†å¥–åŠ±ä»¥è§‚å¯Ÿå­¦ä¹ è¿‡ç¨‹
            sim_backend="gpu",
            use_discrete_action=True,  # å¯ç”¨ç¦»æ•£åŠ¨ä½œé€‰æ‹©
            use_ideal_oracle=True,     # å¯ç”¨ç†æƒ³åŒ–ç¥è°•æŠ“å–
            num_envs=num_envs
        )
        
        print(f"âœ… ç†æƒ³åŒ–æŠ“å–ç¯å¢ƒåˆ›å»ºæˆåŠŸ (ç¯å¢ƒæ•°: {num_envs})")
        print(f"ğŸ¯ ç›®æ ‡ç‰©ä½“æ•°é‡: {env.unwrapped.total_objects_per_env}")
        print(f"ğŸ® åŠ¨ä½œç©ºé—´å¤§å°: {env.unwrapped.MAX_N}")
        print()
        
    except Exception as e:
        print(f"âŒ ç¯å¢ƒåˆ›å»ºå¤±è´¥: {e}")
        return
    
    # æ·»åŠ è§†é¢‘å½•åˆ¶åŒ…è£…å™¨
    if capture_video or save_trajectory:
        os.makedirs(video_output_dir, exist_ok=True)
        print(f"ğŸ“¹ è§†é¢‘å°†ä¿å­˜åˆ°: {video_output_dir}")
        
        try:
            env = RecordEpisode(
                env,
                output_dir=video_output_dir,
                save_trajectory=save_trajectory,
                save_video=capture_video,
                trajectory_name="ideal_grasp_sequence",
                max_steps_per_video=3000,  # è¶³å¤Ÿé•¿ä»¥è§‚å¯Ÿå®Œæ•´çš„9æ¬¡æŠ“å–æµç¨‹
                video_fps=30,
                render_substeps=True,
                info_on_video=True,
            )
            print("âœ… è§†é¢‘å½•åˆ¶åŒ…è£…å™¨æ·»åŠ æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ è§†é¢‘å½•åˆ¶åŒ…è£…å™¨æ·»åŠ å¤±è´¥: {e}")
    
    # æ·»åŠ å‘é‡åŒ–åŒ…è£…å™¨
    try:
        env = ManiSkillVectorEnv(env, 1, ignore_terminations=False, record_metrics=True)
        print("âœ… å‘é‡åŒ–åŒ…è£…å™¨æ·»åŠ æˆåŠŸ")
    except Exception as e:
        print(f"âŒ å‘é‡åŒ–åŒ…è£…å™¨æ·»åŠ å¤±è´¥: {e}")
        return

    try:
        # æµ‹è¯•æŠ“å–é¡ºåºå­¦ä¹ 
        total_episodes = 2
        success_stats = []
        
        for episode in range(total_episodes):
            print(f"\nğŸ® === æŠ“å–é¡ºåºå­¦ä¹ æµ‹è¯• {episode + 1}/{total_episodes} ===")
            
            obs, info = env.reset()
            episode_start_time = time.time()
            
            unwrapped_env = env.unwrapped
            
            # éªŒè¯ç¯å¢ƒåˆå§‹åŒ–çŠ¶æ€
            print(f"ğŸ” ç¯å¢ƒåˆå§‹åŒ–éªŒè¯:")
            if hasattr(unwrapped_env, 'remaining_indices'):
                for env_idx in range(num_envs):
                    remaining = len(unwrapped_env.remaining_indices[env_idx])
                    grasped = len(unwrapped_env.grasped_objects[env_idx])
                    print(f"  ç¯å¢ƒ{env_idx}: å‰©ä½™ç‰©ä½“={remaining}, å·²æŠ“å–={grasped}")
            
            # éªŒè¯è§‚æµ‹ç»“æ„å’ŒåŠ¨ä½œæ©ç 
            print(f"ğŸ” è§‚æµ‹ç»“æ„éªŒè¯:")
            print(f"  è§‚æµ‹ç»´åº¦: {obs.shape}")
            
            # æ ¹æ®æ–°çš„è§‚æµ‹ç»“æ„æå–æ©ç 
            total_objects = unwrapped_env.total_objects_per_env
            mask_start = total_objects * 8
            mask_end = mask_start + total_objects
            
            if obs.shape[-1] >= mask_end:
                action_mask = obs[0, mask_start:mask_end]  # æå–ç¬¬ä¸€ä¸ªç¯å¢ƒçš„æ©ç 
                print(f"  åŠ¨ä½œæ©ç : {action_mask.cpu().numpy() if hasattr(action_mask, 'cpu') else action_mask}")
                available_actions = torch.sum(action_mask).item() if hasattr(action_mask, 'sum') else np.sum(action_mask)
                print(f"  å¯ç”¨åŠ¨ä½œæ•°: {available_actions}")
            else:
                print(f"  âš ï¸ è§‚æµ‹ç»´åº¦ä¸è¶³ï¼Œæ— æ³•æå–æ©ç ")
            
            # æ¨¡æ‹Ÿæ™ºèƒ½æŠ“å–é¡ºåºç­–ç•¥ï¼ˆç”¨äºæ¼”ç¤ºï¼‰
            # ç­–ç•¥ï¼šä¼˜å…ˆé€‰æ‹©æš´éœ²åº¦æœ€é«˜çš„ç‰©ä½“ï¼ˆæ¨¡æ‹Ÿç†æƒ³çš„æŠ“å–é¡ºåºï¼‰
            episode_rewards = []
            episode_actions = []
            step_count = 0
            max_steps_per_episode = unwrapped_env.total_objects_per_env + 2  # æœ€å¤šæŠ“å–æ¬¡æ•°
            
            print(f"\nğŸš€ å¼€å§‹æŠ“å–é¡ºåºæµ‹è¯•ï¼ˆæœ€å¤š{max_steps_per_episode}æ¬¡æŠ“å–ï¼‰...")
            
            while step_count < max_steps_per_episode:
                # é€‰æ‹©åŠ¨ä½œç­–ç•¥ï¼šå¯¹äºæ¯ä¸ªç¯å¢ƒé€‰æ‹©ä¸åŒçš„æŠ“å–ç­–ç•¥
                actions = []
                
                for env_idx in range(num_envs):
                    if hasattr(unwrapped_env, 'remaining_indices') and env_idx < len(unwrapped_env.remaining_indices):
                        remaining_indices = unwrapped_env.remaining_indices[env_idx]
                        
                        if remaining_indices:
                            # ç­–ç•¥1: ç¯å¢ƒ0ä½¿ç”¨é¡ºåºæŠ“å–ï¼ˆä»ä¸Šåˆ°ä¸‹ï¼‰
                            # ç­–ç•¥2: ç¯å¢ƒ1ä½¿ç”¨é€†åºæŠ“å–ï¼ˆä»ä¸‹åˆ°ä¸Šï¼‰
                            if env_idx == 0:
                                action = 0  # é€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨ç‰©ä½“
                            else:
                                action = len(remaining_indices) - 1  # é€‰æ‹©æœ€åä¸€ä¸ªå¯ç”¨ç‰©ä½“
                                
                            # ç¡®ä¿åŠ¨ä½œæœ‰æ•ˆ
                            action = max(0, min(action, len(remaining_indices) - 1))
                            target_obj_idx = remaining_indices[action]
                            actions.append(action)
                            print(f"  ğŸ“ ç¯å¢ƒ{env_idx}: é€‰æ‹©åŠ¨ä½œ{action} -> ç›®æ ‡ç‰©ä½“{target_obj_idx} (å‰©ä½™{len(remaining_indices)}ä¸ª)")
                        else:
                            actions.append(0)  # æ²¡æœ‰å¯æŠ“å–ç‰©ä½“æ—¶çš„é»˜è®¤åŠ¨ä½œ
                            print(f"  â­• ç¯å¢ƒ{env_idx}: æ— å¯æŠ“å–ç‰©ä½“ï¼Œä½¿ç”¨é»˜è®¤åŠ¨ä½œ")
                    else:
                        actions.append(0)
                        print(f"  âš ï¸ ç¯å¢ƒ{env_idx}: çŠ¶æ€å¼‚å¸¸ï¼Œä½¿ç”¨é»˜è®¤åŠ¨ä½œ")
                
                # æ‰§è¡ŒåŠ¨ä½œ
                action_array = np.array(actions)
                episode_actions.append(actions.copy())
                
                obs, reward, terminated, truncated, info = env.step(action_array)
                step_count += 1
                
                # è®°å½•å¥–åŠ±å’ŒçŠ¶æ€
                episode_rewards.append(reward.cpu().numpy() if hasattr(reward, 'cpu') else reward)
                
                print(f"  ğŸ¯ æ­¥éª¤{step_count}: åŠ¨ä½œ={actions}, å¥–åŠ±={reward}")
                
                # éªŒè¯æŠ“å–æ•ˆæœå’Œæ©ç æ›´æ–°
                if hasattr(unwrapped_env, 'grasped_objects'):
                    for env_idx in range(num_envs):
                        if env_idx < len(unwrapped_env.grasped_objects):
                            grasped_count = len(unwrapped_env.grasped_objects[env_idx])
                            remaining_count = len(unwrapped_env.remaining_indices[env_idx])
                            print(f"    ç¯å¢ƒ{env_idx}: å·²æŠ“å–={grasped_count}, å‰©ä½™={remaining_count}")
                
                # æ£€æŸ¥ç»ˆæ­¢æ¡ä»¶
                if isinstance(terminated, (np.ndarray, torch.Tensor)):
                    if hasattr(terminated, 'any'):
                        if terminated.any():
                            print(f"  ğŸ éƒ¨åˆ†ç¯å¢ƒè¾¾åˆ°ç»ˆæ­¢æ¡ä»¶")
                            break
                    elif np.any(terminated):
                        print(f"  ğŸ éƒ¨åˆ†ç¯å¢ƒè¾¾åˆ°ç»ˆæ­¢æ¡ä»¶")
                        break
                elif terminated:
                    print(f"  ğŸ ç¯å¢ƒè¾¾åˆ°ç»ˆæ­¢æ¡ä»¶")
                    break
                
                # æ£€æŸ¥æ˜¯å¦å®Œæˆæ‰€æœ‰æŠ“å–
                all_completed = True
                for env_idx in range(num_envs):
                    if hasattr(unwrapped_env, 'grasped_objects') and env_idx < len(unwrapped_env.grasped_objects):
                        grasped_count = len(unwrapped_env.grasped_objects[env_idx])
                        if grasped_count < unwrapped_env.total_objects_per_env:
                            all_completed = False
                            break
                
                if all_completed:
                    print(f"  âœ… æ‰€æœ‰ç¯å¢ƒå®Œæˆç›®æ ‡æŠ“å–ä»»åŠ¡ï¼")
                    break
            
            episode_end_time = time.time()
            episode_duration = episode_end_time - episode_start_time
            
            # ç»Ÿè®¡æœ¬episodeç»“æœ
            print(f"\nğŸ“Š Episode {episode + 1} ç»“æœç»Ÿè®¡:")
            print(f"  â±ï¸ æ€»è€—æ—¶: {episode_duration:.2f}ç§’")
            print(f"  ğŸ”„ æ€»æ­¥æ•°: {step_count}")
            print(f"  ğŸ’° ç´¯è®¡å¥–åŠ±: {np.sum(episode_rewards):.3f}")
            print(f"  ğŸ“ˆ å¹³å‡æ­¥éª¤å¥–åŠ±: {np.mean(episode_rewards):.3f}")
            
            # å„ç¯å¢ƒæœ€ç»ˆæˆæœ
            env_success_info = []
            for env_idx in range(num_envs):
                if hasattr(unwrapped_env, 'grasped_objects') and env_idx < len(unwrapped_env.grasped_objects):
                    grasped_count = len(unwrapped_env.grasped_objects[env_idx])
                    total_objects = unwrapped_env.total_objects_per_env
                    success_rate = grasped_count / total_objects
                    env_success_info.append({
                        'env_idx': env_idx,
                        'grasped': grasped_count, 
                        'total': total_objects,
                        'success_rate': success_rate
                    })
                    
                    status = "âœ…æˆåŠŸ" if grasped_count == total_objects else "ğŸ”„è¿›è¡Œä¸­" if grasped_count > 0 else "âŒå¤±è´¥"
                    print(f"  ç¯å¢ƒ{env_idx}: {grasped_count}/{total_objects} = {success_rate:.1%} {status}")
                    print(f"    æŠ“å–é¡ºåº: {unwrapped_env.grasped_objects[env_idx]}")
                    
            success_stats.append(env_success_info)
            
            # éªŒè¯å¥–åŠ±å‡½æ•°ä¼˜å…ˆçº§
            if len(episode_rewards) > 1:
                reward_trend = np.diff(episode_rewards, axis=0)
                print(f"  ğŸ“ˆ å¥–åŠ±å˜åŒ–è¶‹åŠ¿: åˆå§‹={episode_rewards[0]:.3f} -> æœ€ç»ˆ={episode_rewards[-1]:.3f}")
        
        # æ€»ä½“ç»“æœåˆ†æ
        print(f"\nğŸ“ˆ === ç†æƒ³åŒ–æŠ“å–é¡ºåºå­¦ä¹ æµ‹è¯•æ€»ç»“ ===")
        
        # è®¡ç®—æ€»ä½“æˆåŠŸç‡
        total_success_count = 0
        total_attempts = 0
        
        for episode_stats in success_stats:
            for env_stats in episode_stats:
                total_attempts += 1
                if env_stats['success_rate'] == 1.0:
                    total_success_count += 1
        
        overall_success_rate = total_success_count / total_attempts if total_attempts > 0 else 0
        
        print(f"ğŸ¯ æ€»æµ‹è¯•æ¬¡æ•°: {total_attempts} (ç¯å¢ƒæ•° {num_envs} Ã— è½®æ¬¡ {total_episodes})")
        print(f"âœ… å®Œå…¨æˆåŠŸæ¬¡æ•°: {total_success_count}")
        print(f"ğŸ“Š æ€»ä½“æˆåŠŸç‡: {overall_success_rate:.1%}")
        
        # åˆ†æä¸åŒæŠ“å–ç­–ç•¥çš„æ•ˆæœ
        if len(success_stats) > 0:
            print(f"\nğŸ” æŠ“å–ç­–ç•¥æ•ˆæœåˆ†æ:")
            
            env0_success = sum(1 for ep in success_stats for env in ep if env['env_idx'] == 0 and env['success_rate'] == 1.0)
            env0_attempts = sum(1 for ep in success_stats for env in ep if env['env_idx'] == 0)
            
            if num_envs > 1:
                env1_success = sum(1 for ep in success_stats for env in ep if env['env_idx'] == 1 and env['success_rate'] == 1.0)
                env1_attempts = sum(1 for ep in success_stats for env in ep if env['env_idx'] == 1)
                
                print(f"  ç­–ç•¥1(é¡ºåºæŠ“å–): {env0_success}/{env0_attempts} = {env0_success/env0_attempts:.1%}")
                print(f"  ç­–ç•¥2(é€†åºæŠ“å–): {env1_success}/{env1_attempts} = {env1_success/env1_attempts:.1%}")
            else:
                print(f"  æµ‹è¯•ç­–ç•¥: {env0_success}/{env0_attempts} = {env0_success/env0_attempts:.1%}")
        
        # è¯„ä¼°æµ‹è¯•ç»“æœ
        if overall_success_rate >= 0.8:
            print(f"\nğŸ‰ ç†æƒ³åŒ–æŠ“å–é¡ºåºå­¦ä¹ ç¯å¢ƒæµ‹è¯•é€šè¿‡ï¼")
            print(f"âœ… åŠ¨ä½œæ©ç æ›´æ–°æœºåˆ¶æ­£å¸¸")
            print(f"âœ… å¹¶è¡Œç¯å¢ƒç´¢å¼•å¤„ç†æ­£ç¡®") 
            print(f"âœ… å¥–åŠ±å‡½æ•°è®¾è®¡åˆç†")
            print(f"ğŸš€ å»ºè®®ï¼šå¯ä»¥å¼€å§‹è®­ç»ƒæŠ“å–é¡ºåºé€‰æ‹©æ¨¡å‹")
        elif overall_success_rate >= 0.5:
            print(f"\nâš ï¸ ç†æƒ³åŒ–æŠ“å–ç¯å¢ƒåŸºæœ¬å¯ç”¨ï¼Œä½†éœ€è¦ä¼˜åŒ–")
            print(f"ğŸ’¡ å»ºè®®ï¼šæ£€æŸ¥å¥–åŠ±å‡½æ•°æƒé‡å’Œæ©ç æ›´æ–°é€»è¾‘")
        else:
            print(f"\nâŒ ç†æƒ³åŒ–æŠ“å–ç¯å¢ƒå­˜åœ¨é—®é¢˜")
            print(f"ğŸ’¡ å»ºè®®ï¼šæ£€æŸ¥ç¯å¢ƒé…ç½®å’ŒçŠ¶æ€æœºé€»è¾‘")
            
        if capture_video:
            print(f"\nğŸ“¹ æµ‹è¯•è§†é¢‘å·²ä¿å­˜è‡³: {video_output_dir}")
            print(f"ğŸ’¡ é€šè¿‡è§†é¢‘å¯ä»¥è§‚å¯ŸæŠ“å–é¡ºåºå­¦ä¹ çš„æ•ˆæœ")
    
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        try:
            env.close()
        except:
            pass
        print("\nğŸ”š ç†æƒ³åŒ–æŠ“å–é¡ºåºå­¦ä¹ æµ‹è¯•å®Œæˆ")


def test_action_mask_dynamics():
    """ä¸“é—¨æµ‹è¯•åŠ¨ä½œæ©ç çš„åŠ¨æ€æ›´æ–°æœºåˆ¶"""
    print("\n=== åŠ¨ä½œæ©ç åŠ¨æ€æ›´æ–°æµ‹è¯• ===")
    
    try:
        env = gym.make(
            "EnvClutter-v1",
            obs_mode="state", 
            use_discrete_action=True,
            use_ideal_oracle=True,
            num_envs=1  # å•ç¯å¢ƒä¾¿äºè°ƒè¯•
        )
        
        env = ManiSkillVectorEnv(env, 1, ignore_terminations=False, record_metrics=True)
        
        obs, info = env.reset()
        unwrapped_env = env.unwrapped
        
        print(f"ğŸ” åˆå§‹çŠ¶æ€:")
        print(f"  æ€»ç‰©ä½“æ•°: {unwrapped_env.total_objects_per_env}")
        print(f"  å‰©ä½™ç‰©ä½“ç´¢å¼•: {unwrapped_env.remaining_indices[0]}")
        
        # æå–å¹¶éªŒè¯åˆå§‹æ©ç 
        total_objects = unwrapped_env.total_objects_per_env
        mask_start = total_objects * 8
        mask_end = mask_start + total_objects
        
        initial_mask = obs[0, mask_start:mask_end]
        print(f"  åˆå§‹æ©ç : {initial_mask}")
        print(f"  å¯ç”¨åŠ¨ä½œæ•°: {torch.sum(initial_mask).item()}")
        
        # æ‰§è¡Œå‡ æ¬¡æŠ“å–ï¼Œè§‚å¯Ÿæ©ç å˜åŒ–
        for step in range(min(3, total_objects)):
            remaining_count = len(unwrapped_env.remaining_indices[0])
            if remaining_count == 0:
                print(f"  â­• æ— æ›´å¤šå¯æŠ“å–ç‰©ä½“")
                break
                
            action = 0  # æ€»æ˜¯é€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨ç‰©ä½“
            print(f"\nğŸ¯ æ‰§è¡ŒæŠ“å– {step + 1}:")
            print(f"  é€‰æ‹©åŠ¨ä½œ: {action}")
            print(f"  ç›®æ ‡ç‰©ä½“ç´¢å¼•: {unwrapped_env.remaining_indices[0][action]}")
            
            obs, reward, terminated, truncated, info = env.step([action])
            
            # æå–æ–°æ©ç 
            new_mask = obs[0, mask_start:mask_end]
            print(f"  æŠ“å–åæ©ç : {new_mask}")
            print(f"  å¯ç”¨åŠ¨ä½œæ•°: {torch.sum(new_mask).item()}")
            print(f"  å‰©ä½™ç‰©ä½“ç´¢å¼•: {unwrapped_env.remaining_indices[0]}")
            print(f"  å·²æŠ“å–ç‰©ä½“: {unwrapped_env.grasped_objects[0]}")
            print(f"  å¥–åŠ±: {reward.item():.3f}")
            
            if terminated or truncated:
                print(f"  ğŸ ç¯å¢ƒç»ˆæ­¢")
                break
        
        print(f"\nâœ… åŠ¨ä½œæ©ç åŠ¨æ€æ›´æ–°æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æ©ç æµ‹è¯•é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        env.close()


def main():
    """ä¸»å‡½æ•° - é€‰æ‹©æµ‹è¯•æ¨¡å¼"""
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "mask":
        test_action_mask_dynamics()
    else:
        test_ideal_grasp_sequence()


if __name__ == "__main__":
    main()
