import os
from typing import Any, Dict, List, Union, Tuple
import numpy as np
import sapien
import torch
import cv2
import random

# å¯¼å…¥é…ç½®
try:
    from .config import Config, get_config
except ImportError:
    # å¤„ç†ç›´æ¥è¿è¡Œæ—¶çš„ç›¸å¯¹å¯¼å…¥é—®é¢˜
    from config import Config, get_config

import mani_skill.envs.utils.randomization as randomization
from mani_skill import ASSET_DIR
from mani_skill.agents.robots import Fetch, Panda
from mani_skill.envs.sapien_env import BaseEnv
from mani_skill.sensors.camera import CameraConfig
from mani_skill.utils import sapien_utils
from mani_skill.utils.building import actors
from mani_skill.utils.building.actor_builder import ActorBuilder
from mani_skill.utils.io_utils import load_json
from mani_skill.utils.registration import register_env
from mani_skill.utils.scene_builder.table import TableSceneBuilder
from mani_skill.utils.structs import Actor, Pose
from mani_skill.utils.structs.types import GPUMemoryConfig, SimConfig

# æ–°å¢ï¼šIKå’Œæ§åˆ¶å™¨ç›¸å…³å¯¼å…¥
# from mani_skill.agents.controllers.pd_ee_pose import PDEEPoseController

# æ–°å¢ï¼šå¯¼å…¥SAPIENçº¦æŸç›¸å…³æ¨¡å—
import sapien.physx as physx


@register_env(
    "EnvClutter-v1",
    asset_download_ids=["ycb"],
    max_episode_steps=200,
)
class EnvClutterEnv(BaseEnv):
    """
    **ä»»åŠ¡æè¿°:**
    å¤æ‚å †å æŠ“å–ç¯å¢ƒï¼ŒåŒ…å«å„ç§å½¢çŠ¶çš„YCBç‰©ä½“å †ç§¯åœ¨æ‰˜ç›˜ä¸­ã€‚
    æœºæ¢°è‡‚éœ€è¦æŒ‘é€‰æœ€é€‚åˆæŠ“å–çš„ç‰©ä½“ï¼Œå¹¶å°†å…¶æ”¾åˆ°æŒ‡å®šä½ç½®ã€‚
    
    **éšæœºåŒ–:**
    - ç‰©ä½“åœ¨æ‰˜ç›˜å†…éšæœºç”Ÿæˆ
    - ç‰©ä½“åˆå§‹å§¿æ€éšæœºåŒ–
    - ç›®æ ‡ä½ç½®å›ºå®šåœ¨æ‰˜ç›˜å³ä¾§
    
    **æˆåŠŸæ¡ä»¶:**
    - ç›®æ ‡ç‰©ä½“è¢«æˆåŠŸæŠ“å–å¹¶æ”¾ç½®åˆ°ç›®æ ‡ä½ç½®
    - æœºå™¨äººé™æ­¢
    """
    
    SUPPORTED_REWARD_MODES = ["dense", "sparse"]
    SUPPORTED_ROBOTS = ["panda", "fetch"]
    agent: Union[Panda, Fetch]
    
    # æ‰˜ç›˜å‚æ•° (åŸºäºtraybox.urdfçš„å°ºå¯¸)
    tray_size = [0.6, 0.6, 0.15]  # æ‰˜ç›˜å†…éƒ¨å°ºå¯¸ (é•¿xå®½xé«˜)
    tray_spawn_area = [0.23, 0.23]  # æ‰˜ç›˜å†…ç‰©ä½“ç”ŸæˆåŒºåŸŸ (è€ƒè™‘è¾¹ç•Œå¢™å’Œå®‰å…¨è¾¹è·)
    
    # æ³¨æ„ï¼šç‰©ä½“ç›¸å…³å‚æ•°ç°åœ¨ä»configä¸­åŠ¨æ€è·å–
    # BOX_OBJECTS, num_objects_per_type, MAX_N, MAX_EPISODE_STEPS ç­‰
    # éƒ½åœ¨ __init__ æ–¹æ³•ä¸­ä»é…ç½®æ–‡ä»¶åˆå§‹åŒ–
    
    # æ–°å¢ï¼šå¸ç›˜çº¦æŸç›¸å…³å¸¸é‡
    SUCTION_DISTANCE_THRESHOLD = 0.15  # å¸ç›˜æ¿€æ´»è·ç¦»é˜ˆå€¼ ä»10cmå¢åŠ åˆ°15cm
    SUCTION_STIFFNESS = 1e6  # å¸ç›˜çº¦æŸåˆšåº¦
    SUCTION_DAMPING = 1e4    # å¸ç›˜çº¦æŸé˜»å°¼
    
    def __init__(
        self,
        *args,
        robot_uids="panda",
        robot_init_qpos_noise=0.02,
        num_envs=1,
        use_discrete_action=False,  # æ–°å¢ï¼šæ˜¯å¦ä½¿ç”¨ç¦»æ•£åŠ¨ä½œ
        config_preset="default",    # æ–°å¢ï¼šé…ç½®é¢„è®¾åç§°
        custom_config=None,         # æ–°å¢ï¼šè‡ªå®šä¹‰é…ç½®å¯¹è±¡
        **kwargs,
    ):
        self.robot_init_qpos_noise = robot_init_qpos_noise
        self.use_discrete_action = use_discrete_action
        
        # åˆå§‹åŒ–é…ç½®
        if custom_config is not None:
            self.config = custom_config
        else:
            self.config = get_config(config_preset)
        
        # ä»é…ç½®ä¸­è·å–ç‰©ä½“ç›¸å…³å‚æ•°
        self.BOX_OBJECTS = self.config.env.box_objects
        self.num_objects_per_type = self.config.env.num_objects_per_type
        self.num_object_types = self.config.env.num_object_types
        self.total_objects_per_env = self.config.env.total_objects_per_env
        self.goal_thresh = self.config.env.goal_thresh  # æˆåŠŸé˜ˆå€¼
        
        # è®¾ç½®åŠ¨æ€è®¡ç®—çš„å±æ€§
        self.MAX_N = self.total_objects_per_env  # æœ€å¤§ç‰©ä½“æ•°é‡
        self.MAX_EPISODE_STEPS = self.config.env.max_episode_steps_discrete  # æœ€å¤§episodeæ­¥æ•°
        
        # åˆå§‹åŒ–ç¦»æ•£åŠ¨ä½œç›¸å…³å˜é‡ - ä¿®æ”¹ä¸ºå¤šç¯å¢ƒæ”¯æŒ
        self.remaining_indices = []  # æ¯ä¸ªç¯å¢ƒçš„å‰©ä½™å¯æŠ“å–ç‰©ä½“ç´¢å¼• [[env0_indices], [env1_indices], ...]
        self.step_count = []  # æ¯ä¸ªç¯å¢ƒçš„å½“å‰æ­¥æ•° [env0_steps, env1_steps, ...]
        self.grasped_objects = []  # æ¯ä¸ªç¯å¢ƒå·²æŠ“å–çš„ç‰©ä½“ [[env0_grasped], [env1_grasped], ...]
        
        # æ–°å¢ï¼šå¹¶è¡Œæœ‰é™çŠ¶æ€æœºå˜é‡
        self.env_stage = None      # [num_envs] å½“å‰æ‰€å¤„çŠ¶æ€ 0~7
        self.env_target = None     # [num_envs] æ¯ä¸ªç¯å¢ƒæ­£åœ¨å¤„ç†çš„ç‰©ä½“ç´¢å¼•
        self.env_busy = None       # [num_envs] True=æµç¨‹è¿›è¡Œä¸­ï¼ŒFalse=æœ¬å›åˆå·²ç»“æŸæˆ–ç­‰å¾…æ–°æŒ‡ä»¤
        self.stage_tick = None     # [num_envs] åœ¨æŸçŠ¶æ€ä¸­å·²ç»èµ°äº†å¤šå°‘å¾®æ­¥
        self.stage_positions = None # [num_envs, 3] æ¯ä¸ªç¯å¢ƒå½“å‰çŠ¶æ€çš„ç›®æ ‡ä½ç½®
        
        # æ–°å¢ï¼šåˆå§‹åŒ–å¸ç›˜çº¦æŸç›¸å…³å˜é‡
        self.suction_constraints = {}  # å­˜å‚¨çº¦æŸå¯¹è±¡çš„å­—å…¸ {object_name: constraint}
        self.is_suction_active = [False] * num_envs  # æ¯ä¸ªç¯å¢ƒçš„å¸ç›˜æ¿€æ´»çŠ¶æ€
        self.current_suction_object = [None] * num_envs  # æ¯ä¸ªç¯å¢ƒå½“å‰å¸é™„çš„ç‰©ä½“
        
        # ç¡®ä¿æ‰€æœ‰å‚æ•°æ­£ç¡®ä¼ é€’ç»™çˆ¶ç±»
        super().__init__(
            *args,
            robot_uids=robot_uids,
            num_envs=num_envs,
            **kwargs,
        )
        
        # åœ¨çˆ¶ç±»åˆå§‹åŒ–ååˆå§‹åŒ–FSMçŠ¶æ€å¼ é‡
        if self.use_discrete_action:
            self._init_fsm_states()

    @property
    def _default_sim_config(self):
        return SimConfig(
            gpu_memory_config=GPUMemoryConfig(
                max_rigid_contact_count=2**21,
                max_rigid_patch_count=2**19
            )
        )

    @property
    def _default_sensor_configs(self):
        pose = sapien_utils.look_at(eye=[0.3, 0, 0.6], target=[-0.1, 0.0, 0.1])
        return [
            CameraConfig(
                "base_camera",
                pose=pose,
                width=128,
                height=128,
                fov=np.pi / 2,
                near=0.01,
                far=100,
            )
        ]

    @property
    def _default_human_render_camera_configs(self):
        pose = sapien_utils.look_at([0.6, 0.7, 0.6], [0.0, 0.2, 0.35])
        return CameraConfig(
            "render_camera", 
            pose=pose, 
            width=512, 
            height=512, 
            fov=1, 
            near=0.01, 
            far=100
        )

    def _load_agent(self, options: dict):
        super()._load_agent(options, sapien.Pose(p=[-0.615, 0, 0]))
        
    # å¸ç›˜çº¦æŸç³»ç»Ÿå®ç°
    def _create_suction_constraint(self, target_object: Actor, env_idx: int = 0) -> bool:
        """
        åˆ›å»ºå¸ç›˜çº¦æŸ
        
        Args:
            target_object: ç›®æ ‡ç‰©ä½“
            env_idx: ç¯å¢ƒç´¢å¼•ï¼ˆå¤šç¯å¢ƒæ”¯æŒï¼‰
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸåˆ›å»ºçº¦æŸ
        """
        if self.is_suction_active[env_idx]:
            print(f"ç¯å¢ƒ{env_idx}: å¸ç›˜å·²ç»æ¿€æ´»ï¼Œæ— æ³•åˆ›å»ºæ–°çº¦æŸ")
            return False
            
        # æ£€æŸ¥æ˜¯å¦ä¸ç‰©ä½“æ¥è§¦
        if not self._is_contacting_object(target_object, self.SUCTION_DISTANCE_THRESHOLD, env_idx):
            print(f"ç¯å¢ƒ{env_idx}: ç‰©ä½“è·ç¦»è¿‡è¿œï¼Œæ— æ³•æ¿€æ´»å¸ç›˜")
            return False
        
        try:
            # å¯¼å…¥Driveç±»
            from mani_skill.utils.structs.drive import Drive
            
            print(f"ç¯å¢ƒ{env_idx}: åˆ›å»ºå¸ç›˜çº¦æŸ: TCPé“¾æ¥ -> ç‰©ä½“ {target_object.name}")
            
            # ğŸ”§ ä¿®å¤ï¼šå®‰å…¨çš„å¤šç¯å¢ƒå¯¹è±¡é€‰æ‹©
            # 1. éªŒè¯ç›®æ ‡ç‰©ä½“çš„ç¯å¢ƒå½’å±
            target_scene_idxs = target_object._scene_idxs
            if len(target_scene_idxs) == 0:
                print(f"ç¯å¢ƒ{env_idx}: ç›®æ ‡ç‰©ä½“æ²¡æœ‰åœºæ™¯ç´¢å¼•")
                return False
            
            target_env_idx = target_scene_idxs[0].item()
            print(f"ç¯å¢ƒ{env_idx}: ç›®æ ‡ç‰©ä½“å®é™…å±äºç¯å¢ƒ{target_env_idx}")
            
            # éªŒè¯ç¯å¢ƒç´¢å¼•ä¸€è‡´æ€§
            if target_env_idx != env_idx:
                print(f"ç¯å¢ƒ{env_idx}: ç¯å¢ƒç´¢å¼•ä¸åŒ¹é…ï¼Œç›®æ ‡ç‰©ä½“å±äºç¯å¢ƒ{target_env_idx}")
                return False
            
            # 2. ğŸ”§ ä¿®å¤ï¼šé€šè¿‡scene_idxså®‰å…¨è·å–TCPå®ä½“
            tcp_objs = self.agent.tcp._objs
            tcp_scene_idxs = self.agent.tcp._scene_idxs
            
            # æ‰¾åˆ°å±äºtarget_env_idxç¯å¢ƒçš„TCPå¯¹è±¡
            tcp_mask = (tcp_scene_idxs == target_env_idx)
            if not tcp_mask.any():
                print(f"ç¯å¢ƒ{env_idx}: æ‰¾ä¸åˆ°å¯¹åº”ç¯å¢ƒçš„TCPå¯¹è±¡")
                return False
            
            tcp_indices = torch.where(tcp_mask)[0]
            if len(tcp_indices) == 0:
                print(f"ç¯å¢ƒ{env_idx}: TCPç´¢å¼•åˆ—è¡¨ä¸ºç©º")
                return False
                
            tcp_idx = tcp_indices[0].item()  # è·å–ç¬¬ä¸€ä¸ªåŒ¹é…çš„ç´¢å¼•
            tcp_entity = tcp_objs[tcp_idx].entity
            print(f"ç¯å¢ƒ{env_idx}: æ‰¾åˆ°TCPå¯¹è±¡ï¼Œç´¢å¼•={tcp_idx}ï¼Œç¯å¢ƒ={target_env_idx}")
            
            # 3. ğŸ”§ ä¿®å¤ï¼šå®‰å…¨è·å–ç›®æ ‡ç‰©ä½“å®ä½“
            if len(target_object._objs) == 0:
                print(f"ç¯å¢ƒ{env_idx}: ç›®æ ‡ç‰©ä½“æ²¡æœ‰å®ä½“å¯¹è±¡")
                return False
            
            # åœ¨å½“å‰è®¾è®¡ä¸­ï¼Œæ¯ä¸ªç‰©ä½“é€šå¸¸åªæœ‰ä¸€ä¸ªå®ä½“
            target_entity = target_object._objs[0]
            print(f"ç¯å¢ƒ{env_idx}: ç›®æ ‡ç‰©ä½“å®ä½“æ•°é‡={len(target_object._objs)}")
            
            print(f"ç¯å¢ƒ{env_idx}: ä½¿ç”¨TCPå®ä½“[ç´¢å¼•{tcp_idx}]å’Œç›®æ ‡å®ä½“åˆ›å»ºçº¦æŸ")
            
            # å…³é”®ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨SAPIENçš„create_driveæ–¹æ³•ï¼Œç»•è¿‡DriveåŒ…è£…å™¨çš„æ‰¹é‡å¤„ç†
            # è¿™æ ·å¯ä»¥é¿å…scene_idxså’Œbodiesç´¢å¼•ä¸åŒ¹é…çš„é—®é¢˜
            sub_scene = self.scene.sub_scenes[target_env_idx]
            physx_drive = sub_scene.create_drive(
                tcp_entity,           # TCPå®ä½“
                sapien.Pose(),        # çˆ¶ä½“æœ¬åœ°å§¿æ€ - ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨sapien.Pose()
                target_entity,        # ç›®æ ‡ç‰©ä½“å®ä½“
                sapien.Pose()         # å­ä½“æœ¬åœ°å§¿æ€ - ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨sapien.Pose()
            )

            # æ‰‹åŠ¨åˆ›å»ºDriveåŒ…è£…å™¨ä»¥ä¾¿åç»­ç®¡ç†
            constraint = Drive(
                _objs=[physx_drive],
                _scene_idxs=torch.tensor([target_env_idx], device=self.device),
                pose_in_child=sapien.Pose(),
                pose_in_parent=sapien.Pose(),
                scene=self.scene
            )
            
            # è®¾ç½®çº¦æŸå‚æ•°ä½¿å…¶è¡¨ç°ä¸ºå›ºå®šçº¦æŸï¼ˆç±»ä¼¼PyBulletçš„JOINT_FIXEDï¼‰
            # ç›´æ¥è°ƒç”¨åº•å±‚PhysxDriveComponentçš„æ–¹æ³•ï¼ˆè¿™äº›æ–¹æ³•æ²¡æœ‰@before_gpu_inité™åˆ¶ï¼‰
            try:
                # çº¿æ€§çº¦æŸï¼ˆX, Y, Zæ–¹å‘ï¼‰
                physx_drive.set_drive_property_x(stiffness=self.SUCTION_STIFFNESS, damping=self.SUCTION_DAMPING)
                physx_drive.set_drive_property_y(stiffness=self.SUCTION_STIFFNESS, damping=self.SUCTION_DAMPING)
                physx_drive.set_drive_property_z(stiffness=self.SUCTION_STIFFNESS, damping=self.SUCTION_DAMPING)
                print(f"ç¯å¢ƒ{env_idx}: âœ… å·²è®¾ç½®é©±åŠ¨å±æ€§")
            except Exception as drive_error:
                print(f"ç¯å¢ƒ{env_idx}: âŒ è®¾ç½®é©±åŠ¨å±æ€§å¤±è´¥: {drive_error}")
                return False
            
            # è®¾ç½®ä½ç½®é™åˆ¶æ¥æ¨¡æ‹Ÿå›ºå®šçº¦æŸ
            try:
                physx_drive.set_limit_x(0, 0)  # ä¸å…è®¸Xæ–¹å‘ç§»åŠ¨
                physx_drive.set_limit_y(0, 0)  # ä¸å…è®¸Yæ–¹å‘ç§»åŠ¨
                physx_drive.set_limit_z(0, 0)  # ä¸å…è®¸Zæ–¹å‘ç§»åŠ¨
                print(f"ç¯å¢ƒ{env_idx}: âœ… å·²è®¾ç½®ä½ç½®é™åˆ¶")
            except Exception as limit_error:
                print(f"ç¯å¢ƒ{env_idx}: âš ï¸ è®¾ç½®é™åˆ¶å¤±è´¥: {limit_error}")
                # ç»§ç»­æ‰§è¡Œï¼Œä»…ä½¿ç”¨é©±åŠ¨å±æ€§
            
            # å­˜å‚¨çº¦æŸ - ä½¿ç”¨ç¯å¢ƒç‰¹å®šçš„é”®
            constraint_key = f"{target_object.name}_env_{env_idx}"
            self.suction_constraints[constraint_key] = constraint
            self.is_suction_active[env_idx] = True
            self.current_suction_object[env_idx] = target_object
            
            print(f"ç¯å¢ƒ{env_idx}: âœ… å¸ç›˜çº¦æŸåˆ›å»ºæˆåŠŸ: {constraint_key}")
            return True
            
        except Exception as e:
            print(f"ç¯å¢ƒ{env_idx}: âŒ åˆ›å»ºå¸ç›˜çº¦æŸå¤±è´¥: {e}")
            import traceback
            print(f"ç¯å¢ƒ{env_idx}: è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            traceback.print_exc()
            return False

    def _remove_suction_constraint(self, env_idx: int = 0) -> bool:
        """
        ç§»é™¤å¸ç›˜çº¦æŸ
        
        Args:
            env_idx: ç¯å¢ƒç´¢å¼•ï¼ˆå¤šç¯å¢ƒæ”¯æŒï¼‰
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸç§»é™¤çº¦æŸ
        """
        if not self.is_suction_active[env_idx] or self.current_suction_object[env_idx] is None:
            #print("æ²¡æœ‰æ¿€æ´»çš„å¸ç›˜çº¦æŸéœ€è¦ç§»é™¤")
            return False
        
        try:
            # è·å–çº¦æŸå¯¹è±¡ - ä½¿ç”¨ç¯å¢ƒç‰¹å®šçš„é”®
            constraint_key = f"{self.current_suction_object[env_idx].name}_env_{env_idx}"
            if constraint_key in self.suction_constraints:
                constraint = self.suction_constraints[constraint_key]
                
                print(f"ç¯å¢ƒ{env_idx}: æ­£åœ¨ç§»é™¤å¸ç›˜çº¦æŸ: {constraint_key}")
                
                # å…³é”®ä¿®å¤ï¼šç›´æ¥æ“ä½œåº•å±‚PhysxDriveComponentå¯¹è±¡
                physx_drive = constraint._objs[0]  # è·å–åº•å±‚çš„PhysxDriveComponentå¯¹è±¡
                
                # æ–¹æ³•1: é€šè¿‡è®¾ç½®åˆšåº¦ä¸º0æ¥ç¦ç”¨çº¦æŸï¼ˆæœ€æœ‰æ•ˆï¼‰
                try:
                    print(f"ç¯å¢ƒ{env_idx}: è®¾ç½®çº¦æŸåˆšåº¦ä¸º0...")
                    physx_drive.set_drive_property_x(stiffness=0.0, damping=0.0)
                    physx_drive.set_drive_property_y(stiffness=0.0, damping=0.0)
                    physx_drive.set_drive_property_z(stiffness=0.0, damping=0.0)
                    print(f"ç¯å¢ƒ{env_idx}: âœ… æˆåŠŸç¦ç”¨çº¦æŸé©±åŠ¨å±æ€§")
                except Exception as disable_error:
                    print(f"ç¯å¢ƒ{env_idx}: âŒ ç¦ç”¨çº¦æŸé©±åŠ¨å±æ€§å¤±è´¥: {disable_error}")
                    return False
                
                # æ–¹æ³•2: é‡ç½®çº¦æŸé™åˆ¶ï¼ˆè¾…åŠ©æ–¹æ³•ï¼‰
                try:
                    print(f"ç¯å¢ƒ{env_idx}: é‡ç½®çº¦æŸé™åˆ¶...")
                    # è®¾ç½®éå¸¸å¤§çš„é™åˆ¶èŒƒå›´ï¼Œç›¸å½“äºå–æ¶ˆé™åˆ¶
                    physx_drive.set_limit_x(-1000, 1000)
                    physx_drive.set_limit_y(-1000, 1000)
                    physx_drive.set_limit_z(-1000, 1000)
                    print(f"ç¯å¢ƒ{env_idx}: âœ… æˆåŠŸé‡ç½®çº¦æŸé™åˆ¶")
                except Exception as limit_error:
                    print(f"ç¯å¢ƒ{env_idx}: âš ï¸ é‡ç½®çº¦æŸé™åˆ¶å¤±è´¥: {limit_error}")
                    # é™åˆ¶é‡ç½®å¤±è´¥ä¸å½±å“ä¸»è¦åŠŸèƒ½ï¼Œç»§ç»­æ‰§è¡Œ
                    pass
                
                # æ¸…ç†çº¦æŸå¼•ç”¨
                del self.suction_constraints[constraint_key]
                print(f"ç¯å¢ƒ{env_idx}: âœ… çº¦æŸå¼•ç”¨å·²æ¸…ç†: {constraint_key}")
            else:
                print(f"ç¯å¢ƒ{env_idx}: âš ï¸ æœªæ‰¾åˆ°çº¦æŸå¯¹è±¡: {constraint_key}")
                pass
            
            # é‡ç½®å¸ç›˜çŠ¶æ€
            self.is_suction_active[env_idx] = False
            self.current_suction_object[env_idx] = None
            
            print(f"ç¯å¢ƒ{env_idx}: âœ… å¸ç›˜çŠ¶æ€å·²é‡ç½®")
            
            return True
            
        except Exception as e:
            print(f"ç¯å¢ƒ{env_idx}: âŒ ç§»é™¤å¸ç›˜çº¦æŸå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
            # å³ä½¿ç§»é™¤å¤±è´¥ï¼Œä¹Ÿè¦é‡ç½®çŠ¶æ€
            self.is_suction_active[env_idx] = False
            self.current_suction_object[env_idx] = None
            return False

    def _is_contacting_object(self, target_object: Actor, threshold: float = 0.05, env_idx: int = 0) -> bool:
        """
        æ£€æµ‹TCPæ˜¯å¦ä¸ç‰©ä½“æ¥è§¦
        
        Args:
            target_object: ç›®æ ‡ç‰©ä½“
            threshold: è·ç¦»é˜ˆå€¼
            env_idx: ç¯å¢ƒç´¢å¼•ï¼ˆå¤šç¯å¢ƒæ”¯æŒï¼‰
            
        Returns:
            bool: æ˜¯å¦æ¥è§¦
        """
        try:
            # è®¡ç®—TCPåˆ°ç‰©ä½“çš„è·ç¦» - ä½¿ç”¨å¯¹åº”ç¯å¢ƒçš„TCPä½ç½®
            tcp_pos = self.agent.tcp.pose.p
            if tcp_pos.dim() > 1:
                tcp_pos = tcp_pos[env_idx] 
            
            obj_pos = target_object.pose.p
            obj_pos = obj_pos[0]
            
            # è®¡ç®—è·ç¦»
            raw_distance = torch.linalg.norm(tcp_pos - obj_pos).item()
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ›´åˆç†çš„åŠå¾„ä¼°è®¡å€¼
            # TCPåŠå¾„çº¦2cmï¼Œç‰©ä½“å¹³å‡åŠå¾„çº¦3cmï¼Œæ€»è®¡çº¦5cm
            estimated_radius = 0.1  # 10cmçš„åŠå¾„ä¼°è®¡ï¼Œä¸_check_suction_grasp_successä¿æŒä¸€è‡´
            distance = raw_distance - estimated_radius
            
            print(f"ç¯å¢ƒ{env_idx}: TCPåˆ°ç‰©ä½“è·ç¦»æ£€æµ‹: åŸå§‹è·ç¦»={raw_distance:.4f}m, è°ƒæ•´åè·ç¦»={distance:.4f}m, é˜ˆå€¼={threshold:.4f}m, æ¥è§¦={'æ˜¯' if distance <= threshold else 'å¦'}")
            
            # æ£€æŸ¥æ˜¯å¦åœ¨æ¥è§¦é˜ˆå€¼å†…
            return distance <= threshold
            
        except Exception as e:
            print(f"ç¯å¢ƒ{env_idx}: æ£€æµ‹æ¥è§¦å¤±è´¥: {e}")
            return False

    def _check_suction_grasp_success(self, target_object: Actor, env_idx: int = 0) -> bool:
        """
        æ£€æŸ¥å¸ç›˜æŠ“å–æ˜¯å¦æˆåŠŸ
        
        Args:
            target_object: ç›®æ ‡ç‰©ä½“
            env_idx: ç¯å¢ƒç´¢å¼•ï¼ˆå¤šç¯å¢ƒæ”¯æŒï¼‰
            
        Returns:
            bool: æŠ“å–æ˜¯å¦æˆåŠŸ
        """
        try:
            # æ–¹æ³•1ï¼šæ£€æŸ¥å¸ç›˜çŠ¶æ€
            if (self.is_suction_active[env_idx] and 
                self.current_suction_object[env_idx] is not None and 
                self.current_suction_object[env_idx].name == target_object.name):
                
                # æ–¹æ³•2ï¼šæ£€æŸ¥ç‰©ä½“æ˜¯å¦ä»åœ¨TCPé™„è¿‘
                tcp_pos = self.agent.tcp.pose.p
                if tcp_pos.dim() > 1:
                    if env_idx < tcp_pos.shape[0]:
                        tcp_pos = tcp_pos[env_idx]
                    else:
                        tcp_pos = tcp_pos[0]
                        print(f"âš ï¸ ç¯å¢ƒ{env_idx}: TCPä½ç½®ç´¢å¼•è¶Šç•Œï¼Œä½¿ç”¨ç¯å¢ƒ0çš„ä½ç½®")
                
                obj_pos = target_object.pose.p
                obj_pos = obj_pos[0]
                
                raw_distance = torch.linalg.norm(tcp_pos - obj_pos).item()
                # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ä¸æ¥è§¦æ£€æµ‹ä¸€è‡´çš„åŠå¾„ä¼°è®¡
                estimated_radius = 0.1  # 10cmçš„åŠå¾„ä¼°è®¡ï¼Œä¸_is_contacting_objectä¿æŒä¸€è‡´
                distance = raw_distance - estimated_radius
                
                # è·ç¦»å°äº5cmè®¤ä¸ºæŠ“å–æˆåŠŸ
                success_threshold = 0.05
                success = distance < success_threshold
                
                print(f"ç¯å¢ƒ{env_idx}: æŠ“å–æˆåŠŸæ£€æµ‹ - åŸå§‹è·ç¦»={raw_distance:.4f}m, è°ƒæ•´åè·ç¦»={distance:.4f}m, æˆåŠŸ={'æ˜¯' if success else 'å¦'}")
                
                return success
            else:
                print(f"ç¯å¢ƒ{env_idx}: å¸ç›˜æœªæ¿€æ´»æˆ–ç‰©ä½“ä¸åŒ¹é…")
                return False
                
        except Exception as e:
            print(f"ç¯å¢ƒ{env_idx}: æ£€æŸ¥å¸ç›˜æŠ“å–æˆåŠŸå¤±è´¥: {e}")
            return False
    
    
    
    def _low_level_step(self, delta_pose: torch.Tensor):
        """å•æ­¥æ‰§è¡Œdelta poseï¼Œåªæ¨è¿›ä»¿çœŸï¼Œä¸èµ°ç¦»æ•£é€»è¾‘"""
        # è°ƒç”¨çˆ¶ç±»çš„stepæ–¹æ³•æ‰§è¡Œè¿ç»­åŠ¨ä½œ
        super().step(delta_pose)
    
    
    def _is_object_blocked(self, target_obj) -> bool:
        """
        ç®€åŒ–çš„é®æŒ¡æ£€æµ‹ï¼Œå¯¹åº”PyBulletçš„å°„çº¿æ£€æµ‹
        æ£€æŸ¥ç‰©ä½“ä¸Šæ–¹æ˜¯å¦æœ‰å…¶ä»–ç‰©ä½“
        """
        try:
            target_pos = target_obj.pose.p
            if target_pos.dim() > 1:
                target_pos = target_pos[0]
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–ç‰©ä½“åœ¨ç›®æ ‡ç‰©ä½“ä¸Šæ–¹
            for obj in self.all_objects:
                if obj == target_obj:
                    continue
                
                obj_pos = obj.pose.p
                if obj_pos.dim() > 1:
                    obj_pos = obj_pos[0]
                
                # æ£€æŸ¥æ˜¯å¦åœ¨ç›®æ ‡ç‰©ä½“ä¸Šæ–¹ï¼ˆxyå¹³é¢è·ç¦»å°äº5cmï¼Œzé«˜åº¦å¤§äºç›®æ ‡ç‰©ä½“ï¼‰
                xy_distance = torch.linalg.norm(obj_pos[:2] - target_pos[:2])
                if xy_distance < 0.05 and obj_pos[2] > target_pos[2]:
                    return True
            
            return False
            
        except Exception as e:
            #print(f"é®æŒ¡æ£€æµ‹å¤±è´¥: {e}")
            return False


    def _load_scene(self, options: dict):
        # æ„å»ºæ¡Œé¢åœºæ™¯
        self.scene_builder = TableSceneBuilder(
            self, robot_init_qpos_noise=self.robot_init_qpos_noise
        )
        self.scene_builder.build()
        
        # åŠ è½½æ‰˜ç›˜
        self._load_tray()
        
        # åˆ›å»ºç‰©ä½“åˆ—è¡¨
        self.all_objects = []
        self.selectable_objects = []
        self.object_info = []  # å­˜å‚¨ç‰©ä½“ä¿¡æ¯
        
        # ä¸ºæ¯ä¸ªç¯å¢ƒåˆ›å»ºç‰©ä½“
        for env_idx in range(self.num_envs):
            env_objects = []
            env_selectable = []
            env_info = []
            
            # åˆ›å»ºæ¯ç§ç±»å‹çš„ç‰©ä½“
            for obj_type in self.BOX_OBJECTS:
                for i in range(self.num_objects_per_type):
                    # åˆ›å»ºç‰©ä½“
                    builder = actors.get_actor_builder(self.scene, id=f"ycb:{obj_type}")
                    

                    # åœ¨æ‰˜ç›˜å†…éšæœºç”Ÿæˆä½ç½®
                    x, y, z = self._generate_object_position_in_tray(i)
                    
                    # éšæœºå§¿æ€
                    quat = randomization.random_quaternions(1)[0]
                    initial_pose = sapien.Pose(p=[x, y, z], q=quat.cpu().numpy())
                    
                    builder.initial_pose = initial_pose
                    builder.set_scene_idxs([env_idx])
                    
                    obj_name = f"env_{env_idx}_{obj_type}_{i}"
                    obj = builder.build(name=obj_name)
                    
                    env_objects.append(obj)
                    env_selectable.append(obj)
                    
                    # å­˜å‚¨ç‰©ä½“ä¿¡æ¯
                    obj_info = {
                        'type': obj_type,
                        'size': self._get_object_size(obj_type),
                        'initial_pose': initial_pose,
                        'center': [x, y, z],
                        'exposed_area': 1.0,  # åˆå§‹æš´éœ²é¢ç§¯ï¼Œåç»­ä¼šè®¡ç®—
                    }
                    env_info.append(obj_info)
            
            self.all_objects.extend(env_objects)
            self.selectable_objects.append(env_selectable)
            self.object_info.append(env_info)
        
        # åˆå¹¶æ‰€æœ‰ç‰©ä½“
        if self.all_objects:
            self.merged_objects = Actor.merge(self.all_objects, name="all_objects")
        
        # åˆ›å»ºç›®æ ‡ä½ç½®æ ‡è®°
        self.goal_site = actors.build_sphere(
            self.scene,
            radius=self.goal_thresh,
            color=[0, 1, 0, 1],
            name="goal_site",
            body_type="kinematic",
            add_collision=False,
            initial_pose=sapien.Pose(),
        )
        self._hidden_objects.append(self.goal_site)
        
        # åˆå§‹åŒ–ç›®æ ‡ç‰©ä½“ç›¸å…³å˜é‡
        self.target_object = None
        self.target_object_indices = []

    def _load_tray(self):
        """åŠ è½½æ‰˜ç›˜URDFæ–‡ä»¶"""
        # è·å–æ‰˜ç›˜URDFæ–‡ä»¶è·¯å¾„
        tray_urdf_path = "/home2/jzh/RL_RobotArm-main/assets/tray/traybox.urdf"
        
        if not os.path.exists(tray_urdf_path):
            raise FileNotFoundError(f"æ‰˜ç›˜URDFæ–‡ä»¶æœªæ‰¾åˆ°: {tray_urdf_path}")
        
        # åˆ›å»ºURDFåŠ è½½å™¨
        loader = self.scene.create_urdf_loader()
        
        # è®¾ç½®æ‰˜ç›˜çš„ç‰©ç†å±æ€§
        loader.set_material(static_friction=0.8, dynamic_friction=0.6, restitution=0.05)
        loader.fix_root_link = True  # å›ºå®šæ‰˜ç›˜ä¸åŠ¨
        loader.scale = 1.0  # ä¿æŒåŸå§‹å°ºå¯¸
        
        # è§£æURDFæ–‡ä»¶
        parsed_result = loader.parse(tray_urdf_path)
        
        # åªä½¿ç”¨ actor_builders æ–¹å¼
        actor_builders = parsed_result.get("actor_builders", [])
        
        if not actor_builders:
            raise ValueError("æ‰˜ç›˜URDFæ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°actor_builders")
        
        self.trays = []
        
        # ä½¿ç”¨ actor_builders åŠ è½½æ‰˜ç›˜
        for env_idx in range(self.num_envs):
            builder = actor_builders[0]
            # è®¾ç½®æ‰˜ç›˜ä½ç½® (æ”¾åœ¨æ¡Œé¢ä¸Šï¼Œæœºå™¨äººå‰æ–¹)
            tray_position = [-0.2, 0.0, 0.006]  # æ¡Œé¢é«˜åº¦åŠ ä¸Šæ‰˜ç›˜åº•éƒ¨åšåº¦
            builder.initial_pose = sapien.Pose(p=tray_position)
            builder.set_scene_idxs([env_idx])
            
            # ä½¿ç”¨ build_static åˆ›å»ºé™æ€æ‰˜ç›˜ï¼Œç¡®ä¿ä¸ä¼šç§»åŠ¨
            tray = builder.build_static(name=f"tray_{env_idx}")
            self.trays.append(tray)
        
        # åˆå¹¶æ‰€æœ‰æ‰˜ç›˜
        if self.trays:
            self.merged_trays = Actor.merge(self.trays, name="all_trays")
        
        #print(f"æˆåŠŸåŠ è½½æ‰˜ç›˜ï¼Œå…± {len(self.trays)} ä¸ª")

    def _generate_object_position_in_tray(self, stack_level=0):
        """åœ¨æ‰˜ç›˜å†…ç”Ÿæˆç‰©ä½“ä½ç½®"""
        # æ‰˜ç›˜ä¸­å¿ƒä½ç½®
        tray_center_x = -0.2
        tray_center_y = 0.0
        tray_bottom_z = 0.02 + 0.02  # æ‰˜ç›˜åº•éƒ¨ + å°åç§»
        
        # æ‰˜ç›˜è¾¹ç•Œè®¡ç®—ï¼ˆåŸºäºURDFæ–‡ä»¶ä¸­çš„è¾¹ç•Œå¢™ä½ç½®ï¼‰
        # è¾¹ç•Œå¢™åœ¨æ‰˜ç›˜ä¸­å¿ƒçš„Â±0.2ç±³å¤„
        # å®é™…å¯ç”¨ç©ºé—´ï¼šä»ä¸­å¿ƒå‘ä¸¤è¾¹å„0.18ç±³ï¼ˆç•™å‡ºå®‰å…¨è¾¹è·ï¼‰
        safe_spawn_area_x = 0.18
        safe_spawn_area_y = 0.18
        
        # åœ¨æ‰˜ç›˜å†…éšæœºç”Ÿæˆxyä½ç½®
        x = tray_center_x + random.uniform(-safe_spawn_area_x, safe_spawn_area_x)
        y = tray_center_y + random.uniform(-safe_spawn_area_y, safe_spawn_area_y)
        
        # å †å é«˜åº¦
        z = tray_bottom_z + stack_level * 0.04  # æ¯å±‚é«˜åº¦
        
        return x, y, z

    def _get_object_size(self, obj_type):
        """è·å–ç‰©ä½“çš„å¤§å°ä¿¡æ¯"""
        # åŸºäºYCBæ•°æ®é›†çš„å®é™…ç‰©ä½“å°ºå¯¸ï¼ˆå•ä½ï¼šç±³ï¼‰
        sizes = {
            #"003_cracker_box": [0.16, 0.21, 0.07],         # é¥¼å¹²ç›’: 16cm x 21cm x 7cm
            "004_sugar_box": [0.09, 0.175, 0.044],         # ç³–ç›’: 9cm x 17.5cm x 4.4cm
            "006_mustard_bottle": [0.095, 0.095, 0.177],   # èŠ¥æœ«ç“¶: 9.5cm x 9.5cm x 17.7cm
            "008_pudding_box": [0.078, 0.109, 0.032],      # å¸ƒä¸ç›’: 7.8cm x 10.9cm x 3.2cm
            #"009_gelatin_box": [0.028, 0.085, 0.114],      # æ˜èƒ¶ç›’: 2.8cm x 8.5cm x 11.4cm  
            #"010_potted_meat_can": [0.101, 0.051, 0.051],  # ç½è£…è‚‰ç½å¤´: 10.1cm x 5.1cm x 5.1cm
           
        }
        return sizes.get(obj_type, [0.05, 0.05, 0.05])

    def _sample_target_objects(self):
        """éšæœºé€‰æ‹©ç›®æ ‡ç‰©ä½“"""
        target_objects = []
        self.target_object_indices = []
        
        for env_idx in range(self.num_envs):
            if env_idx < len(self.selectable_objects) and self.selectable_objects[env_idx]:
                # éšæœºé€‰æ‹©ä¸€ä¸ªå¯é€‰æ‹©çš„ç‰©ä½“
                target_idx = random.randint(0, len(self.selectable_objects[env_idx]) - 1)
                target_obj = self.selectable_objects[env_idx][target_idx]
                target_objects.append(target_obj)
                self.target_object_indices.append(target_idx)
        
        if target_objects:
            self.target_object = Actor.merge(target_objects, name="target_object")

    def _calculate_exposed_area(self, env_idx):
        """è®¡ç®—ç‰©ä½“çš„æš´éœ²é¢ç§¯"""
        # è¿™é‡Œæ˜¯ç®€åŒ–çš„æš´éœ²é¢ç§¯è®¡ç®—
        # å®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦æ›´å¤æ‚çš„å‡ ä½•è®¡ç®—
        if env_idx < len(self.object_info):
            for i, obj_info in enumerate(self.object_info[env_idx]):
                # åŸºäºç‰©ä½“é«˜åº¦å’Œå‘¨å›´ç‰©ä½“æ•°é‡çš„ç®€å•ä¼°ç®—
                exposed_area = max(0.1, 1.0 - i * 0.1)  # è¶Šé«˜çš„ç‰©ä½“æš´éœ²é¢ç§¯è¶Šå¤§
                obj_info['exposed_area'] = exposed_area

    def _initialize_episode(self, env_idx: torch.Tensor, options: dict):
        """åˆå§‹åŒ–æ¯ä¸ªepisode"""
        with torch.device(self.device):
            b = len(env_idx)
            self.scene_builder.initialize(env_idx)
            
            # é‡ç½®æ‰˜ç›˜ä½ç½®
            if hasattr(self, 'merged_trays'):
                # åœ¨GPUä»¿çœŸä¸­ï¼Œé™æ€å¯¹è±¡ä¸èƒ½æ”¹å˜ä½å§¿ï¼Œæ‰€ä»¥è·³è¿‡
                if not self.scene.gpu_sim_enabled:
                    if b == self.num_envs:
                        self.merged_trays.pose = self.merged_trays.initial_pose
                    else:
                        mask = torch.isin(self.merged_trays._scene_idxs, env_idx)
                        self.merged_trays.pose = self.merged_trays.initial_pose[mask]
                else:
                    #print("GPUä»¿çœŸæ¨¡å¼ä¸‹è·³è¿‡é™æ€æ‰˜ç›˜ä½å§¿é‡ç½®")
                    pass
            
            # é‡ç½®ç‰©ä½“åˆ°åˆå§‹ä½ç½®
            if hasattr(self, 'merged_objects'):
                if b == self.num_envs:
                    self.merged_objects.pose = self.merged_objects.initial_pose
                else:
                    mask = torch.isin(self.merged_objects._scene_idxs, env_idx)
                    self.merged_objects.pose = self.merged_objects.initial_pose[mask]
            
            # è®¾ç½®ç›®æ ‡ä½ç½® - å›ºå®šåœ¨æ‰˜ç›˜å³ä¾§
            goal_pos = torch.zeros((b, 3), device=self.device)
            
            # æ‰˜ç›˜ä¸­å¿ƒä½ç½®ï¼š[-0.2, 0.0, 0.02]
            # æ‰˜ç›˜å°ºå¯¸ï¼šé•¿0.6mï¼Œå®½0.6m
            # ç›®æ ‡ä½ç½®è®¾å®šåœ¨æ‰˜ç›˜å³ä¾§å¤–10cmå¤„ï¼Œé¿å…ä¸æ‰˜ç›˜è¾¹ç•Œå†²çª
            goal_pos[:, 0] = -0.4  # æ‰˜ç›˜å³ä¾§çš„å›ºå®šä½ç½®
            goal_pos[:, 1] = 0.4  
            goal_pos[:, 2] = 0.05  # æ¡Œé¢é«˜åº¦5cmï¼Œç¡®ä¿ç‰©ä½“ç¨³å®šæ”¾ç½®
            
            self.goal_pos = goal_pos
            self.goal_site.set_pose(Pose.create_from_pq(self.goal_pos))
            
            # è®°å½•åˆå§‹ç‰©ä½“ä½ç½®ï¼ˆç”¨äºè®¡ç®—ä½ç§»ï¼‰
            self.initial_object_positions = []
            for i in range(b):
                env_positions = []
                for obj in self.all_objects:
                    if hasattr(obj, '_scene_idxs') and len(obj._scene_idxs) > 0:
                        if obj._scene_idxs[0] == env_idx[i]:
                            env_positions.append(obj.pose.p.clone())
                self.initial_object_positions.append(env_positions)
            
            # è®¡ç®—æš´éœ²é¢ç§¯
            for i in range(b):
                self._calculate_exposed_area(env_idx[i])
            
            # é‡æ–°é€‰æ‹©ç›®æ ‡ç‰©ä½“ - åªåœ¨è¿ç»­åŠ¨ä½œæ¨¡å¼ä¸‹ä½¿ç”¨
            if not self.use_discrete_action:
                self._sample_target_objects()
            
            # æ–°å¢ï¼šåˆå§‹åŒ–ç¦»æ•£åŠ¨ä½œç›¸å…³å˜é‡
            if self.use_discrete_action:
                # ä¸ºæ¯ä¸ªç¯å¢ƒåˆå§‹åŒ–çŠ¶æ€
                if len(self.remaining_indices) != self.num_envs:
                    self.remaining_indices = [list(range(self.MAX_N)) for _ in range(self.num_envs)]
                    self.step_count = [0 for _ in range(self.num_envs)]
                    self.grasped_objects = [[] for _ in range(self.num_envs)]
                else:
                    # é‡ç½®æŒ‡å®šç¯å¢ƒçš„çŠ¶æ€
                    for i, env_id in enumerate(env_idx):
                        env_id_int = env_id.item() if hasattr(env_id, 'item') else int(env_id)
                        self.remaining_indices[env_id_int] = list(range(self.MAX_N))
                        self.step_count[env_id_int] = 0
                        self.grasped_objects[env_id_int] = []
                
                # æ–°å¢ï¼šé‡ç½®FSMçŠ¶æ€
                if hasattr(self, 'env_stage') and self.env_stage is not None:
                    if b == self.num_envs:
                        # é‡ç½®æ‰€æœ‰ç¯å¢ƒ
                        self.env_stage.fill_(0)
                        self.env_target.fill_(-1)
                        self.env_busy.fill_(False)
                        self.stage_tick.fill_(0)
                        self.stage_positions.fill_(0)
                    else:
                        # é‡ç½®æŒ‡å®šç¯å¢ƒ
                        for i, env_id in enumerate(env_idx):
                            env_id_int = env_id.item() if hasattr(env_id, 'item') else int(env_id)
                            if env_id_int < self.num_envs:
                                self.env_stage[env_id_int] = 0
                                self.env_target[env_id_int] = -1
                                self.env_busy[env_id_int] = False
                                self.stage_tick[env_id_int] = 0
                                self.stage_positions[env_id_int].fill_(0)
            
            # æ–°å¢ï¼šé‡ç½®å¸ç›˜çº¦æŸçŠ¶æ€
            self.suction_constraints = {}
            self.is_suction_active = [False] * self.num_envs  # æ¯ä¸ªç¯å¢ƒçš„å¸ç›˜æ¿€æ´»çŠ¶æ€
            self.current_suction_object = [None] * self.num_envs  # æ¯ä¸ªç¯å¢ƒå½“å‰å¸é™„çš„ç‰©ä½“
            
            
            # ä½¿ç”¨æŒ‡å®šçš„æœºå™¨äººåˆå§‹å§¿æ€é‡ç½®
            # æŒ‡å®šçš„å…³èŠ‚ä½ç½®ï¼š[-1.6137, 1.3258, 1.9346, -0.8884, -1.6172, 1.0867, -3.0494, 0.04, 0.04]
            #target_qpos = np.array([-0.5370, 1.3258, 1.9346, -0.8884, -1.6172, 1.0867, -3.0494, 0.04, 0.04])

            # é‡ç½®æœºå™¨äººåˆ°æŒ‡å®šå§¿æ€
            #self.agent.reset(target_qpos)
            self.agent.reset()

    def _get_obs_extra(self, info: Dict):
        """è·å–é¢å¤–è§‚æµ‹ä¿¡æ¯"""
        # è·å–æ‰¹æ¬¡å¤§å°
        batch_size = self.num_envs
        
        if not self.use_discrete_action:
            # è¿ç»­åŠ¨ä½œæ¨¡å¼ï¼šä¿æŒåŸæœ‰è§‚æµ‹ç»“æ„
            obs = dict(
                is_grasped=info["is_grasped"],
                tcp_pose=self.agent.tcp.pose.raw_pose,
                goal_pos=self.goal_site.pose.p,
            )
            
            if "state" in self.obs_mode:
                if hasattr(self, 'target_object') and self.target_object is not None:
                    obs.update(
                        target_obj_pose=self.target_object.pose.raw_pose,
                        tcp_to_obj_pos=self.target_object.pose.p - self.agent.tcp.pose.p,
                        obj_to_goal_pos=self.goal_site.pose.p - self.target_object.pose.p,
                    )
                else:
                    zero_pose = torch.zeros((batch_size, 7), device=self.device)
                    zero_pos = torch.zeros((batch_size, 3), device=self.device)
                    obs.update(
                        target_obj_pose=zero_pose,
                        tcp_to_obj_pos=zero_pos,
                        obj_to_goal_pos=zero_pos,
                    )
                
                obs.update(
                    num_objects=torch.tensor([len(self.all_objects)], device=self.device).repeat(batch_size),
                )
            return obs
        
        # ç¦»æ•£åŠ¨ä½œæ¨¡å¼ï¼šæ˜“æ”¶æ•›çš„baselineç‰¹å¾é›†
        
        # 1. å…¨å±€ç‰¹å¾ (æ¯ç¯å¢ƒ 3 ç»´)
        global_features = []
        for env_idx in range(batch_size):
            grasped_count = len(self.grasped_objects[env_idx])
            grasped_ratio = grasped_count / float(self.total_objects_per_env)  # å·²æŠ“æ•°é‡/æ€»æ•°é‡
            
            # ä½¿ç”¨æŠ“å–å°è¯•æ¬¡æ•°çš„æ¯”ä¾‹ä½œä¸ºç‰¹å¾
            attempt_ratio = min(self.step_count[env_idx] / float(self.total_objects_per_env), 1.0)  # æŠ“å–å°è¯•æ¬¡æ•°/æ€»æ•°é‡ï¼Œé™åˆ¶åœ¨[0,1]
            remaining_ratio = (self.total_objects_per_env - grasped_count) / float(self.total_objects_per_env)  # å‰©ä½™æ•°é‡/æ€»æ•°é‡
            
            global_features.append([grasped_ratio, attempt_ratio, remaining_ratio])
        
        global_features = torch.tensor(global_features, device=self.device, dtype=torch.float32)  # [batch_size, 3]
        
        # 2. æ¯ç‰©ä½“ç‰¹å¾ 
        # è·å–å·¥ä½œç©ºé—´èŒƒå›´ç”¨äºå½’ä¸€åŒ–
        workspace_min = torch.tensor([-0.5, -0.5, 0.0], device=self.device)  # å·¥ä½œç©ºé—´æœ€å°å€¼
        workspace_max = torch.tensor([0.5, 0.5, 0.3], device=self.device)     # å·¥ä½œç©ºé—´æœ€å¤§å€¼
        workspace_size = workspace_max - workspace_min
        
        # è·å–æœ€å¤§ç‰©ä½“å°ºå¯¸ç”¨äºå½’ä¸€åŒ–
        max_size = 0.2  # å‡è®¾æœ€å¤§ç‰©ä½“å°ºå¯¸ä¸º0.2m
        
        object_features = []  # [batch_size, 8, 8]
        action_mask = []      # [batch_size, 8]
        
        for env_idx in range(batch_size):
            env_obj_features = []
            env_mask = []
            
            for obj_idx in range(self.total_objects_per_env):  # åŠ¨æ€ç‰©ä½“æ•°é‡
                # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ç¯å¢ƒç‰¹å®šçš„ç‰©ä½“åˆ—è¡¨è€Œä¸æ˜¯å…¨å±€ç´¢å¼•
                if (env_idx < len(self.selectable_objects) and 
                    obj_idx < len(self.selectable_objects[env_idx])):
                    
                    # è·å–ç¯å¢ƒç‰¹å®šçš„ç‰©ä½“
                    target_obj = self.selectable_objects[env_idx][obj_idx]
                    obj_pose_p = target_obj.pose.p
                    
                    # å¤„ç†å¤šç¯å¢ƒä½ç½®æ•°æ®
                    if len(obj_pose_p.shape) > 1 and obj_pose_p.shape[0] > env_idx:
                        obj_pos = obj_pose_p[env_idx]  # [3]
                    elif len(obj_pose_p.shape) > 1 and obj_pose_p.shape[0] == 1:
                        obj_pos = obj_pose_p[0]
                    else:
                        obj_pos = obj_pose_p
                    
                    # ä½ç½®å½’ä¸€åŒ–åˆ° [0, 1]
                    pos_normalized = (obj_pos - workspace_min) / workspace_size
                    pos_normalized = torch.clamp(pos_normalized, 0.0, 1.0)
                    
                    # è·å–ç‰©ä½“å°ºå¯¸å¹¶å½’ä¸€åŒ–
                    obj_type_idx = obj_idx // self.num_objects_per_type
                    if obj_type_idx < len(self.BOX_OBJECTS):
                        obj_type = self.BOX_OBJECTS[obj_type_idx]
                        size = self._get_object_size(obj_type)
                        obj_size = torch.tensor(size, device=self.device)
                    else:
                        obj_size = torch.tensor([0.05, 0.05, 0.05], device=self.device)
                    
                    # å°ºå¯¸å½’ä¸€åŒ–åˆ° [0, 1]
                    size_normalized = obj_size / max_size
                    size_normalized = torch.clamp(size_normalized, 0.0, 1.0)
                    
                    # æŠ“å–æ ‡å¿—
                    grabbed_flag = 1.0 if obj_idx in self.grasped_objects[env_idx] else 0.0
                    
                    # é«˜åº¦ç‰¹å¾ (å¯é€‰ï¼Œå¦‚æœå·²åŒ…å«åœ¨pos_normalizedä¸­å¯ä»¥å»æ‰)
                    topness = pos_normalized[2]  # zåæ ‡å·²ç»å½’ä¸€åŒ–
                    
                    # ç»„åˆç‰¹å¾: [size_x, size_y, size_z, pos_x, pos_y, pos_z, grabbed_flag, topness]
                    obj_feature = torch.cat([
                        size_normalized,      # [3] - å°ºå¯¸
                        pos_normalized,       # [3] - ä½ç½®
                        torch.tensor([grabbed_flag], device=self.device),  # [1] - æŠ“å–æ ‡å¿—
                        torch.tensor([topness], device=self.device)        # [1] - é«˜åº¦ç‰¹å¾
                    ])  # æ€»å…±8ç»´
                    
                    # åŠ¨ä½œæ©ç ï¼šæœªæŠ“å–=1(å¯é€‰)ï¼Œå·²æŠ“å–=0(ä¸å¯é€‰)
                    mask_value = 0.0 if grabbed_flag > 0.5 else 1.0
                    
                else:
                    # å¡«å……é›¶ç‰¹å¾
                    obj_feature = torch.zeros(8, device=self.device)
                    mask_value = 0.0  # ä¸å­˜åœ¨çš„ç‰©ä½“ä¸å¯é€‰
                
                env_obj_features.append(obj_feature)
                env_mask.append(mask_value)
            
            object_features.append(torch.stack(env_obj_features))  # [8, 8]
            action_mask.append(torch.tensor(env_mask, device=self.device))  # [8]
        
        object_features = torch.stack(object_features)  # [batch_size, 8, 8]
        action_mask = torch.stack(action_mask)          # [batch_size, 8]
        
        # 3. å±•å¹³ç‰©ä½“ç‰¹å¾
        object_features_flat = object_features.view(batch_size, -1)  # [batch_size, total_objects_per_env * 8]
        
        # 4. ç»„åˆæœ€ç»ˆè§‚æµ‹
        # obs = concat(obj_feats.flatten(), action_mask, global_feats)
        final_obs = torch.cat([
            object_features_flat,  # [batch_size, total_objects_per_env * 8] - ç‰©ä½“ç‰¹å¾
            action_mask,          # [batch_size, total_objects_per_env]  - åŠ¨ä½œæ©ç 
            global_features       # [batch_size, 3]  - å…¨å±€ç‰¹å¾
        ], dim=1)  # [batch_size, total_objects_per_env * 9 + 3]
        
        # è¿”å›æ‰å¹³åŒ–çš„è§‚æµ‹å‘é‡ï¼Œç¬¦åˆbaselineè®­ç»ƒè¦æ±‚
        return final_obs

    
    def _close_gripper(self):
        """é—­åˆå¤¹çˆª"""
        # æ„å»º7ç»´åŠ¨ä½œå‘é‡ [dx, dy, dz, drx, dry, drz, gripper]
        action = torch.zeros(self.num_envs, 7, device=self.device, dtype=torch.float32)
        action[:, 6] = 0.00  # é—­åˆå¤¹çˆª
        
        # æ‰§è¡Œå¤šæ­¥ä»¥ç¡®ä¿å¤¹çˆªé—­åˆ
        for _ in range(5):
            self._low_level_step(action)
    
    def _open_gripper(self):
        """æ‰“å¼€å¤¹çˆª"""
        # æ„å»º7ç»´åŠ¨ä½œå‘é‡ [dx, dy, dz, drx, dry, drz, gripper]
        action = torch.zeros(self.num_envs, 7, device=self.device, dtype=torch.float32)
        action[:, 6] = 0.04  # æ‰“å¼€å¤¹çˆª
        
        # æ‰§è¡Œå¤šæ­¥ä»¥ç¡®ä¿å¤¹çˆªæ‰“å¼€
        for _ in range(5):
            self._low_level_step(action)

    def step(self, action):
        """
        è¦†ç›–stepæ–¹æ³•ä»¥æ”¯æŒç¦»æ•£åŠ¨ä½œé€‰æ‹©
        
        Args:
            action: å¦‚æœuse_discrete_action=Trueï¼Œåˆ™ä¸ºç‰©ä½“ç´¢å¼•ï¼›å¦åˆ™ä¸ºè¿ç»­åŠ¨ä½œ
        """
        if self.use_discrete_action:
            return self._discrete_step(action)
        else:
            # è°ƒç”¨çˆ¶ç±»çš„è¿ç»­åŠ¨ä½œstep
            return super().step(action)
    
    def _discrete_step(self, action):
        """
        å¤„ç†ç¦»æ•£åŠ¨ä½œçš„stepæ–¹æ³• - å¹¶è¡ŒçŠ¶æ€æœºç‰ˆæœ¬
        
        Args:
            action: è¦æŠ“å–çš„ç‰©ä½“ç´¢å¼•ï¼Œå½¢çŠ¶ä¸º(num_envs,)æˆ–æ ‡é‡
        """
        # ç¡®ä¿actionæ˜¯æ­£ç¡®çš„å½¢çŠ¶
        if isinstance(action, (int, np.integer)):
            # å•ä¸ªåŠ¨ä½œï¼Œå¤åˆ¶åˆ°æ‰€æœ‰ç¯å¢ƒ
            action = np.full(self.num_envs, action)
        elif isinstance(action, torch.Tensor):
            action = action.cpu().numpy()
        elif isinstance(action, np.ndarray):
            if action.shape == ():  # æ ‡é‡æ•°ç»„
                action = np.full(self.num_envs, action.item())
        
        # ç¡®ä¿actionæ˜¯æ­£ç¡®é•¿åº¦çš„æ•°ç»„
        if len(action) != self.num_envs:
            print(f"è­¦å‘Šï¼šåŠ¨ä½œé•¿åº¦{len(action)}ä¸ç¯å¢ƒæ•°é‡{self.num_envs}ä¸åŒ¹é…")
            action = np.full(self.num_envs, action[0] if len(action) > 0 else 0)
        
        # 1. æŠŠæ–°æŒ‡ä»¤åˆ†é…ç»™ç©ºé—²ç¯å¢ƒ
        for i in range(self.num_envs):
            if not self.env_busy[i]:
                pick = int(action[i])
                if pick >= 0 and pick < len(self.remaining_indices[i]):
        # è·å–å®é™…çš„ç‰©ä½“ç´¢å¼•
                    target_idx = self.remaining_indices[i][pick]
                    self.env_target[i] = target_idx
                    self.remaining_indices[i].pop(pick)
                    self.env_stage[i] = 0
                    self.env_busy[i] = True
                    self.stage_tick[i] = 0
                    self.step_count[i] += 1
        
        # 2. ç”Ÿæˆè¿ç»­åŠ¨ä½œ - ä¸ºæ‰€æœ‰å¿™ç¢Œçš„ç¯å¢ƒæ‰§è¡Œä¸€æ­¥FSM
        cmd = torch.zeros(self.num_envs, 7, device=self.device, dtype=torch.float32)
        for i in range(self.num_envs):
            if self.env_busy[i]:
                cmd[i] = self._pick_object_step(i)
        
        # 3. æ‰§è¡Œä¸€æ­¥ä»¿çœŸ
        super().step(cmd)
        
        # 4. æ›´æ–°ç¯å¢ƒçŠ¶æ€ï¼ˆé‡ç½®åˆšå®ŒæˆæŠ“å–çš„ç›®æ ‡ï¼‰
        for env_idx in range(self.num_envs):
            if not self.env_busy[env_idx] and self.env_target[env_idx] != -1:
                # é‡ç½®ç›®æ ‡
                self.env_target[env_idx] = -1
        
        # 5. ä½¿ç”¨æ ‡å‡†çš„å¥–åŠ±è®¡ç®—æµç¨‹
        info = self.get_info()
        obs = self.get_obs(info)
        reward = self.get_reward(obs=obs, action=action, info=info)
        
        # 6. æ£€æŸ¥ç»ˆæ­¢æ¡ä»¶ - ä½¿ç”¨æ ‡å‡†çš„ ManiSkill é€»è¾‘
        # success å’Œ fail éƒ½ä¼šå¯¼è‡´ episode æå‰ç»“æŸ
        # info å·²ç»åŒ…å«äº† evaluate() çš„ç»“æœï¼Œç›´æ¥ä½¿ç”¨
        terminated = torch.zeros(self.num_envs, dtype=torch.bool, device=self.device)
        truncated = torch.zeros(self.num_envs, dtype=torch.bool, device=self.device)
        
        # ä½¿ç”¨ info ä¸­çš„ success å’Œ fail çŠ¶æ€
        if "success" in info and "fail" in info:
            terminated = torch.logical_or(info["success"], info["fail"])
        elif "success" in info:
            terminated = info["success"].clone()
        elif "fail" in info:
            terminated = info["fail"].clone()
        
        return obs, reward, terminated, truncated, info
    
    def _pick_object_step(self, env_idx: int) -> torch.Tensor:
        """
        å•æ­¥çŠ¶æ€æœºæ‰§è¡Œ - æ¯æ¬¡è°ƒç”¨åªæ‰§è¡Œå½“å‰çŠ¶æ€çš„ä¸€å°æ­¥
        
        Args:
            env_idx: ç¯å¢ƒç´¢å¼•
            
        Returns:
            action: è¯¥ç¯å¢ƒçš„è¿ç»­åŠ¨ä½œå‘é‡ [dx, dy, dz, drx, dry, drz, gripper]
        """
        stage = self.env_stage[env_idx].item()
        target_idx = self.env_target[env_idx].item()
        tick = self.stage_tick[env_idx].item()
        
        # åˆå§‹åŒ–åŠ¨ä½œå‘é‡
        action = torch.zeros(7, device=self.device, dtype=torch.float32)
        
        try:
            # å…³é”®ä¿®å¤ï¼šä½¿ç”¨selectable_objectsæ ¹æ®ç¯å¢ƒå’Œç›¸å¯¹ç´¢å¼•è·å–æ­£ç¡®çš„ç‰©ä½“å¯¹è±¡
            if target_idx < 0 or env_idx >= len(self.selectable_objects) or target_idx >= len(self.selectable_objects[env_idx]):
                # æ— æ•ˆç›®æ ‡ï¼Œç»“æŸæµç¨‹
                print(f"ç¯å¢ƒ{env_idx}: æ— æ•ˆç›®æ ‡ç´¢å¼• target_idx={target_idx}, selectable_objectsé•¿åº¦={len(self.selectable_objects[env_idx]) if env_idx < len(self.selectable_objects) else 0}")
                self.env_busy[env_idx] = False
                return action
            
            # ä½¿ç”¨ç¯å¢ƒç‰¹å®šçš„ç‰©ä½“åˆ—è¡¨è·å–ç›®æ ‡ç‰©ä½“
            target_obj = self.selectable_objects[env_idx][target_idx]
            #print(f"ç¯å¢ƒ{env_idx}: ä½¿ç”¨ç›®æ ‡ç‰©ä½“ {target_obj.name} (ç¯å¢ƒå†…ç´¢å¼•={target_idx})")
            
            # è·å–ç›®æ ‡ç‰©ä½“ä½ç½®
            obj_pos = target_obj.pose.p
            obj_pos = obj_pos[0]
            obj_pos = obj_pos.cpu().numpy()
            
            # è·å–å½“å‰TCPä½ç½®
            tcp_pos = self.agent.tcp.pose.p
            if tcp_pos.dim() > 1:
                if env_idx < tcp_pos.shape[0]:
                    tcp_pos = tcp_pos[env_idx]
                else:
                    tcp_pos = tcp_pos[0]
                    print(f"âš ï¸ ç¯å¢ƒ{env_idx}: TCPä½ç½®ç´¢å¼•è¶Šç•Œï¼Œä½¿ç”¨ç¯å¢ƒ0çš„ä½ç½®")
            
            # çŠ¶æ€æœºé€»è¾‘
            if stage == 0:
                # çŠ¶æ€0: ç§»åŠ¨åˆ°ç‰©ä½“ä¸Šæ–¹
                if tick == 0:
                    # ç¬¬ä¸€æ¬¡è¿›å…¥æ­¤çŠ¶æ€ï¼Œè®¾ç½®ç›®æ ‡ä½ç½®
                    target_pos = obj_pos.copy()
                    target_pos[2] += 0.15  # ä¸Šæ–¹15cm
                    self.stage_positions[env_idx] = torch.tensor(target_pos, device=self.device)
                    print(f"ç¯å¢ƒ{env_idx}: çŠ¶æ€0åˆå§‹åŒ– - ç‰©ä½“ä½ç½®={obj_pos}, ç›®æ ‡ä½ç½®={target_pos}")
                
                target_pos = self.stage_positions[env_idx]
                action[:3], reached = self._get_move_action(tcp_pos, target_pos, max_steps=150)
                
                # æ·»åŠ è°ƒè¯•ä¿¡æ¯
                current_distance = torch.linalg.norm(tcp_pos - target_pos).item()
                # æ‰“å°è¿›åº¦ï¼ˆå‡å°‘è¾“å‡ºé¢‘ç‡ï¼‰
                if tick % 10 == 0 :  # å‰5æ­¥å’Œæ¯30æ­¥è¾“å‡ºä¸€æ¬¡
                    #print(f"ç¯å¢ƒ{env_idx}: çŠ¶æ€0 æ­¥{tick} - TCPä½ç½®={tcp_pos.cpu().numpy()}, ç›®æ ‡ä½ç½®={target_pos.cpu().numpy()}, è·ç¦»={current_distance:.4f}m, åˆ°è¾¾={'æ˜¯' if reached else 'å¦'}")
                    print(f"ç¯å¢ƒ{env_idx}: çŠ¶æ€0 æ­¥{tick}, è·ç¦»={current_distance:.4f}m, åˆ°è¾¾={'æ˜¯' if reached else 'å¦'}")
                
                if reached or tick >= 150:
                    print(f"ç¯å¢ƒ{env_idx}: çŠ¶æ€0å®Œæˆ - reached={reached}, tick={tick}")
                    self.env_stage[env_idx] = 1
                    self.stage_tick[env_idx] = 0
                else:
                    self.stage_tick[env_idx] += 1
            
            elif stage == 1:
                # çŠ¶æ€1: ä¸‹é™åˆ°ç‰©ä½“ä¸Šæ–¹
                if tick == 0:
                    target_pos = obj_pos.copy()
                    target_pos[2] += 0.05  # ä¸Šæ–¹3cm
                    self.stage_positions[env_idx] = torch.tensor(target_pos, device=self.device)
                
                target_pos = self.stage_positions[env_idx]
                action[:3], reached = self._get_move_action(tcp_pos, target_pos, max_steps=80)
                
                if reached or tick >= 80:
                    self.env_stage[env_idx] = 2
                    self.stage_tick[env_idx] = 0
                else:
                    self.stage_tick[env_idx] += 1
            
            elif stage == 2:
                # çŠ¶æ€2: æŠ“å–ç‰©ä½“
                if tick == 0:
                    target_pos = obj_pos.copy()
                    target_pos[2] += 0.01  # ä¸Šæ–¹1cm
                    self.stage_positions[env_idx] = torch.tensor(target_pos, device=self.device)
                
                target_pos = self.stage_positions[env_idx]
                action[:3], reached = self._get_move_action(tcp_pos, target_pos, max_steps=80)
                
                if reached or tick >= 80:
                    # å°è¯•åˆ›å»ºå¸ç›˜çº¦æŸ
                    suction_success = self._create_suction_constraint(target_obj, env_idx)
                    if suction_success and self._check_suction_grasp_success(target_obj, env_idx):
                        self.env_stage[env_idx] = 3
                        self.stage_tick[env_idx] = 0
                    else:
                        # æŠ“å–å¤±è´¥ï¼Œç»“æŸæµç¨‹
                        print(f"ç¯å¢ƒ{env_idx}: æŠ“å–å¤±è´¥ï¼Œç»“æŸæµç¨‹")
                        self.env_busy[env_idx] = False
                else:
                    self.stage_tick[env_idx] += 1
            
            elif stage == 3:
                # çŠ¶æ€3: ç‰©ä½“ä¸Šå‡
                if tick == 0:
                    current_pos = tcp_pos.cpu().numpy()
                    target_pos = current_pos.copy()
                    target_pos[2] += 0.2  # ä¸Šå‡20cm
                    self.stage_positions[env_idx] = torch.tensor(target_pos, device=self.device)
                
                target_pos = self.stage_positions[env_idx]
                action[:3], reached = self._get_move_action(tcp_pos, target_pos, max_steps=100)
                
                if reached or tick >= 100:
                    self.env_stage[env_idx] = 4
                    self.stage_tick[env_idx] = 0
                else:
                    self.stage_tick[env_idx] += 1
            
            elif stage == 4:
                # çŠ¶æ€4: ç§»åŠ¨åˆ°æ”¾ç½®ä½ç½®
                if tick == 0:
                    current_z = tcp_pos[2].item()
                    target_pos = np.array([-0.4, 0.4, current_z])  # ä¿æŒå½“å‰é«˜åº¦
                    self.stage_positions[env_idx] = torch.tensor(target_pos, device=self.device)
                
                target_pos = self.stage_positions[env_idx]
                action[:3], reached = self._get_move_action(tcp_pos, target_pos, max_steps=180)
                
                if reached or tick >= 180:
                    self.env_stage[env_idx] = 5
                    self.stage_tick[env_idx] = 0
                else:
                    self.stage_tick[env_idx] += 1
            
            elif stage == 5:
                # çŠ¶æ€5: ä¸‹é™åˆ°æ”¾ç½®ä½ç½®
                if tick == 0:
                    current_pos = self.stage_positions[env_idx].cpu().numpy()  # ä½¿ç”¨çŠ¶æ€4çš„ç›®æ ‡ä½ç½®
                    target_pos = current_pos.copy()
                    target_pos[2] = 0.05  # ä¸‹é™åˆ°æ¡Œé¢é«˜åº¦5cm
                    self.stage_positions[env_idx] = torch.tensor(target_pos, device=self.device)
                
                target_pos = self.stage_positions[env_idx]
                action[:3], reached = self._get_move_action(tcp_pos, target_pos, max_steps=100)
                
                if reached or tick >= 100:
                    self.env_stage[env_idx] = 6
                    self.stage_tick[env_idx] = 0
                else:
                    self.stage_tick[env_idx] += 1
            
            elif stage == 6:
                # çŠ¶æ€6: æ”¾ä¸‹ç‰©ä½“
                if tick == 0:
                    # å°è¯•ç§»é™¤å¸ç›˜çº¦æŸï¼ˆåªåœ¨ç¬¬ä¸€æ¬¡å°è¯•ï¼‰
                    try:
                        if self.is_suction_active[env_idx] and self.current_suction_object[env_idx] is not None:
                            success = self._remove_suction_constraint(env_idx)
                            if success:
                                print(f"ç§»é™¤å¸ç›˜çº¦æŸæˆåŠŸ env={env_idx}")
                            else:
                                print(f"ç§»é™¤å¸ç›˜çº¦æŸå¤±è´¥ env={env_idx}")
                            
                    except Exception as e:
                        # å¸ç›˜çº¦æŸç§»é™¤å¤±è´¥ä¸å½±å“çŠ¶æ€è½¬æ¢
                        print(f"ç§»é™¤å¸ç›˜çº¦æŸå¼‚å¸¸ env={env_idx}: {e}")
                        pass
                
                # ç­‰å¾…ç‰©ä½“ç¨³å®š
                if tick >= 10:  # ç­‰å¾…10æ­¥è®©ç‰©ä½“ç¨³å®š
                    self.env_stage[env_idx] = 7
                    self.stage_tick[env_idx] = 0
                else:
                    self.stage_tick[env_idx] += 1
            
            elif stage == 7:
                # çŠ¶æ€7: å›åˆ°åˆå§‹ä½ç½®
                if tick == 0:
                    target_pos = np.array([-0.6, 0.4, 0.4])  # å®‰å…¨çš„åˆå§‹ä½ç½®
                    self.stage_positions[env_idx] = torch.tensor(target_pos, device=self.device)
                
                target_pos = self.stage_positions[env_idx]
                action[:3], reached = self._get_move_action(tcp_pos, target_pos, max_steps=100)
                
                if reached or tick >= 100:
                    # å®Œæˆæ•´ä¸ªæµç¨‹
                    self.env_busy[env_idx] = False
                    # ä¿®å¤ï¼šä½¿ç”¨ç›¸å¯¹ç´¢å¼•æ ‡è®°æŠ“å–æˆåŠŸ
                    self.grasped_objects[env_idx].append(target_idx)
                    self.stage_tick[env_idx] = 0
                    print(f"ç¯å¢ƒ{env_idx}å®ŒæˆæŠ“å–ç‰©ä½“{target_obj.name} (ç›¸å¯¹ç´¢å¼•={target_idx})")
                else:
                    self.stage_tick[env_idx] += 1
            
            else:
                # æœªçŸ¥çŠ¶æ€ï¼Œç»“æŸæµç¨‹
                self.env_busy[env_idx] = False
            
            # å§¿æ€æ§åˆ¶ï¼šä¿æŒå‚ç›´å‘ä¸‹
            action[3:6] = 0.0
            # å¤¹çˆªæ§åˆ¶
            action[6] = 0.0
            
            return action
            
        except Exception as e:
            print(f"çŠ¶æ€æœºæ‰§è¡Œé”™è¯¯ env={env_idx}, stage={stage}: {e}")
            # å‡ºé”™æ—¶ç»“æŸæµç¨‹
            self.env_busy[env_idx] = False
            return action
    
    def _get_move_action(self, current_pos: torch.Tensor, target_pos: torch.Tensor, 
                        max_steps: int = 100) -> Tuple[torch.Tensor, bool]:
        """
        è·å–ç§»åŠ¨åŠ¨ä½œå’Œæ˜¯å¦åˆ°è¾¾ç›®æ ‡
        
        Args:
            current_pos: å½“å‰ä½ç½®
            target_pos: ç›®æ ‡ä½ç½®
            max_steps: æœ€å¤§æ­¥æ•°ï¼ˆç”¨äºåˆ¤æ–­è¶…æ—¶ï¼‰
            
        Returns:
            action: ä½ç½®åŠ¨ä½œ [dx, dy, dz]
            reached: æ˜¯å¦åˆ°è¾¾ç›®æ ‡
        """
        if isinstance(target_pos, np.ndarray):
            target_pos = torch.tensor(target_pos, device=self.device, dtype=torch.float32)
        
        # è®¡ç®—ä½ç½®è¯¯å·®
        pos_error = target_pos - current_pos
        current_distance = torch.linalg.norm(pos_error).item()
        
        # åˆ¤æ–­æ˜¯å¦åˆ°è¾¾ - æ”¾å®½é˜ˆå€¼åˆ°5cm
        reached = current_distance < 0.05
        
        if reached:
            print(f"_get_move_action: å·²åˆ°è¾¾ç›®æ ‡ï¼Œè·ç¦»={current_distance:.4f}m")
            return torch.zeros(3, device=self.device, dtype=torch.float32), True
        
        # è®¡ç®—ç§»åŠ¨åŠ¨ä½œ
        max_controller_step = 0.1  # æ§åˆ¶å™¨æ”¯æŒçš„æœ€å¤§å¢é‡ï¼š10cm
        
        # ä¼˜åŒ–æ­¥é•¿ç­–ç•¥ - æé«˜æ”¶æ•›é€Ÿåº¦
        if current_distance > 0.15:
            scale_factor = 1.0  # ä½¿ç”¨100%çš„æ§åˆ¶å™¨èƒ½åŠ›
        elif current_distance > 0.10:
            scale_factor = 0.95  # ç¨å¾®å‡é€Ÿ
        elif current_distance > 0.05:
            scale_factor = 0.8  # ä¸­ç­‰é€Ÿåº¦
        else:
            scale_factor = 0.7  # æé«˜ç²¾ç»†æ§åˆ¶é€Ÿåº¦ï¼ˆä»0.5æå‡åˆ°0.7ï¼‰
        
        actual_max_step = max_controller_step * scale_factor
        
        # å½’ä¸€åŒ–ä½ç½®è¯¯å·®
        pos_error_norm = torch.linalg.norm(pos_error)
        if pos_error_norm > actual_max_step:
            action = (pos_error / pos_error_norm) * actual_max_step
        else:
            action = pos_error
        
        #print(f"_get_move_action: è·ç¦»={current_distance:.4f}m, åŠ¨ä½œ={action.cpu().numpy()}, scale_factor={scale_factor}")
        
        return action, False
    
    def _get_failed_step_result(self):
        """è·å–å¤±è´¥æ­¥éª¤çš„ç»“æœ"""
        # æƒ©ç½šæ€§å¥–åŠ± - è½¬æ¢ä¸ºtorch.Tensor
        reward = torch.tensor([-1.0], device=self.device, dtype=torch.float32)
        
        # ä¸ç»ˆæ­¢ï¼Œè®©æ™ºèƒ½ä½“å­¦ä¹  - è½¬æ¢ä¸ºtorch.Tensor
        terminated = torch.tensor([False], device=self.device, dtype=torch.bool)
        truncated = torch.tensor([False], device=self.device, dtype=torch.bool)
        
        # è·å–å½“å‰è§‚æµ‹
        info = self.evaluate()
        info.update({
            'success': False,
            'displacement': 0.0,
            'remaining_objects': sum(len(env_remaining) for env_remaining in self.remaining_indices),
            'grasped_objects': sum(len(env_grasped) for env_grasped in self.grasped_objects),
        })
        
        obs = self._get_obs_extra(info)
        
        return obs, reward, terminated, truncated, info



    @property
    def discrete_action_space(self):
        """è·å–ç¦»æ•£åŠ¨ä½œç©ºé—´"""
        if self.use_discrete_action:
            import gymnasium as gym
            return gym.spaces.Discrete(self.MAX_N)
        else:
            return None

    def evaluate(self):
        """è¯„ä¼°ä»»åŠ¡å®Œæˆæƒ…å†µ"""
        success = torch.zeros(self.num_envs, device=self.device, dtype=bool)
        fail = torch.zeros(self.num_envs, device=self.device, dtype=bool)
        is_grasped = torch.zeros(self.num_envs, device=self.device, dtype=bool)
        is_robot_static = torch.zeros(self.num_envs, device=self.device, dtype=bool)
        is_obj_placed = torch.zeros(self.num_envs, device=self.device, dtype=bool)
        
        if self.use_discrete_action:
            # ç¦»æ•£åŠ¨ä½œæ¨¡å¼ï¼šåŸºäºæŠ“å–æˆåŠŸçš„ç‰©ä½“æ•°é‡æ¯”ä¾‹è¯„ä¼°
            for env_idx in range(self.num_envs):
                # è®¡ç®—æŠ“å–æˆåŠŸçš„ç‰©ä½“æ•°é‡
                grasped_count = len(self.grasped_objects[env_idx])
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ç‰©ä½“è¢«æˆåŠŸæŠ“å–
                is_grasped[env_idx] = grasped_count > 0
                
                # è®¡ç®—æˆåŠŸç‡ï¼šæŠ“å–æˆåŠŸçš„ç‰©ä½“æ•°é‡æ¯”ä¾‹
                success_ratio = grasped_count / self.total_objects_per_env
                success[env_idx] = success_ratio == 1.0   # æ‰€æœ‰ç‰©ä½“éƒ½è¢«æŠ“å–è®¤ä¸ºæˆåŠŸ
                
                # å¤±è´¥æ¡ä»¶ï¼šè¾¾åˆ°æœ€å¤§æŠ“å–å°è¯•æ¬¡æ•°ä½†æœªæˆåŠŸ
                # æ³¨æ„ï¼šstep_countæ˜¯æŠ“å–å°è¯•æ¬¡æ•°ï¼Œä¸æ˜¯æ€»ä»¿çœŸæ­¥æ•°
                # MAX_EPISODE_STEPS=15 è¡¨ç¤ºæœ€å¤š15æ¬¡æŠ“å–å°è¯•
                if hasattr(self, 'step_count'):
                    fail[env_idx] = self.step_count[env_idx] >= self.MAX_EPISODE_STEPS and not success[env_idx]
        else:
            # è¿ç»­åŠ¨ä½œæ¨¡å¼ï¼šåŸºäºtarget_objectè¯„ä¼°
            if hasattr(self, 'target_object') and self.target_object is not None:
                # æ£€æŸ¥ç‰©ä½“æ˜¯å¦æ”¾ç½®åˆ°ç›®æ ‡ä½ç½®
                obj_to_goal_dist = torch.linalg.norm(
                    self.goal_site.pose.p - self.target_object.pose.p, axis=1
                )
                is_obj_placed = obj_to_goal_dist <= self.goal_thresh
                
                # æ£€æŸ¥æ˜¯å¦æŠ“å–
                is_grasped = self.agent.is_grasping(self.target_object)
                
                # æ£€æŸ¥æœºå™¨äººæ˜¯å¦é™æ­¢
                is_robot_static = self.agent.is_static(0.2)
                
                # æˆåŠŸæ¡ä»¶ï¼šç‰©ä½“æ”¾ç½®åˆ°ä½ä¸”æœºå™¨äººé™æ­¢
                success = is_obj_placed & is_robot_static
        
        return {
            "success": success,
            "fail": fail,
            "is_obj_placed": is_obj_placed,
            "is_robot_static": is_robot_static,
            "is_grasped": is_grasped,
        }

    def _calculate_other_objects_displacement(self):
        """è®¡ç®—å…¶ä»–ç‰©ä½“çš„ä½ç§»è·ç¦»"""
        total_displacement = torch.zeros(self.num_envs, device=self.device)
        
        for env_idx in range(self.num_envs):
            displacement = 0.0
            obj_count = 0
            
            for i, obj in enumerate(self.all_objects):
                if hasattr(obj, '_scene_idxs') and len(obj._scene_idxs) > 0:
                    if obj._scene_idxs[0] == env_idx:
                        # è·³è¿‡ç›®æ ‡ç‰©ä½“
                        if hasattr(self, 'target_object_indices') and env_idx < len(self.target_object_indices):
                            if i == self.target_object_indices[env_idx]:
                                continue
                        
                        # è®¡ç®—ä½ç§»
                        if hasattr(self, 'initial_object_positions') and env_idx < len(self.initial_object_positions):
                            if obj_count < len(self.initial_object_positions[env_idx]):
                                initial_pos = self.initial_object_positions[env_idx][obj_count]
                                current_pos = obj.pose.p
                                displacement += torch.linalg.norm(current_pos - initial_pos)
                                obj_count += 1
            
            total_displacement[env_idx] = displacement
        
        return total_displacement

    def compute_dense_reward(self, obs: Any, action: torch.Tensor, info: Dict):
        """è®¡ç®—å¯†é›†å¥–åŠ±"""
        reward = torch.zeros(self.num_envs, device=self.device)
        
        # æ ¹æ®åŠ¨ä½œæ¨¡å¼é€‰æ‹©ä¸åŒçš„å¥–åŠ±è®¡ç®—ç­–ç•¥
        if self.use_discrete_action:
            # ç¦»æ•£åŠ¨ä½œæ¨¡å¼ï¼šä½¿ç”¨é€‰æ‹©å¥–åŠ±é€»è¾‘
            return self._compute_discrete_action_reward(info)
        else:
            # è¿ç»­åŠ¨ä½œæ¨¡å¼ï¼šä½¿ç”¨åŸæœ‰çš„å¯†é›†å¥–åŠ±é€»è¾‘
            return self._compute_continuous_action_reward(info)
    
    def _compute_discrete_action_reward(self, info: Dict):
        """è®¡ç®—ç¦»æ•£åŠ¨ä½œæ¨¡å¼çš„å¥–åŠ± - æ˜“æ”¶æ•›çš„baselineç‰ˆæœ¬
        
        æ³¨æ„ï¼šåœ¨ç¦»æ•£åŠ¨ä½œæ¨¡å¼ä¸‹ï¼Œæ¯ä¸ªåŠ¨ä½œä»£è¡¨é€‰æ‹©ä¸€ä¸ªç‰©ä½“è¿›è¡ŒæŠ“å–
        å¥–åŠ±åœ¨æ¯ä¸ªä»¿çœŸæ­¥éƒ½ä¼šè®¡ç®—ï¼Œä½†ä¸»è¦çš„å¥–åŠ±ä¿¡å·æ¥è‡ªäºæŠ“å–æˆåŠŸ
        """
        reward = torch.zeros(self.num_envs, device=self.device)
        
        # å¥–åŠ±ç³»æ•° - æ˜“è°ƒå‚ã€æ˜“æ”¶æ•›
        w_success = 2.0      # æˆåŠŸæŠ“å–å¥–åŠ±æƒé‡
        w_time = 0.01        # æ—¶é—´æƒ©ç½šæƒé‡ï¼ˆæ¯ä¸ªä»¿çœŸæ­¥ï¼‰
        w_disp = 0.5         # ä½ç§»æƒ©ç½šæƒé‡ï¼ˆç®€åŒ–å¤„ç†ï¼‰
        R_complete = 10.0    # å…¨éƒ¨å®Œæˆå¤§å¥–åŠ±
        disp_scale = 0.1     # ä½ç§»ç¼©æ”¾å› å­
        
        for env_idx in range(self.num_envs):
            # è®¡ç®—å½“å‰çŠ¶æ€
            grasped_count = len(self.grasped_objects[env_idx])
            
            # æ£€æŸ¥æ˜¯å¦åˆšå®Œæˆä¸€æ¬¡æŠ“å–åŠ¨ä½œï¼ˆç¯å¢ƒä»å¿™ç¢Œå˜ä¸ºç©ºé—²ï¼‰
            if not self.env_busy[env_idx] and hasattr(self, '_prev_grasped_count'):
                # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„ç‰©ä½“è¢«æŠ“å–
                prev_count = getattr(self, '_prev_grasped_count', [0] * self.num_envs)[env_idx]
                if grasped_count > prev_count:
                    # æˆåŠŸæŠ“å–äº†æ–°ç‰©ä½“
                    reward[env_idx] += w_success * 1.0  # å•æ¬¡æˆåŠŸå¥–åŠ±
                    
                    # ç®€åŒ–çš„ä½ç§»æƒ©ç½šï¼ˆå‡è®¾å…¶ä»–ç‰©ä½“çš„ä½ç§»å¾ˆå°ï¼‰
                    # åœ¨å®é™…å®ç°ä¸­ï¼Œå¯ä»¥è®¡ç®—å…¶ä»–ç‰©ä½“ä½ç½®çš„å˜åŒ–
                    other_displacement = 0.0  # ç®€åŒ–ä¸º0ï¼Œé¿å…å¤æ‚è®¡ç®—
                    reward[env_idx] -= w_disp * min(other_displacement / disp_scale, 1.0)
            
            # æ—¶é—´æƒ©ç½š - æ¯æ­¥éƒ½æœ‰
            reward[env_idx] -= w_time
            
            # å…¨éƒ¨å®Œæˆå¤§å¥–åŠ±
            if grasped_count == self.total_objects_per_env:
                reward[env_idx] += R_complete
        
        # è®°å½•å½“å‰æŠ“å–æ•°é‡ï¼Œç”¨äºä¸‹æ¬¡æ¯”è¾ƒ
        if not hasattr(self, '_prev_grasped_count'):
            self._prev_grasped_count = [0] * self.num_envs
        for env_idx in range(self.num_envs):
            self._prev_grasped_count[env_idx] = len(self.grasped_objects[env_idx])
        
        return reward
    
    def _compute_continuous_action_reward(self, info: Dict):
        """è®¡ç®—è¿ç»­åŠ¨ä½œæ¨¡å¼çš„å¥–åŠ±"""
        reward = torch.zeros(self.num_envs, device=self.device)
        
        if not hasattr(self, 'target_object') or self.target_object is None:
            return reward
        
        # 1. æ¥è¿‘å¥–åŠ±ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        tcp_to_obj_dist = torch.linalg.norm(
            self.target_object.pose.p - self.agent.tcp.pose.p, axis=1
        )
        reaching_reward = 1 - torch.tanh(5 * tcp_to_obj_dist)
        reward += reaching_reward * 2.0  # æƒé‡2.0
        
        # 2. æŠ“å–å¥–åŠ±
        is_grasped = info["is_grasped"]
        reward += is_grasped * 3.0  # æƒé‡3.0
        
        # 3. æ”¾ç½®å¥–åŠ±
        obj_to_goal_dist = torch.linalg.norm(
            self.goal_site.pose.p - self.target_object.pose.p, axis=1
        )
        place_reward = 1 - torch.tanh(5 * obj_to_goal_dist)
        reward += place_reward * is_grasped * 2.0  # åªæœ‰æŠ“å–æ—¶æ‰ç»™æ”¾ç½®å¥–åŠ±
        
        # 4. å…¶ä»–ç‰©ä½“ä½ç§»æƒ©ç½šï¼ˆä¼˜å…ˆçº§ç¬¬äºŒï¼‰
        other_displacement = self._calculate_other_objects_displacement()
        displacement_penalty = torch.tanh(other_displacement)
        reward -= displacement_penalty * 1.5  # æƒé‡1.5
        
        # 5. æ—¶é—´æƒ©ç½šï¼ˆä¼˜å…ˆçº§ç¬¬ä¸‰ï¼‰
        time_penalty = 0.01  # æ¯æ­¥å°æƒ©ç½š
        reward -= time_penalty
        
        # 6. é™æ­¢å¥–åŠ±
        static_reward = 1 - torch.tanh(
            5 * torch.linalg.norm(self.agent.robot.get_qvel()[..., :-2], axis=1)
        )
        reward += static_reward * info["is_obj_placed"] * 1.0
        
        # 7. æˆåŠŸå¥–åŠ±
        reward[info["success"]] = 10.0
        
        return reward

    def compute_sparse_reward(self, obs: Any, action: torch.Tensor, info: Dict):
        """è®¡ç®—ç¨€ç–å¥–åŠ±"""
        reward = torch.zeros(self.num_envs, device=self.device)
        
        # åªæœ‰æˆåŠŸæ—¶æ‰ç»™å¥–åŠ±
        reward[info["success"]] = 1.0
        
        # å…¶ä»–ç‰©ä½“ä½ç§»æƒ©ç½š
        other_displacement = self._calculate_other_objects_displacement()
        displacement_penalty = other_displacement * 0.1
        reward -= displacement_penalty
        
        return reward

    def compute_normalized_dense_reward(self, obs: Any, action: torch.Tensor, info: Dict):
        """è®¡ç®—å½’ä¸€åŒ–å¯†é›†å¥–åŠ±"""
        # æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼Œnormalized_dense_reward åº”è¯¥æ˜¯å¯¹ dense_reward çš„å½’ä¸€åŒ–
        # ä¸åº”è¯¥æ ¹æ® reward_mode é€‰æ‹©ä¸åŒçš„å¥–åŠ±å‡½æ•°
        dense_reward = self.compute_dense_reward(obs=obs, action=action, info=info)
        return dense_reward / 10.0 

 

    def _init_fsm_states(self):
        """åˆå§‹åŒ–æœ‰é™çŠ¶æ€æœºçŠ¶æ€å¼ é‡"""
        self.env_stage = torch.zeros(self.num_envs, dtype=torch.int8, device=self.device)
        self.env_target = torch.full((self.num_envs,), -1, dtype=torch.int16, device=self.device)
        self.env_busy = torch.zeros(self.num_envs, dtype=torch.bool, device=self.device)
        self.stage_tick = torch.zeros(self.num_envs, dtype=torch.int16, device=self.device)
        self.stage_positions = torch.zeros(self.num_envs, 3, dtype=torch.float32, device=self.device)